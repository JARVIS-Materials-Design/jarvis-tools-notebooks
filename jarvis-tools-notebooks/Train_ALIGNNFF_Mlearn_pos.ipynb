{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/Train_ALIGNNFF_Mlearn_pos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "if not os.path.exists('jarvis_leaderboard'):\n",
        "  !git clone https://github.com/usnistgov/jarvis_leaderboard.git\n",
        "os.chdir('jarvis_leaderboard')\n",
        "!pip install -e .\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "_k6ga4THb2B9",
        "outputId": "8b1b656f-2f72-4ded-a12c-0aab6256b09e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jarvis_leaderboard'...\n",
            "remote: Enumerating objects: 58550, done.\u001b[K\n",
            "remote: Counting objects: 100% (7042/7042), done.\u001b[K\n",
            "remote: Compressing objects: 100% (881/881), done.\u001b[K\n",
            "remote: Total 58550 (delta 3905), reused 6486 (delta 3585), pack-reused 51508\u001b[K\n",
            "Receiving objects: 100% (58550/58550), 382.61 MiB | 15.82 MiB/s, done.\n",
            "Resolving deltas: 100% (30901/30901), done.\n",
            "Updating files: 100% (3644/3644), done.\n",
            "Obtaining file:///content/jarvis_leaderboard\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (1.11.4)\n",
            "Collecting jarvis-tools>=2021.07.19 (from jarvis-leaderboard==2024.1.6)\n",
            "  Downloading jarvis_tools-2023.12.12-py2.py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.7/975.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (1.5.3)\n",
            "Collecting rouge>=1.0.1 (from jarvis-leaderboard==2024.1.6)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting mkdocs>=1.5.2 (from jarvis-leaderboard==2024.1.6)\n",
            "  Downloading mkdocs-1.5.3-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mkdocs-material>=9.0.5 (from jarvis-leaderboard==2024.1.6)\n",
            "  Downloading mkdocs_material-9.5.3-py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic>=2.3.0 (from jarvis-leaderboard==2024.1.6)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (3.5.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (5.15.0)\n",
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (1.4.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.6) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.6) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.6) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.6) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.6) (4.66.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (3.7.1)\n",
            "Collecting spglib>=1.14.1 (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading spglib-2.2.0-cp310-cp310-manylinux_2_17_x86_64.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (2.31.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (0.12.0)\n",
            "Collecting xmltodict>=0.11.0 (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting ghp-import>=1.0 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6) (3.1.2)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6) (2.1.3)\n",
            "Collecting mergedeep>=1.3.4 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: packaging>=20.5 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6) (23.2)\n",
            "Collecting pathspec>=0.11.1 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6) (4.1.0)\n",
            "Collecting pyyaml-env-tag>=0.1 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading pyyaml_env_tag-0.1-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6) (6.0.1)\n",
            "Collecting watchdog>=2.0 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel~=2.10 in /usr/local/lib/python3.10/dist-packages (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6) (2.14.0)\n",
            "Collecting colorama~=0.4 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting mkdocs-material-extensions~=1.3 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting paginate~=0.5 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading paginate-0.5.6.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygments~=2.16 in /usr/local/lib/python3.10/dist-packages (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6) (2.16.1)\n",
            "Collecting pymdown-extensions~=10.2 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading pymdown_extensions-10.7-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->jarvis-leaderboard==2024.1.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->jarvis-leaderboard==2024.1.6) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.6.1 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.6)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge>=1.0.1->jarvis-leaderboard==2024.1.6) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->jarvis-leaderboard==2024.1.6) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->jarvis-leaderboard==2024.1.6) (8.2.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.6) (2023.11.17)\n",
            "Building wheels for collected packages: paginate\n",
            "  Building wheel for paginate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paginate: filename=paginate-0.5.6-py3-none-any.whl size=12666 sha256=d7464f3ec7785c0d09f2ab973d5d1de3254d62fd220797731ada5ea95b9423e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/d3/18/0b5bebc873f29bea61fedece1e92cbcbef416839dfe5bd0eef\n",
            "Successfully built paginate\n",
            "Installing collected packages: paginate, xmltodict, watchdog, typing-extensions, spglib, rouge, pyyaml-env-tag, pymdown-extensions, pathspec, mkdocs-material-extensions, mergedeep, colorama, annotated-types, pydantic-core, ghp-import, pydantic, mkdocs, mkdocs-material, jarvis-tools, jarvis-leaderboard\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Running setup.py develop for jarvis-leaderboard\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.6.0 colorama-0.4.6 ghp-import-2.1.0 jarvis-leaderboard-2024.1.6 jarvis-tools-2023.12.12 mergedeep-1.3.4 mkdocs-1.5.3 mkdocs-material-9.5.3 mkdocs-material-extensions-1.3.1 paginate-0.5.6 pathspec-0.12.1 pydantic-2.5.3 pydantic-core-2.14.6 pymdown-extensions-10.7 pyyaml-env-tag-0.1 rouge-1.0.1 spglib-2.2.0 typing-extensions-4.9.0 watchdog-3.0.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install  -q dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
        "!pip install  -q dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
        "# !pip install -q alignn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2yF-sgRv6a0",
        "outputId": "7b18ab94-6b1c-45aa-de61-ccd53da4c75a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "CPU times: user 249 ms, sys: 39.5 ms, total: 288 ms\n",
            "Wall time: 37 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cmd = 'rm -r alignn'\n",
        "os.system(cmd)\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "os.chdir('alignn')\n",
        "!git checkout posderiv2\n",
        "!python setup.py develop"
      ],
      "metadata": {
        "id": "xmRHVJ74qV-m",
        "outputId": "f3f6778f-241d-4764-fa68-592dd6ec934b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alignn'...\n",
            "remote: Enumerating objects: 4244, done.\u001b[K\n",
            "remote: Counting objects: 100% (1150/1150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (310/310), done.\u001b[K\n",
            "remote: Total 4244 (delta 983), reused 845 (delta 839), pack-reused 3094\u001b[K\n",
            "Receiving objects: 100% (4244/4244), 154.28 MiB | 16.41 MiB/s, done.\n",
            "Resolving deltas: 100% (2537/2537), done.\n",
            "Branch 'posderiv2' set up to track remote branch 'posderiv2' from 'origin'.\n",
            "Switched to a new branch 'posderiv2'\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/dist.py:519: InformationOnly: Normalizing '2023.04.07' to '2023.4.7'\n",
            "  self.metadata.version = self._normalize_version(\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating alignn.egg-info\n",
            "writing alignn.egg-info/PKG-INFO\n",
            "writing dependency_links to alignn.egg-info/dependency_links.txt\n",
            "writing requirements to alignn.egg-info/requires.txt\n",
            "writing top-level names to alignn.egg-info/top_level.txt\n",
            "writing manifest file 'alignn.egg-info/SOURCES.txt'\n",
            "reading manifest file 'alignn.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.rst'\n",
            "writing manifest file 'alignn.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/alignn.egg-link (link to .)\n",
            "Removing alignn 2023.4.7 from easy-install.pth file\n",
            "Adding alignn 2023.4.7 to easy-install.pth file\n",
            "Installing pretrained.py script to /usr/local/bin\n",
            "Installing train_folder.py script to /usr/local/bin\n",
            "Installing train_folder_ff.py script to /usr/local/bin\n",
            "Installing run_alignn_ff.py script to /usr/local/bin\n",
            "\n",
            "Installed /content/alignn/alignn/alignn\n",
            "Processing dependencies for alignn==2023.4.7\n",
            "Searching for ase==3.22.1\n",
            "Best match: ase 3.22.1\n",
            "Processing ase-3.22.1-py3.10.egg\n",
            "ase 3.22.1 is already the active version in easy-install.pth\n",
            "Installing ase script to /usr/local/bin\n",
            "Installing ase-build script to /usr/local/bin\n",
            "Installing ase-db script to /usr/local/bin\n",
            "Installing ase-gui script to /usr/local/bin\n",
            "Installing ase-info script to /usr/local/bin\n",
            "Installing ase-run script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/ase-3.22.1-py3.10.egg\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Processing pyparsing-2.4.7-py3.10.egg\n",
            "pyparsing 2.4.7 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/pyparsing-2.4.7-py3.10.egg\n",
            "Searching for pydocstyle==6.3.0\n",
            "Best match: pydocstyle 6.3.0\n",
            "Processing pydocstyle-6.3.0-py3.10.egg\n",
            "pydocstyle 6.3.0 is already the active version in easy-install.pth\n",
            "Installing pydocstyle script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/pydocstyle-6.3.0-py3.10.egg\n",
            "Searching for pycodestyle==2.11.1\n",
            "Best match: pycodestyle 2.11.1\n",
            "Adding pycodestyle 2.11.1 to easy-install.pth file\n",
            "Installing pycodestyle script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for flake8==7.0.0\n",
            "Best match: flake8 7.0.0\n",
            "Processing flake8-7.0.0-py3.10.egg\n",
            "flake8 7.0.0 is already the active version in easy-install.pth\n",
            "Installing flake8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/flake8-7.0.0-py3.10.egg\n",
            "Searching for pydantic==1.8.1\n",
            "Best match: pydantic 1.8.1\n",
            "Processing pydantic-1.8.1-py3.10.egg\n",
            "pydantic 1.8.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/pydantic-1.8.1-py3.10.egg\n",
            "Searching for pytorch-ignite==0.5.0.dev20240110\n",
            "Best match: pytorch-ignite 0.5.0.dev20240110\n",
            "Processing pytorch_ignite-0.5.0.dev20240110-py3.10.egg\n",
            "pytorch-ignite 0.5.0.dev20240110 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/pytorch_ignite-0.5.0.dev20240110-py3.10.egg\n",
            "Searching for pandas==1.5.3\n",
            "Best match: pandas 1.5.3\n",
            "Adding pandas 1.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tqdm==4.66.1\n",
            "Best match: tqdm 4.66.1\n",
            "Adding tqdm 4.66.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for matplotlib==3.7.1\n",
            "Best match: matplotlib 3.7.1\n",
            "Adding matplotlib 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scikit-learn==1.2.2\n",
            "Best match: scikit-learn 1.2.2\n",
            "Adding scikit-learn 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for dgl==1.1.3+cu121\n",
            "Best match: dgl 1.1.3+cu121\n",
            "Adding dgl 1.1.3+cu121 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torch==2.1.0+cu121\n",
            "Best match: torch 2.1.0+cu121\n",
            "Adding torch 2.1.0+cu121 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for jarvis-tools==2023.12.12\n",
            "Best match: jarvis-tools 2023.12.12\n",
            "Adding jarvis-tools 2023.12.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scipy==1.11.4\n",
            "Best match: scipy 1.11.4\n",
            "Adding scipy 1.11.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.23.5\n",
            "Best match: numpy 1.23.5\n",
            "Adding numpy 1.23.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for snowballstemmer==2.2.0\n",
            "Best match: snowballstemmer 2.2.0\n",
            "Adding snowballstemmer 2.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyflakes==3.2.0\n",
            "Best match: pyflakes 3.2.0\n",
            "Processing pyflakes-3.2.0-py3.10.egg\n",
            "pyflakes 3.2.0 is already the active version in easy-install.pth\n",
            "Installing pyflakes script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/pyflakes-3.2.0-py3.10.egg\n",
            "Searching for mccabe==0.7.0\n",
            "Best match: mccabe 0.7.0\n",
            "Processing mccabe-0.7.0-py3.10.egg\n",
            "mccabe 0.7.0 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/mccabe-0.7.0-py3.10.egg\n",
            "Searching for typing-extensions==4.9.0\n",
            "Best match: typing-extensions 4.9.0\n",
            "Adding typing-extensions 4.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for packaging==23.2\n",
            "Best match: packaging 23.2\n",
            "Adding packaging 23.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pytz==2023.3.post1\n",
            "Best match: pytz 2023.3.post1\n",
            "Adding pytz 2023.3.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Pillow==9.4.0\n",
            "Best match: Pillow 9.4.0\n",
            "Adding Pillow 9.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for kiwisolver==1.4.5\n",
            "Best match: kiwisolver 1.4.5\n",
            "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fonttools==4.47.0\n",
            "Best match: fonttools 4.47.0\n",
            "Adding fonttools 4.47.0 to easy-install.pth file\n",
            "Installing fonttools script to /usr/local/bin\n",
            "Installing pyftmerge script to /usr/local/bin\n",
            "Installing pyftsubset script to /usr/local/bin\n",
            "Installing ttx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cycler==0.12.1\n",
            "Best match: cycler 0.12.1\n",
            "Adding cycler 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for contourpy==1.2.0\n",
            "Best match: contourpy 1.2.0\n",
            "Adding contourpy 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for threadpoolctl==3.2.0\n",
            "Best match: threadpoolctl 3.2.0\n",
            "Adding threadpoolctl 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for joblib==1.3.2\n",
            "Best match: joblib 1.3.2\n",
            "Adding joblib 1.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests==2.31.0\n",
            "Best match: requests 2.31.0\n",
            "Adding requests 2.31.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.2.1\n",
            "Best match: networkx 3.2.1\n",
            "Adding networkx 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.1.0\n",
            "Best match: triton 2.1.0\n",
            "Adding triton 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fsspec==2023.6.0\n",
            "Best match: fsspec 2023.6.0\n",
            "Adding fsspec 2023.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.12\n",
            "Best match: sympy 1.12\n",
            "Adding sympy 1.12 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.13.1\n",
            "Best match: filelock 3.13.1\n",
            "Adding filelock 3.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Markdown==3.5.1\n",
            "Best match: Markdown 3.5.1\n",
            "Adding Markdown 3.5.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mkdocs-material==9.5.3\n",
            "Best match: mkdocs-material 9.5.3\n",
            "Adding mkdocs-material 9.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for xmltodict==0.13.0\n",
            "Best match: xmltodict 0.13.0\n",
            "Adding xmltodict 0.13.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for toolz==0.12.0\n",
            "Best match: toolz 0.12.0\n",
            "Adding toolz 0.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for spglib==2.2.0\n",
            "Best match: spglib 2.2.0\n",
            "Adding spglib 2.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for certifi==2023.11.17\n",
            "Best match: certifi 2023.11.17\n",
            "Adding certifi 2023.11.17 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for urllib3==2.0.7\n",
            "Best match: urllib3 2.0.7\n",
            "Adding urllib3 2.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for idna==3.6\n",
            "Best match: idna 3.6\n",
            "Adding idna 3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for charset-normalizer==3.3.2\n",
            "Best match: charset-normalizer 3.3.2\n",
            "Adding charset-normalizer 3.3.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.3\n",
            "Best match: MarkupSafe 2.1.3\n",
            "Adding MarkupSafe 2.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for regex==2023.6.3\n",
            "Best match: regex 2023.6.3\n",
            "Adding regex 2023.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pymdown-extensions==10.7\n",
            "Best match: pymdown-extensions 10.7\n",
            "Adding pymdown-extensions 10.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Pygments==2.16.1\n",
            "Best match: Pygments 2.16.1\n",
            "Adding Pygments 2.16.1 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for paginate==0.5.6\n",
            "Best match: paginate 0.5.6\n",
            "Adding paginate 0.5.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mkdocs==1.5.3\n",
            "Best match: mkdocs 1.5.3\n",
            "Adding mkdocs 1.5.3 to easy-install.pth file\n",
            "Installing mkdocs script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mkdocs-material-extensions==1.3.1\n",
            "Best match: mkdocs-material-extensions 1.3.1\n",
            "Adding mkdocs-material-extensions 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for colorama==0.4.6\n",
            "Best match: colorama 0.4.6\n",
            "Adding colorama 0.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Babel==2.14.0\n",
            "Best match: Babel 2.14.0\n",
            "Adding Babel 2.14.0 to easy-install.pth file\n",
            "Installing pybabel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PyYAML==6.0.1\n",
            "Best match: PyYAML 6.0.1\n",
            "Adding PyYAML 6.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for watchdog==3.0.0\n",
            "Best match: watchdog 3.0.0\n",
            "Adding watchdog 3.0.0 to easy-install.pth file\n",
            "Installing watchmedo script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyyaml-env-tag==0.1\n",
            "Best match: pyyaml-env-tag 0.1\n",
            "Adding pyyaml-env-tag 0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for platformdirs==4.1.0\n",
            "Best match: platformdirs 4.1.0\n",
            "Adding platformdirs 4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pathspec==0.12.1\n",
            "Best match: pathspec 0.12.1\n",
            "Adding pathspec 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mergedeep==1.3.4\n",
            "Best match: mergedeep 1.3.4\n",
            "Adding mergedeep 1.3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for ghp-import==2.1.0\n",
            "Best match: ghp-import 2.1.0\n",
            "Adding ghp-import 2.1.0 to easy-install.pth file\n",
            "Installing ghp-import script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for click==8.1.7\n",
            "Best match: click 8.1.7\n",
            "Adding click 8.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for alignn==2023.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example configuration file"
      ],
      "metadata": {
        "id": "OIfymESSDare"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json\n",
        "!cp config_mlearn_cu.json /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYHqz8av6YD",
        "outputId": "4934591a-c63c-4fe9-8a6c-00303e6b409a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-10 00:28:53--  https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2034 (2.0K) [text/plain]\n",
            "Saving to: ‘config_mlearn_cu.json.1’\n",
            "\n",
            "\rconfig_mlearn_cu.js   0%[                    ]       0  --.-KB/s               \rconfig_mlearn_cu.js 100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-10 00:28:53 (41.5 MB/s) - ‘config_mlearn_cu.json.1’ saved [2034/2034]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "WwCWPwjKxUd2",
        "outputId": "22fb7321-569c-48b7-8159-7e80b337b6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alignn/alignn/alignn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip\n",
        "!cp mlearn.json.zip /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7dK40z_xaEc",
        "outputId": "cbb0e2c5-7dd1-4ea1-8817-87a71edb7556"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-10 00:28:05--  https://figshare.com/ndownloader/files/40357663\n",
            "Resolving figshare.com (figshare.com)... 54.171.25.118, 54.78.226.1, 2a05:d018:1f4:d000:7c2f:634d:6031:94b5, ...\n",
            "Connecting to figshare.com (figshare.com)|54.171.25.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240110/eu-west-1/s3/aws4_request&X-Amz-Date=20240110T002806Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=90ee42bf548ff21b249bcda129227c5d4f15ef09bb7809cbb10f472ca4cafc60 [following]\n",
            "--2024-01-10 00:28:06--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240110/eu-west-1/s3/aws4_request&X-Amz-Date=20240110T002806Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=90ee42bf548ff21b249bcda129227c5d4f15ef09bb7809cbb10f472ca4cafc60\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.57.211, 52.218.29.19, 52.218.112.99, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.57.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2542319 (2.4M) [application/zip]\n",
            "Saving to: ‘mlearn.json.zip’\n",
            "\n",
            "mlearn.json.zip     100%[===================>]   2.42M  1.96MB/s    in 1.2s    \n",
            "\n",
            "2024-01-10 00:28:08 (1.96 MB/s) - ‘mlearn.json.zip’ saved [2542319/2542319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y ase\n",
        "!pip install ase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw3dVfYRxorg",
        "outputId": "c0c59101-b1c7-44cc-d1dd-67c62e7e1880"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: ase 3.22.1\n",
            "Uninstalling ase-3.22.1:\n",
            "  Successfully uninstalled ase-3.22.1\n",
            "Collecting ase\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase) (1.16.0)\n",
            "Installing collected packages: ase\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "alignn 2023.4.7 requires pyparsing<3,>=2.2.1, but you have pyparsing 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ase-3.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ase"
      ],
      "metadata": {
        "id": "m5Rh6vTTtc8x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# withut cut-off function, grad weight 0.2\n",
        "%%time\n",
        "import os,json,torch\n",
        "from jarvis.core.atoms import Atoms\n",
        "from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "import json,zipfile\n",
        "import zipfile\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from jarvis.core.atoms import Atoms\n",
        "import os\n",
        "from alignn.ff.ff import AlignnAtomwiseCalculator, default_path, ForceField\n",
        "import torch\n",
        "from ase.stress import full_3x3_to_voigt_6_stress, voigt_6_to_full_3x3_stress\n",
        "from jarvis.db.figshare import data\n",
        "import subprocess\n",
        "from subprocess import Popen, PIPE\n",
        "mlearn = json.loads(\n",
        "        zipfile.ZipFile(\"/content/mlearn.json.zip\").read(\n",
        "            \"mlearn.json\"\n",
        "        )\n",
        "    )\n",
        "example_config = loadjson(\"config_mlearn_cu.json\")\n",
        "null=None\n",
        "false=False\n",
        "true=True\n",
        "example_config={\n",
        "    \"version\": \"112bbedebdaecf59fb18e11c929080fb2f358246\",\n",
        "    \"dataset\": \"user_data\",\n",
        "    \"target\": \"target\",\n",
        "    \"atom_features\": \"cgcnn\",\n",
        "    \"neighbor_strategy\": \"k-nearest\",\n",
        "    \"id_tag\": \"jid\",\n",
        "    \"random_seed\": 123,\n",
        "    \"classification_threshold\": null,\n",
        "    \"n_val\": null,\n",
        "    \"n_test\": null,\n",
        "    \"n_train\": null,\n",
        "    \"train_ratio\": 0.8,\n",
        "    \"val_ratio\": 0.1,\n",
        "    \"test_ratio\": 0.1,\n",
        "    \"target_multiplication_factor\": null,\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 2,\n",
        "    \"weight_decay\": 1e-05,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"filename\": \"sample\",\n",
        "    \"warmup_steps\": 2000,\n",
        "    \"criterion\": \"l1\",\n",
        "    \"optimizer\": \"adamw\",\n",
        "    \"scheduler\": \"onecycle\",\n",
        "    \"pin_memory\": false,\n",
        "    \"save_dataloader\": false,\n",
        "    \"write_checkpoint\": true,\n",
        "    \"write_predictions\": true,\n",
        "    \"store_outputs\": false,\n",
        "    \"progress\": true,\n",
        "    \"log_tensorboard\": false,\n",
        "    \"standard_scalar_and_pca\": false,\n",
        "    \"use_canonize\": false,\n",
        "    \"num_workers\": 0,\n",
        "    \"cutoff\": 8.0,\n",
        "    \"max_neighbors\": 12,\n",
        "    \"keep_data_order\": false,\n",
        "    \"model\": {\n",
        "        \"name\": \"alignn_atomwise\",\n",
        "        \"atom_input_features\": 92,\n",
        "        \"calculate_gradient\":true,\n",
        "        \"atomwise_output_features\":3,\n",
        "        \"alignn_layers\":4,\n",
        "        \"hidden_features\": 300,\n",
        "        \"gcn_layers\":4,\n",
        "        \"output_features\": 1,\n",
        "        \"graphwise_weight\":0.0,\n",
        "        \"gradwise_weight\":1.5,\n",
        "        \"atomwise_weight\":0.0,\n",
        "        \"stresswise_weight\":0.0\n",
        "\n",
        "    }\n",
        "}\n",
        "run_dir='/content'\n",
        "elements = [\"Si\"] #,\"Cu\"] #,\"Ni\",\"Ge\",\"Mo\",\"Li\"]\n",
        "mem = []\n",
        "for element in elements:\n",
        "    os.chdir(run_dir)\n",
        "    dir_name = \"alff_\" + element\n",
        "    cmd='rm -rf '+dir_name\n",
        "    os.system(cmd)\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    benchmark_energies = (\n",
        "        \"jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/mlearn_\"\n",
        "        + element\n",
        "        + \"_energy.json.zip\"\n",
        "    )\n",
        "\n",
        "    temp_energies = benchmark_energies.split(\"/\")[-1].split(\".zip\")[0]\n",
        "    energies = json.loads(\n",
        "        zipfile.ZipFile(benchmark_energies).read(temp_energies)\n",
        "    )\n",
        "    train_ids = list(energies[\"train\"].keys())\n",
        "    test_ids = list(energies[\"test\"].keys())\n",
        "    example_config[\"n_train\"] = len(train_ids)\n",
        "    example_config[\"n_val\"] = len(test_ids)\n",
        "    example_config[\"n_test\"] = len(test_ids)\n",
        "    example_config[\"model\"][\"graphwise_weight\"] = 1\n",
        "    example_config[\"model\"][\"gradwise_weight\"] = 1\n",
        "    example_config[\"epochs\"] = 100\n",
        "    example_config[\"batch_size\"] = 2\n",
        "\n",
        "    example_config[\"keep_data_order\"] = True\n",
        "    config_name = dir_name + \"/config_\" + element + \".json\"\n",
        "    dumpjson(data=example_config, filename=config_name)\n",
        "\n",
        "    train_energies = []\n",
        "    train_forces = []\n",
        "    train_stresses = []\n",
        "    train_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in train_ids:\n",
        "            # print(i)\n",
        "            train_energies.append(i[\"energy\"])\n",
        "            train_forces.append(i[\"forces\"])\n",
        "            train_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            # alignn uses intensive/energy oer atom quanitity\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            mem.append(info)\n",
        "    # Val same as test\n",
        "    test_energies = []\n",
        "    test_forces = []\n",
        "    test_stresses = []\n",
        "    test_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            # print(i)\n",
        "            test_energies.append(i[\"energy\"])\n",
        "            test_forces.append(i[\"forces\"])\n",
        "            test_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            # alignn uses intensive/energy oer atom quanitity\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            mem.append(info)\n",
        "    test_energies = []\n",
        "    test_forces = []\n",
        "    test_stresses = []\n",
        "    test_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            # print(i)\n",
        "            test_energies.append(i[\"energy\"])\n",
        "            test_forces.append(i[\"forces\"])\n",
        "            test_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            #test_structures.append(atoms.pymatgen_converter())\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            # alignn uses intensive/energy oer atom quanitity\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            mem.append(info)\n",
        "    filename = dir_name + \"/id_prop.json\"\n",
        "    dumpjson(data=mem, filename=filename)\n",
        "    cmd = (\n",
        "        \"train_folder_ff.py --root_dir \"\n",
        "        + dir_name\n",
        "        + \" --config \"\n",
        "        + config_name\n",
        "        + \" --output_dir \"\n",
        "        + dir_name\n",
        "    )\n",
        "    #cmd=\"train_folder_ff.py -h\"\n",
        "\n",
        "    print(cmd)\n",
        "    #os.system(cmd)\n",
        "    subprocess.call(cmd, stdout=PIPE,shell=True)\n",
        "    #p1 = Popen(cmd, stdout=PIPE, shell=True)\n",
        "\n",
        "\n",
        "################\n",
        "    model_path = dir_name\n",
        "\n",
        "    # calc = AlignnAtomwiseCalculator(path=model_path)\n",
        "    calc = AlignnAtomwiseCalculator(\n",
        "        path=model_path,\n",
        "        force_mult_natoms=False,\n",
        "        force_multiplier=1,\n",
        "        stress_wt=-4800,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    def get_alignn_forces(atoms):\n",
        "        energy = 0.0\n",
        "        forces = np.zeros((atoms.num_atoms, 3))\n",
        "        stress = np.zeros((3, 3))\n",
        "        # try:\n",
        "        ase_atoms = atoms.ase_converter()\n",
        "        ase_atoms.calc = calc  # M3GNetCalculator(potential=potential)\n",
        "        forces = np.array(ase_atoms.get_forces())\n",
        "        energy = ase_atoms.get_potential_energy()\n",
        "        stress = voigt_6_to_full_3x3_stress(ase_atoms.get_stress())\n",
        "        # except:\n",
        "        #  print ('Failed for',atoms)\n",
        "        #  pass\n",
        "        return energy, forces, stress\n",
        "\n",
        "    # df = pd.DataFrame(mdata)\n",
        "    df = pd.DataFrame(\n",
        "        json.loads(\n",
        "            zipfile.ZipFile(\"mlearn.json.zip\").read(\n",
        "                \"mlearn.json\"\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    print(df)\n",
        "    #for i in glob.glob(\"../../benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "    for i in glob.glob(\"/content/jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "        if \"mlearn\" in i and element in i:\n",
        "            fname_e = (\n",
        "                \"AI-MLFF-energy-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-mae.csv\"\n",
        "            )\n",
        "            fname_f = (\n",
        "                \"AI-MLFF-forces-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-multimae.csv\"\n",
        "            )\n",
        "            fname_s = (\n",
        "                \"AI-MLFF-stresses-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-multimae.csv\"\n",
        "            )\n",
        "            f_e = open(fname_e, \"w\")\n",
        "            f_f = open(fname_f, \"w\")\n",
        "            f_s = open(fname_s, \"w\")\n",
        "\n",
        "            f_e.write(\"id,prediction\\n\")\n",
        "            f_f.write(\"id,prediction\\n\")\n",
        "            f_s.write(\"id,prediction\\n\")\n",
        "\n",
        "            print(i)\n",
        "            dat = json.loads(\n",
        "                zipfile.ZipFile(i).read(i.split(\"/\")[-1].split(\".zip\")[0])\n",
        "            )\n",
        "            print(dat[\"test\"])\n",
        "            for key, val in dat[\"test\"].items():\n",
        "                entry = df[df[\"jid\"] == key]\n",
        "                atoms = Atoms.from_dict(entry.atoms.values[0])\n",
        "                # print(key,val,df[df['jid']==key],atoms)\n",
        "                # energy,forces=get_alignn_forces(atoms)\n",
        "                energy, forces, stress = get_alignn_forces(atoms)\n",
        "                print(key, val, energy, atoms.num_atoms)\n",
        "                line = key + \",\" + str(energy) + \"\\n\"\n",
        "                f_e.write(line)\n",
        "                line = (\n",
        "                    key\n",
        "                    + \",\"\n",
        "                    + str(\";\".join(map(str, np.array(forces).flatten())))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "                f_f.write(line)\n",
        "                line = (\n",
        "                    key\n",
        "                    + \",\"\n",
        "                    + str(\";\".join(map(str, np.array(stress).flatten())))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "                f_s.write(line)\n",
        "            f_e.close()\n",
        "            f_f.close()\n",
        "            f_s.close()\n",
        "            zname = fname_e + \".zip\"\n",
        "            with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "                myzip.write(fname_e)\n",
        "\n",
        "            zname = fname_f + \".zip\"\n",
        "            with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "                myzip.write(fname_f)\n",
        "\n",
        "            zname = fname_s + \".zip\"\n",
        "            with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "                myzip.write(fname_s)\n",
        "            # cmd = \"zip \" + fname_e + \".zip \" + fname_e\n",
        "            # os.system(cmd)\n",
        "            # cmd = \"zip \" + fname_f + \".zip \" + fname_f\n",
        "            # os.system(cmd)\n",
        "            # cmd = \"zip \" + fname_s + \".zip \" + fname_s\n",
        "            # os.system(cmd)\n",
        "            # cmd = \"rm \" + fname_e\n",
        "            # os.system(cmd)\n",
        "            # cmd = \"rm \" + fname_f\n",
        "            # os.system(cmd)\n",
        "            # cmd='rm '+fname_s\n",
        "            # os.system(cmd)\n",
        "            # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8t_1dRwv6Vm",
        "outputId": "e365b668-791d-48bc-ebda-3053adc4acd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_folder_ff.py --root_dir alff_Si --config alff_Si/config_Si.json --output_dir alff_Si\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kzqntqx1reGB",
        "outputId": "1bd1424c-5115-4fd7-ce7d-042f08435c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 10 00:17:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0              22W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot energy & force scatter plot"
      ],
      "metadata": {
        "id": "RK5MfRNrcvMn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HhMpYddv148y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "d1KRguhm145-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silicon"
      ],
      "metadata": {
        "id": "R4As7DqgQWO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "out_dir = 'alff_Si'\n",
        "%matplotlib inline\n",
        "# Plot training hostory for validation set\n",
        "json_path = os.path.join(out_dir, \"history_val.json\")\n",
        "v = loadjson(json_path)\n",
        "ens = []\n",
        "fs = []\n",
        "for i in v:\n",
        "    ens.append(i[0])\n",
        "    fs.append(i[2])\n",
        "the_grid = GridSpec(1, 2)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "plt.title(\"(a) Energy\")\n",
        "plt.plot(ens)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV\")\n",
        "plt.subplot(the_grid[1])\n",
        "plt.title(\"(b) Forces\")\n",
        "plt.plot(fs)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV/A\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"history.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "CytZnalMv6S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_grid = GridSpec(1, 2)\n",
        "json_path = os.path.join(out_dir, \"Val_results.json\")\n",
        "test = loadjson(json_path)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "xx = []\n",
        "yy = []\n",
        "factor = 1\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_out\"], i[\"pred_out\"]):\n",
        "        xx.append(j)\n",
        "        yy.append(k)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Val\")\n",
        "print(\"Baseline MAE: eV\", baseline_mae)\n",
        "print(\"MAE eV\", mean_absolute_error(xx, yy))\n",
        "\n",
        "plt.plot(xx, yy, \".\")\n",
        "plt.ylabel(\"ALIGNN Energy (eV)\")\n",
        "plt.xlabel(\"DFT Energy (eV)\")\n",
        "plt.subplot(the_grid[1])\n",
        "xx = []\n",
        "yy = []\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_grad\"], i[\"pred_grad\"]):\n",
        "        for m, n in zip(j, k):\n",
        "            xx.append(m)\n",
        "            yy.append(n)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Test\")\n",
        "print(\"Baseline MAE: eV/A\", baseline_mae)\n",
        "print(\"MAE eV/A\", mean_absolute_error(xx, yy))\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "plt.ylabel(\"ALIGNN Force (eV/A)\")\n",
        "plt.xlabel(\"DFT Force (eV/A)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"val.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "BnvgA2euv6QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHEZ2LEJPS50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUnnHpJcPS0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCf2nmy-PSyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMmF8lqJPSvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RTgAlDmO_vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copper"
      ],
      "metadata": {
        "id": "qGKqUXeGQTkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "out_dir = 'alff_Cu'\n",
        "%matplotlib inline\n",
        "# Plot training hostory for validation set\n",
        "json_path = os.path.join(out_dir, \"history_val.json\")\n",
        "v = loadjson(json_path)\n",
        "ens = []\n",
        "fs = []\n",
        "for i in v:\n",
        "    ens.append(i[0])\n",
        "    fs.append(i[2])\n",
        "the_grid = GridSpec(1, 2)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "plt.title(\"(a) Energy\")\n",
        "plt.plot(ens)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV\")\n",
        "plt.subplot(the_grid[1])\n",
        "plt.title(\"(b) Forces\")\n",
        "plt.plot(fs)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV/A\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"history.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "ojMQaKg4v6Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_grid = GridSpec(1, 2)\n",
        "json_path = os.path.join(out_dir, \"Val_results.json\")\n",
        "test = loadjson(json_path)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "xx = []\n",
        "yy = []\n",
        "factor = 1\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_out\"], i[\"pred_out\"]):\n",
        "        xx.append(j)\n",
        "        yy.append(k)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Val\")\n",
        "print(\"Baseline MAE: eV\", baseline_mae)\n",
        "print(\"MAE eV\", mean_absolute_error(xx, yy))\n",
        "\n",
        "plt.plot(xx, yy, \".\")\n",
        "plt.ylabel(\"ALIGNN Energy (eV)\")\n",
        "plt.xlabel(\"DFT Energy (eV)\")\n",
        "plt.subplot(the_grid[1])\n",
        "xx = []\n",
        "yy = []\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_grad\"], i[\"pred_grad\"]):\n",
        "        for m, n in zip(j, k):\n",
        "            xx.append(m)\n",
        "            yy.append(n)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Test\")\n",
        "print(\"Baseline MAE: eV/A\", baseline_mae)\n",
        "print(\"MAE eV/A\", mean_absolute_error(xx, yy))\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "plt.ylabel(\"ALIGNN Force (eV/A)\")\n",
        "plt.xlabel(\"DFT Force (eV/A)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"val.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "WEd5fgdIPF-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.ff.ff import AlignnAtomwiseCalculator,default_path,wt10_path,alignnff_fmult,fd_path,ForceField\n",
        "from ase import Atom, Atoms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_path = 'alff_Cu' #default_path()\n",
        "calc = AlignnAtomwiseCalculator(path=model_path)\n",
        "\n",
        "\n",
        "lattice_params = np.linspace(3.1, 3.8)\n",
        "fcc_energies = []\n",
        "ready = True\n",
        "for a in lattice_params:\n",
        "    atoms = Atoms([Atom('Cu', (0, 0, 0))],\n",
        "                  cell=0.5 * a * np.array([[1.0, 1.0, 0.0],\n",
        "                                           [0.0, 1.0, 1.0],\n",
        "                                           [1.0, 0.0, 1.0]]),\n",
        "                 pbc=True)\n",
        "\n",
        "    atoms.set_tags(np.ones(len(atoms)))\n",
        "\n",
        "    atoms.calc = calc\n",
        "\n",
        "    e = atoms.get_potential_energy()\n",
        "    fcc_energies.append(e)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(lattice_params, fcc_energies)\n",
        "plt.title('1x1x1')\n",
        "plt.xlabel('Lattice constant ($\\AA$)')\n",
        "plt.ylabel('Total energy (eV)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XYYKSJMvQYvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q phonopy"
      ],
      "metadata": {
        "id": "U5e5RePpQqGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.ff.ff import phonons\n",
        "from jarvis.core.atoms import ase_to_atoms\n",
        "ph_path=model_path\n",
        "ph=phonons(model_path=ph_path,atoms=ase_to_atoms(atoms))\n",
        "%matplotlib inline\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JiEA_OU3QYq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBzZ3QtsQYoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpuLTOT7PQoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stop"
      ],
      "metadata": {
        "id": "XpG-QyCOv6Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some of the exisiting contributions for Cu forces. We are going to add another contribution after a quick alignn_ff training run and comapre with existing contributions."
      ],
      "metadata": {
        "id": "Oa6rICgdnSEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis_leaderboard.rebuild import get_metric_value,get_results\n",
        "# %matplotlib inline\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# names,vals=get_results(bench_name='AI-MLFF-forces-mlearn_Si-test-multimae.csv.zip')\n",
        "# plt.bar(np.arange(len(vals)),vals,color=(0.2, 0.4, 0.6, 0.6),edgecolor='blue')\n",
        "# plt.xticks(np.arange(len(vals)),names,rotation=90)\n",
        "# plt.ylabel('MAE (eV/A)')"
      ],
      "metadata": {
        "id": "64aGqWzvb6yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version #Bases on nvcc version, corresponding gpu version of dgl will be needed."
      ],
      "metadata": {
        "id": "IHoA-IATdzR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find list of pre-trained ALIGNN-FF models here: https://github.com/usnistgov/alignn/blob/main/alignn/ff/ff.py#L67"
      ],
      "metadata": {
        "id": "T7ukeWU5Y6u2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. EV-curve and phonon bandstructure for FCC Copper"
      ],
      "metadata": {
        "id": "xdxqMjFyd5TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use pretrained models for FCC Copper"
      ],
      "metadata": {
        "id": "qRMCJ_IObUYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.ff.ff import AlignnAtomwiseCalculator,default_path,wt10_path,alignnff_fmult,fd_path,ForceField\n",
        "model_path = wt10_path() #default_path()\n",
        "calc = AlignnAtomwiseCalculator(path=model_path)"
      ],
      "metadata": {
        "id": "2kJ-FaM4YxFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ase import Atom, Atoms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lattice_params = np.linspace(3.5, 3.8)\n",
        "fcc_energies = []\n",
        "ready = True\n",
        "for a in lattice_params:\n",
        "    atoms = Atoms([Atom('Cu', (0, 0, 0))],\n",
        "                  cell=0.5 * a * np.array([[1.0, 1.0, 0.0],\n",
        "                                           [0.0, 1.0, 1.0],\n",
        "                                           [1.0, 0.0, 1.0]]),\n",
        "                 pbc=True)\n",
        "\n",
        "    atoms.set_tags(np.ones(len(atoms)))\n",
        "\n",
        "    atoms.calc = calc\n",
        "\n",
        "    e = atoms.get_potential_energy()\n",
        "    fcc_energies.append(e)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(lattice_params, fcc_energies)\n",
        "plt.title('1x1x1')\n",
        "plt.xlabel('Lattice constant ($\\AA$)')\n",
        "plt.ylabel('Total energy (eV)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H99l8k5PZIdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.ff.ff import phonons\n",
        "from jarvis.core.atoms import ase_to_atoms\n",
        "ph_path=fd_path()\n",
        "ph=phonons(model_path=ph_path,atoms=ase_to_atoms(atoms))"
      ],
      "metadata": {
        "id": "Yc1F5QA3ZeWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr"
      ],
      "metadata": {
        "id": "DXS-tNyMarlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zFJoL7M0bERn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rqTfjR6baV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pwd\n",
        "os.chdir('/content')\n",
        "# Clone ALIGNN repo to get example folder\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "\n"
      ],
      "metadata": {
        "id": "hFZn-PrinTX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Use pretrained models for optimizing a few cubic systems"
      ],
      "metadata": {
        "id": "AdskezHHbuQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.core.atoms import Atoms\n",
        "from tqdm import tqdm\n",
        "from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "#Taking 5 out of 63 for quick test\n",
        "d = (loadjson(\"alignn/alignn/scripts/data_1.json\"))[0:6]\n",
        "model_path=alignnff_fmult()\n",
        "exp_a = [] #experiment\n",
        "aff_a = [] #alignn-ff\n",
        "for i in tqdm(d):\n",
        "    atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "    material = i[\"material\"]\n",
        "    crys = i[\"Crystal structure\"]\n",
        "    a = i[\"a\"]\n",
        "    print(material, crys, a)\n",
        "    ff = ForceField(\n",
        "        jarvis_atoms=atoms,\n",
        "        model_path=model_path,\n",
        "        stress_wt=0.3,\n",
        "        force_multiplier=1,\n",
        "        force_mult_natoms=False,\n",
        "    )\n",
        "    opt, en, fs = ff.optimize_atoms()  # logfile=None)\n",
        "    print(material, crys, a, opt.lattice.abc[0])\n",
        "    exp_a.append(float(a))\n",
        "    aff_a.append(float(opt.lattice.abc[0]))\n",
        "info = {}\n",
        "info[\"exp_a\"] = exp_a\n",
        "info[\"aff_a\"] = aff_a\n",
        "dumpjson(data=info, filename=\"comapre_cubic_lat.json\")\n"
      ],
      "metadata": {
        "id": "R-y2oncab7-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(exp_a,aff_a,'.')\n",
        "plt.plot(exp_a,exp_a,'-')\n",
        "plt.xlabel('Experimental a (Ang.)')\n",
        "plt.ylabel('ALIGNN-FF a (Ang.)')"
      ],
      "metadata": {
        "id": "vxahSs2Tc1kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train a Copper force-field from scratch"
      ],
      "metadata": {
        "id": "jSgU71Fqe5Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json\n"
      ],
      "metadata": {
        "id": "ylnu0xCjoWjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls alignn/alignn/examples/sample_data_ff/mlearn_data/all/"
      ],
      "metadata": {
        "id": "YWcGU66vn4J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "# Using lower batch size, samples, alignn and gcn layers etc. to fit in colab\n",
        "# RECOMMENDED: Use larger batch size (e.g.10,20,30 etc.), larger model architectire (higher number of alignn and GCN layers) and large number of epochs e.g. 300\n",
        "d=loadjson('config_mlearn_cu.json')\n",
        "d['batch_size']=2\n",
        "d['epochs']=20\n",
        "dumpjson(data=d,filename='config_mlearn_cu_less.json')"
      ],
      "metadata": {
        "id": "1yQ5rv5rsvdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_folder_ff.py` requires 1) id_prop.json and 2) a config file. In id_prop.json, atoms, energies, forces, stresses and other information are given. To see this json file was prepared, checkout this [script](https://github.com/usnistgov/alignn/blob/develop/alignn/examples/sample_data_ff/mlearn_data/generate_mlearn_data.py)."
      ],
      "metadata": {
        "id": "ZcHGCoK6nu3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " %%time\n",
        " # Note instead of training from scratch, one can use --restart_model_path argument for fine tuning a pretrained model.\n",
        " !train_folder_ff.py --root_dir \"alignn/alignn/examples/sample_data_ff/mlearn_data/Cu/\"  --config \"config_mlearn_cu_less.json\" --output_dir=\"OutCu\""
      ],
      "metadata": {
        "id": "o8tG1cAusthS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Analyze training results"
      ],
      "metadata": {
        "id": "jFEnqwk3ijcr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BaHGXkzyyo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuQ20q5-y36y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOWF55ley34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MiwMvAWcy32L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FynEcSoey3zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1daSd81y3w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "out_dir = \"OutCu\""
      ],
      "metadata": {
        "id": "9uOOGKAdl_9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Plot training hostory for validation set\n",
        "json_path = os.path.join(out_dir, \"history_val.json\")\n",
        "v = loadjson(json_path)\n",
        "ens = []\n",
        "fs = []\n",
        "for i in v:\n",
        "    ens.append(i[0])\n",
        "    fs.append(i[2])\n",
        "the_grid = GridSpec(1, 2)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "plt.title(\"(a) Energy\")\n",
        "plt.plot(ens)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV\")\n",
        "plt.subplot(the_grid[1])\n",
        "plt.title(\"(b) Forces\")\n",
        "plt.plot(fs)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV/A\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"history.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "yxKgQvw8mHn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_grid = GridSpec(1, 2)\n",
        "json_path = os.path.join(out_dir, \"Val_results.json\")\n",
        "test = loadjson(json_path)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "xx = []\n",
        "yy = []\n",
        "factor = 1\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_out\"], i[\"pred_out\"]):\n",
        "        xx.append(j)\n",
        "        yy.append(k)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Val\")\n",
        "print(\"Baseline MAE: eV\", baseline_mae)\n",
        "print(\"MAE eV\", mean_absolute_error(xx, yy))\n",
        "\n",
        "plt.plot(xx, yy, \".\")\n",
        "plt.ylabel(\"ALIGNN Energy (eV)\")\n",
        "plt.xlabel(\"DFT Energy (eV)\")\n",
        "plt.subplot(the_grid[1])\n",
        "xx = []\n",
        "yy = []\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_grad\"], i[\"pred_grad\"]):\n",
        "        for m, n in zip(j, k):\n",
        "            xx.append(m)\n",
        "            yy.append(n)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Test\")\n",
        "print(\"Baseline MAE: eV/A\", baseline_mae)\n",
        "print(\"MAE eV/A\", mean_absolute_error(xx, yy))\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "plt.ylabel(\"ALIGNN Force (eV/A)\")\n",
        "plt.xlabel(\"DFT Force (eV/A)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"val.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "XRPWGF0RmHlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train comparison\n",
        "the_grid = GridSpec(1, 2)\n",
        "json_path = os.path.join(out_dir, \"Train_results.json\")\n",
        "test = loadjson(json_path)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "xx = []\n",
        "yy = []\n",
        "factor = 1\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_out\"], i[\"pred_out\"]):\n",
        "        xx.append(j)\n",
        "        yy.append(k)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Train\")\n",
        "print(\"Baseline MAE: eV\", baseline_mae)\n",
        "print(\"MAE eV\", mean_absolute_error(xx, yy))\n",
        "\n",
        "plt.plot(xx, yy, \".\")\n",
        "plt.ylabel(\"ALIGNN Energy (eV)\")\n",
        "plt.xlabel(\"DFT Energy (eV)\")\n",
        "\n",
        "\n",
        "plt.subplot(the_grid[1])\n",
        "xx = []\n",
        "yy = []\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_grad\"], i[\"pred_grad\"]):\n",
        "        for m, n in zip(j, k):\n",
        "            xx.append(m)\n",
        "            yy.append(n)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Baseline MAE: eV/A\", baseline_mae)\n",
        "print(\"MAE eV/A\", mean_absolute_error(xx, yy))\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "plt.ylabel(\"ALIGNN Force (eV/A)\")\n",
        "plt.xlabel(\"DFT Force (eV/A)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"train.png\")\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "XGPaqn1cmHjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "eb65G9gRnus6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check EV curve for Copper using this newly trained model"
      ],
      "metadata": {
        "id": "FpyneAkkoX4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ase import Atom, Atoms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from alignn.ff.ff import AlignnAtomwiseCalculator,default_path,wt10_path,alignnff_fmult,fd_path,ForceField\n",
        "# Using the path for newly trained model\n",
        "model_path = out_dir\n",
        "calc = AlignnAtomwiseCalculator(path=model_path)\n",
        "\n",
        "lattice_params = np.linspace(3.5, 3.8)\n",
        "fcc_energies = []\n",
        "ready = True\n",
        "for a in lattice_params:\n",
        "    atoms = Atoms([Atom('Cu', (0, 0, 0))],\n",
        "                  cell=0.5 * a * np.array([[1.0, 1.0, 0.0],\n",
        "                                           [0.0, 1.0, 1.0],\n",
        "                                           [1.0, 0.0, 1.0]]),\n",
        "                 pbc=True)\n",
        "\n",
        "    atoms.set_tags(np.ones(len(atoms)))\n",
        "\n",
        "    atoms.calc = calc\n",
        "\n",
        "    e = atoms.get_potential_energy()\n",
        "    fcc_energies.append(e)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(lattice_params, fcc_energies)\n",
        "plt.title('1x1x1')\n",
        "plt.xlabel('Lattice constant ($\\AA$)')\n",
        "plt.ylabel('Total energy (eV)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ediLCTlyjxjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ph=phonons(phonopy_bands_figname=\"phonopy_bands2.png\", model_path=out_dir,atoms=ase_to_atoms(atoms))\n",
        "%matplotlib inline\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands2.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Fev-kbMjxgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "1GA12E--kUaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Make JARVIS-Leaderboard entry"
      ],
      "metadata": {
        "id": "rZ4RFyhDisPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/jarvis_leaderboard/jarvis_leaderboard/contributions/')\n",
        "os.makedirs('alignnff_cu')\n",
        "os.chdir('alignnff_cu')"
      ],
      "metadata": {
        "id": "s1rn9Unhmydg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip"
      ],
      "metadata": {
        "id": "74c9fm3Crgv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from jarvis.core.atoms import Atoms\n",
        "import os\n",
        "from alignn.ff.ff import AlignnAtomwiseCalculator, default_path, ForceField\n",
        "import torch\n",
        "from ase.stress import full_3x3_to_voigt_6_stress, voigt_6_to_full_3x3_stress\n",
        "from jarvis.db.figshare import data\n",
        "# mdata = data('mlearn')\n",
        "\n",
        "# torch.cuda.is_available = lambda : False\n",
        "model_path = \"/content/OutCu\"\n",
        "\n",
        "# calc = AlignnAtomwiseCalculator(path=model_path)\n",
        "calc = AlignnAtomwiseCalculator(\n",
        "    path=model_path,\n",
        "    force_mult_natoms=False,\n",
        "    force_multiplier=1,\n",
        "    stress_wt=-4800,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def get_alignn_forces(atoms):\n",
        "    energy = 0.0\n",
        "    forces = np.zeros((atoms.num_atoms, 3))\n",
        "    stress = np.zeros((3, 3))\n",
        "    # try:\n",
        "    ase_atoms = atoms.ase_converter()\n",
        "    ase_atoms.calc = calc  # M3GNetCalculator(potential=potential)\n",
        "    forces = np.array(ase_atoms.get_forces())\n",
        "    energy = ase_atoms.get_potential_energy()\n",
        "    stress = voigt_6_to_full_3x3_stress(ase_atoms.get_stress())\n",
        "    # except:\n",
        "    #  print ('Failed for',atoms)\n",
        "    #  pass\n",
        "    return energy, forces, stress\n",
        "\n",
        "# df = pd.DataFrame(mdata)\n",
        "df = pd.DataFrame(\n",
        "    json.loads(\n",
        "        zipfile.ZipFile(\"mlearn.json.zip\").read(\n",
        "            \"mlearn.json\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "print(df)\n",
        "for i in glob.glob(\"../../benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "    if \"mlearn\" in i and \"Cu\" in i:\n",
        "        fname_e = (\n",
        "            \"AI-MLFF-energy-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-mae.csv\"\n",
        "        )\n",
        "        fname_f = (\n",
        "            \"AI-MLFF-forces-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "        )\n",
        "        fname_s = (\n",
        "            \"AI-MLFF-stresses-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "        )\n",
        "        f_e = open(fname_e, \"w\")\n",
        "        f_f = open(fname_f, \"w\")\n",
        "        f_s = open(fname_s, \"w\")\n",
        "\n",
        "        f_e.write(\"id,prediction\\n\")\n",
        "        f_f.write(\"id,prediction\\n\")\n",
        "        f_s.write(\"id,prediction\\n\")\n",
        "\n",
        "        print(i)\n",
        "        dat = json.loads(\n",
        "            zipfile.ZipFile(i).read(i.split(\"/\")[-1].split(\".zip\")[0])\n",
        "        )\n",
        "        print(dat[\"test\"])\n",
        "        for key, val in dat[\"test\"].items():\n",
        "            entry = df[df[\"jid\"] == key]\n",
        "            atoms = Atoms.from_dict(entry.atoms.values[0])\n",
        "            # print(key,val,df[df['jid']==key],atoms)\n",
        "            # energy,forces=get_alignn_forces(atoms)\n",
        "            energy, forces, stress = get_alignn_forces(atoms)\n",
        "            print(key, val, energy, atoms.num_atoms)\n",
        "            line = key + \",\" + str(energy) + \"\\n\"\n",
        "            f_e.write(line)\n",
        "            line = (\n",
        "                key\n",
        "                + \",\"\n",
        "                + str(\";\".join(map(str, np.array(forces).flatten())))\n",
        "                + \"\\n\"\n",
        "            )\n",
        "            f_f.write(line)\n",
        "            line = (\n",
        "                key\n",
        "                + \",\"\n",
        "                + str(\";\".join(map(str, np.array(stress).flatten())))\n",
        "                + \"\\n\"\n",
        "            )\n",
        "            f_s.write(line)\n",
        "        f_e.close()\n",
        "        f_f.close()\n",
        "        f_s.close()\n",
        "        zname = fname_e + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_e)\n",
        "\n",
        "        zname = fname_f + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_f)\n",
        "\n",
        "        zname = fname_s + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_s)\n",
        "        # cmd = \"zip \" + fname_e + \".zip \" + fname_e\n",
        "        # os.system(cmd)\n",
        "        # cmd = \"zip \" + fname_f + \".zip \" + fname_f\n",
        "        # os.system(cmd)\n",
        "        # cmd = \"zip \" + fname_s + \".zip \" + fname_s\n",
        "        # os.system(cmd)\n",
        "        # cmd = \"rm \" + fname_e\n",
        "        # os.system(cmd)\n",
        "        # cmd = \"rm \" + fname_f\n",
        "        # os.system(cmd)\n",
        "        # cmd='rm '+fname_s\n",
        "        # os.system(cmd)\n",
        "        # break"
      ],
      "metadata": {
        "id": "_cH9ME5HmybY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/usnistgov/jarvis_leaderboard/main/jarvis_leaderboard/contributions/alignnff_fmult_mlearn_only/metadata.json"
      ],
      "metadata": {
        "id": "Q4WhUkLxsNDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "NR6FotY5sNAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr"
      ],
      "metadata": {
        "id": "hKGDcw4cld6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "4GQo10LHl436"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We added alignnff_cu contribution. This was for a quick test only, so the errors are still high. For better quality model, train longer epochs with high capacity models."
      ],
      "metadata": {
        "id": "EEhGK5kDmtST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis_leaderboard.rebuild import get_metric_value,get_results\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "names,vals=get_results(bench_name='AI-MLFF-forces-mlearn_Cu-test-multimae.csv.zip')\n",
        "plt.bar(np.arange(len(vals)),vals,color=(0.2, 0.4, 0.6, 0.6),edgecolor='blue')\n",
        "plt.xticks(np.arange(len(vals)),names,rotation=90)\n",
        "plt.ylabel('MAE (eV/A)')"
      ],
      "metadata": {
        "id": "KJLhrks2l9gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_forces = get_metric_value(csv_path='/content/jarvis_leaderboard/jarvis_leaderboard/contributions/alignnff_cu/AI-MLFF-forces-mlearn_Cu-test-multimae.csv.zip')\n",
        "res_energy = get_metric_value(csv_path='/content/jarvis_leaderboard/jarvis_leaderboard/contributions/alignnff_cu/AI-MLFF-energy-mlearn_Cu-test-mae.csv.zip')\n",
        "res_stress = get_metric_value(csv_path='/content/jarvis_leaderboard/jarvis_leaderboard/contributions/alignnff_cu/AI-MLFF-stresses-mlearn_Cu-test-multimae.csv.zip')"
      ],
      "metadata": {
        "id": "a3w4aYKelaum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.concatenate(\n",
        "  [\n",
        "      np.array(i.split(\";\"), dtype=\"float\")\n",
        "      for i in res_forces[\"df\"][\"prediction\"].values\n",
        "  ]\n",
        ")\n",
        "actual = np.concatenate(\n",
        "  [\n",
        "      np.array(i.split(\";\"), dtype=\"float\")\n",
        "      for i in res_forces[\"df\"][\"actual\"].values\n",
        "  ]\n",
        ")\n",
        "print(\"MAE F\", mean_absolute_error(actual, pred))\n",
        "plt.plot(actual, pred, \".\")\n",
        "plt.xlabel('DFT forces (eV/A)')\n",
        "plt.ylabel('FF forces (eV/A)')\n"
      ],
      "metadata": {
        "id": "yX23DFfAlbWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjust stress_wt\n",
        "pred = np.concatenate(\n",
        "  [\n",
        "      np.array(i.split(\";\"), dtype=\"float\")\n",
        "      for i in res_stress[\"df\"][\"prediction\"].values\n",
        "  ]\n",
        ")\n",
        "actual = np.concatenate(\n",
        "  [\n",
        "      np.array(i.split(\";\"), dtype=\"float\")\n",
        "      for i in res_stress[\"df\"][\"actual\"].values\n",
        "  ]\n",
        ")\n",
        "print(\"MAE F\", mean_absolute_error(actual, pred))\n",
        "plt.plot(actual, pred, \".\")\n",
        "plt.xlabel('DFT stress (kBar)') #TODO: check units of stress in mlearn\n",
        "plt.ylabel('FF stress (kBar)')\n"
      ],
      "metadata": {
        "id": "6sm_V0EilbUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = res_energy[\"df\"][\"actual\"].values\n",
        "pred = res_energy[\"df\"][\"prediction\"].values\n",
        "print(actual, actual.shape)\n",
        "print(pred, pred.shape)\n",
        "print(\"MAE E\", mean_absolute_error(actual, pred))\n",
        "plt.plot(actual, pred, \".\")\n",
        "plt.xlabel('DFT energies (eV/atom)')\n",
        "plt.ylabel('FF energies (eV/atom)')\n"
      ],
      "metadata": {
        "id": "pUzktFsvmVGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOprnsvCmVDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cx5MVzHOmVBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"xyz\"\n",
        "email = \"abc@gmail.com\"\n",
        "passwd = #\"ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
      ],
      "metadata": {
        "id": "inHoFBEKmU-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Osmium phonon\n",
        "from alignn.ff.ff import phonons\n",
        "from jarvis.core.atoms import ase_to_atoms\n",
        "from jarvis.db.figshare import get_jid_data\n",
        "from jarvis.core.atoms import Atoms\n",
        "from alignn.ff.ff import AlignnAtomwiseCalculator,default_path,wt10_path,alignnff_fmult,fd_path,ForceField\n",
        "atoms=Atoms.from_dict(get_jid_data(jid='JVASP-952',dataset='dft_3d')['atoms'])\n",
        "ph_path=fd_path()\n",
        "ph=phonons(model_path=ph_path,atoms=(atoms))\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W2zxpWQftXvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ce=\"\"\"Ce\n",
        "1.0\n",
        "2.883577080372866 -0.0 1.6648337892833467\n",
        "0.9611923601242888 2.7186624460117796 1.6648337892833467\n",
        "0.0 -0.0 3.3296675785666934\n",
        "Ce\n",
        "1\n",
        "Cartesian\n",
        "0.0 0.0 0.0\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YL1_EAc7tXtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.io.vasp.inputs import Poscar\n",
        "pos = Poscar.from_string(Ce)"
      ],
      "metadata": {
        "id": "1QDwNl-5tXrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ph=phonons(model_path=ph_path,atoms=(pos.atoms))\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6tTFmU3WDzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "7aPp-8e4pQ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnsmfvOepjVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJS2zJK8p1Um"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}