{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/AGRA_ALIGNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AGRA Dataset traininig with ALIGNN model"
      ],
      "metadata": {
        "id": "ULjv0aYI_rqe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf_DWV9FVjo2",
        "outputId": "6231f719-f5a9-4f46-e668-47c5544b0ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.8/240.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "confection 0.1.1 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.1 which is incompatible.\n",
            "spacy 3.6.1 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\n",
            "thinc 8.1.12 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q dgl==1.0.1+cu117 -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install -q alignn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('AGRA'):\n",
        "  !git clone https://github.com/Feugmo-Group/AGRA.git\n",
        "os.chdir('AGRA')\n",
        "# !pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbnGyvcuVtaP",
        "outputId": "4a70909a-9010-4068-c6c1-c54ad2f0a6ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AGRA'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 87 (delta 13), reused 16 (delta 7), pack-reused 56\u001b[K\n",
            "Receiving objects: 100% (87/87), 4.03 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FdSS-fPV_oI",
        "outputId": "7b75672a-497c-4b0b-9bd7-dceaa71be213"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CO2RR.db  Dataset_generator.ipynb  ORR.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip O_small_full.zip"
      ],
      "metadata": {
        "id": "8Pya5P3iWEfW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr O_small_full|wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kafbFC2cXE3M",
        "outputId": "cd8428b6-fbb3-4c3b-9d2b-8fb99aef14a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'O_small_full': No such file or directory\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ase db data/ORR.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6IvEffaWihL",
        "outputId": "574295ab-c95e-444a-a57f-a36f88ccb6e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id|age|user     |formula          |calculator|  energy|natoms| fmax|pbc| volume|charge|    mass|magmom\n",
            " 1|18M|tetsassic|Ir2PdPt6Rh2Ru5HO |gpaw      |-114.176|    18|0.034|TTF|576.730| 0.000|2389.526| 0.000\n",
            " 2|18M|tetsassic|Ir2PdPt6Rh2Ru5O  |gpaw      |-110.614|    17|0.044|TTF|576.730| 0.000|2388.518| 0.000\n",
            " 3|18M|tetsassic|Ir5Pd2Pt4Rh4RuHO |gpaw      |-110.122|    18|0.047|TTF|576.730| 0.000|2483.960| 0.000\n",
            " 4|18M|tetsassic|Ir5Pd2Pt4Rh4RuO  |gpaw      |-106.481|    17|0.045|TTF|576.730| 0.000|2482.952| 0.000\n",
            " 5|18M|tetsassic|Ir3Pd5Pt2Rh3Ru3HO|gpaw      |-102.409|    18|0.040|TTF|576.730| 0.000|2127.852| 0.000\n",
            " 6|18M|tetsassic|Ir3Pd5Pt2Rh3Ru3O |gpaw      | -98.793|    17|0.043|TTF|576.730| 0.000|2126.844| 0.000\n",
            " 7|18M|tetsassic|Ir7Pd2Pt3Rh4HO   |gpaw      |-112.026|    18|0.034|TTF|576.730| 0.000|2572.240| 0.000\n",
            " 8|18M|tetsassic|Ir7Pd2Pt3Rh4O    |gpaw      |-108.373|    17|0.046|TTF|576.730| 0.000|2571.232| 0.000\n",
            " 9|18M|tetsassic|Ir3Pd4Pt3Rh3Ru3HO|gpaw      |-103.409|    18|0.037|TTF|576.730| 0.000|2216.516| 0.000\n",
            "10|18M|tetsassic|Ir3Pd4Pt3Rh3Ru3O |gpaw      | -99.777|    17|0.045|TTF|576.730| 0.000|2215.508| 0.000\n",
            "11|18M|tetsassic|Ir3Pd4Pt5RhRu3HO |gpaw      |-101.485|    18|0.040|TTF|576.730| 0.000|2400.873| 0.000\n",
            "12|18M|tetsassic|Ir3Pd4Pt5RhRu3O  |gpaw      | -98.080|    17|0.049|TTF|576.730| 0.000|2399.865| 0.000\n",
            "13|18M|tetsassic|Ir3Pd4Pt3Rh3Ru3HO|gpaw      |-103.310|    18|0.040|TTF|576.730| 0.000|2216.516| 0.000\n",
            "14|18M|tetsassic|Ir3Pd4Pt3Rh3Ru3O |gpaw      | -99.456|    17|0.049|TTF|576.730| 0.000|2215.508| 0.000\n",
            "15|18M|tetsassic|Ir2Pd3Pt3Rh5Ru3HO|gpaw      |-104.476|    18|0.043|TTF|576.730| 0.000|2123.690| 0.000\n",
            "16|18M|tetsassic|Ir2Pd3Pt3Rh5Ru3O |gpaw      |-100.474|    17|0.024|TTF|576.730| 0.000|2122.682| 0.000\n",
            "17|18M|tetsassic|Ir2Pd5PtRh3Ru5HO |gpaw      |-102.923|    18|0.046|TTF|576.730| 0.000|1942.692| 0.000\n",
            "18|18M|tetsassic|Ir2Pd5PtRh3Ru5O  |gpaw      | -99.597|    17|0.041|TTF|576.730| 0.000|1941.684| 0.000\n",
            "19|18M|tetsassic|Ir4Pd4Pt2Rh3Ru3HO|gpaw      |-107.264|    18|0.032|TTF|576.730| 0.000|2213.649| 0.000\n",
            "20|18M|tetsassic|Ir4Pd4Pt2Rh3Ru3O |gpaw      |-103.779|    17|0.024|TTF|576.730| 0.000|2212.641| 0.000\n",
            "Rows: 1877 (showing first 20)\n",
            "Keys: ads_energy, adsorbate, slabId\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ase db data/CO2RR.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjtvWHIyWxD1",
        "outputId": "a18e5e70-5ea3-4452-edfa-09720b413401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id|age|user|formula              |natoms|pbc|  volume|charge|    mass\n",
            " 1|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 2|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 3|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 4|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 5|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 6|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 7|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 8|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 9|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "10|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "11|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "12|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "13|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "14|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "15|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "16|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "17|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "18|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "19|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "20|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "Rows: 710 (showing first 20)\n",
            "Keys: Ads_site_id_vesta, Adsorbate, Energy, Hea_ID, Relaxed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ase db CO2RR/CO2RR_database.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKoaNwm7Xjyk",
        "outputId": "d22f4e0c-1d01-42c7-924c-63d851c4996b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id|age|user|formula              |natoms|pbc|  volume|charge|    mass\n",
            " 1|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 2|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 3|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 4|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 5|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 6|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 7|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 8|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            " 9|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "10|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "11|18M|zach|Co7Cu14Fe19Mo8Ni16CO |    66|TTT|2998.447| 0.000|4097.936\n",
            "12|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "13|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "14|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "15|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "16|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "17|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "18|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "19|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "20|18M|zach|Co10Cu19Fe20Mo4Ni11CO|    66|TTT|2998.447| 0.000|3971.043\n",
            "Rows: 710 (showing first 20)\n",
            "Keys: Ads_site_id_vesta, Adsorbate, Energy, Hea_ID, Relaxed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ase.db import connect\n",
        "from jarvis.core.atoms import ase_to_atoms\n",
        "db_O = connect(\"data/ORR.db\")\n",
        "\n",
        "mem_O=[]\n",
        "mem_OH=[]\n",
        "count=0\n",
        "for row in db_O.select():\n",
        "  count+=1\n",
        "  id='agra_ORR_'+str(count)\n",
        "  atoms = ase_to_atoms(row.toatoms())\n",
        "  ead = row.ads_energy\n",
        "  energy = row.energy\n",
        "  adsb = row.adsorbate\n",
        "  info={}\n",
        "  info['id']=id\n",
        "  info['atoms']=atoms.to_dict()\n",
        "  info['ead']=ead\n",
        "  info['energy']=energy\n",
        "  if adsb=='OH':\n",
        "    mem_OH.append(info)\n",
        "  if adsb=='O':\n",
        "    mem_O.append(info)\n",
        "\n",
        "    # print(count,adsb)\n",
        "\n",
        "  #break"
      ],
      "metadata": {
        "id": "sqiiwngGXvSR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mem_O),len(mem_OH),len(db_O)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEY6hSqockLo",
        "outputId": "9a71d233-d578-41ba-d745-8cb0f23de86e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 877, 1877)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ase.db import connect\n",
        "from jarvis.core.atoms import ase_to_atoms\n",
        "db_CO2 = connect(\"data/CO2RR.db\")\n",
        "\n",
        "mem_CO=[]\n",
        "mem_CHO=[]\n",
        "mem_COOH=[]\n",
        "count=0\n",
        "for row in db_CO2.select():\n",
        "  count+=1\n",
        "  atoms = ase_to_atoms(row.toatoms())\n",
        "  ead = row.Energy\n",
        "  adsb = row.Adsorbate\n",
        "  # print(adsb)\n",
        "  id='agra_CO2RR_'+str(count)\n",
        "  info={}\n",
        "  info['id']=id\n",
        "  info['atoms']=atoms.to_dict()\n",
        "  info['ead']=ead\n",
        "  info['energy']=energy\n",
        "  if adsb=='CO':\n",
        "    mem_CO.append(info)\n",
        "  if adsb=='CHO':\n",
        "    mem_CHO.append(info)\n",
        "  if adsb=='COOH':\n",
        "    mem_COOH.append(info)\n",
        "  #break"
      ],
      "metadata": {
        "id": "IT_JbgEMYC72"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mem_CO),len(mem_CHO),len(mem_COOH),len(db_CO2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFuXOXyrZfd1",
        "outputId": "eb1eee6e-eff6-4e24-f490-737f404d504a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194, 216, 280, 710)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=mem_O,filename='AGRA_O.json')\n",
        "dumpjson(data=mem_OH,filename='AGRA_OH.json')\n",
        "dumpjson(data=mem_CO,filename='AGRA_CO.json')\n",
        "dumpjson(data=mem_CHO,filename='AGRA_CHO.json')\n",
        "dumpjson(data=mem_COOH,filename='AGRA_COOH.json')"
      ],
      "metadata": {
        "id": "ASnKv5IeYGxe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_O.json.zip AGRA_O.json\n",
        "!zip AGRA_OH.json.zip AGRA_OH.json\n",
        "!zip AGRA_CO.json.zip AGRA_CO.json\n",
        "!zip AGRA_CHO.json.zip AGRA_CHO.json\n",
        "!zip AGRA_COOH.json.zip AGRA_COOH.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiRcqfHXYfhE",
        "outputId": "5ca08ce0-5977-4ac0-fe67-51e73dbb430a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_O.json (deflated 78%)\n",
            "  adding: AGRA_OH.json (deflated 77%)\n",
            "  adding: AGRA_CO.json (deflated 78%)\n",
            "  adding: AGRA_CHO.json (deflated 79%)\n",
            "  adding: AGRA_COOH.json (deflated 79%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from jarvis.db.figshare import data\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "dfO=pd.DataFrame(mem_O)\n",
        "plt.hist(dfO['ead'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qXr7BqK1Y1xA",
        "outputId": "048d6b12-63a6-4d72-e3cb-c1daa13629ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from jarvis.db.figshare import data\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "dfO=pd.DataFrame(mem_OH)\n",
        "plt.hist(dfO['ead'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "XA9mpldCY7f1",
        "outputId": "219dd6bb-ade8-4568-c0d3-1026b892575b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from jarvis.db.figshare import data\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "dfO=pd.DataFrame(mem_CO)\n",
        "plt.hist(dfO['ead'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qhKpMQm1ZB3w",
        "outputId": "210b56d7-43fa-4edc-8bf6-8e135a0dade1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from jarvis.db.figshare import data\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "dfO=pd.DataFrame(mem_CHO)\n",
        "plt.hist(dfO['ead'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "O_0-un7tZJHn",
        "outputId": "f973956c-b073-41e0-f860-67bc5f178b88"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from jarvis.db.figshare import data\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "dfO=pd.DataFrame(mem_COOH)\n",
        "plt.hist(dfO['ead'],bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "M1AjJj00i748",
        "outputId": "3a03ad6c-a7b2-40f2-91f3-67731a8548ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.core.atoms import Atoms\n",
        "os.chdir('/content')\n",
        "\n",
        "if not os.path.exists('DataDir_O'):\n",
        "  os.makedirs('DataDir_O')\n",
        "os.chdir('DataDir_O')\n",
        "f=open('id_prop.csv','w')\n",
        "for i in mem_O:\n",
        "  line=i['id']+','+str(i['ead'])+'\\n'\n",
        "  f.write(line)\n",
        "  atoms=Atoms.from_dict(i['atoms'])\n",
        "  fname=i['id']\n",
        "  atoms.write_poscar(fname)\n",
        "f.close()\n",
        "os.chdir('/content')\n",
        "\n",
        "\n",
        "if not os.path.exists('DataDir_OH'):\n",
        "  os.makedirs('DataDir_OH')\n",
        "os.chdir('DataDir_OH')\n",
        "f=open('id_prop.csv','w')\n",
        "for i in mem_OH:\n",
        "  line=i['id']+','+str(i['ead'])+'\\n'\n",
        "  f.write(line)\n",
        "  atoms=Atoms.from_dict(i['atoms'])\n",
        "  fname=i['id']\n",
        "  atoms.write_poscar(fname)\n",
        "f.close()\n",
        "os.chdir('/content')\n",
        "\n",
        "\n",
        "if not os.path.exists('DataDir_CO'):\n",
        "  os.makedirs('DataDir_CO')\n",
        "os.chdir('DataDir_CO')\n",
        "f=open('id_prop.csv','w')\n",
        "for i in mem_CO:\n",
        "  line=i['id']+','+str(i['ead'])+'\\n'\n",
        "  f.write(line)\n",
        "  atoms=Atoms.from_dict(i['atoms'])\n",
        "  fname=i['id']\n",
        "  atoms.write_poscar(fname)\n",
        "f.close()\n",
        "os.chdir('/content')\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists('DataDir_CHO'):\n",
        "  os.makedirs('DataDir_CHO')\n",
        "os.chdir('DataDir_CHO')\n",
        "f=open('id_prop.csv','w')\n",
        "for i in mem_CHO:\n",
        "  line=i['id']+','+str(i['ead'])+'\\n'\n",
        "  f.write(line)\n",
        "  atoms=Atoms.from_dict(i['atoms'])\n",
        "  fname=i['id']\n",
        "  atoms.write_poscar(fname)\n",
        "f.close()\n",
        "os.chdir('/content')\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists('DataDir_COOH'):\n",
        "  os.makedirs('DataDir_COOH')\n",
        "os.chdir('DataDir_COOH')\n",
        "f=open('id_prop.csv','w')\n",
        "for i in mem_COOH:\n",
        "  line=i['id']+','+str(i['ead'])+'\\n'\n",
        "  f.write(line)\n",
        "  atoms=Atoms.from_dict(i['atoms'])\n",
        "  fname=i['id']\n",
        "  atoms.write_poscar(fname)\n",
        "f.close()\n",
        "os.chdir('/content')\n"
      ],
      "metadata": {
        "id": "-UWTQlXZi-ob"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/usnistgov/alignn/main/alignn/examples/sample_data/config_example.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3_EEfjulHIb",
        "outputId": "c6542e2d-819a-48e9-bd7a-2e11e35a6296"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-20 01:34:23--  https://raw.githubusercontent.com/usnistgov/alignn/main/alignn/examples/sample_data/config_example.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1411 (1.4K) [text/plain]\n",
            "Saving to: ‘config_example.json’\n",
            "\n",
            "config_example.json 100%[===================>]   1.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-20 01:34:24 (20.7 MB/s) - ‘config_example.json’ saved [1411/1411]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "config = loadjson('config_example.json')\n",
        "config['epochs'] = 200\n",
        "config['batch_size'] = 10\n",
        "\n",
        "\n",
        "dumpjson(data=config,filename='tmp_config.json')"
      ],
      "metadata": {
        "id": "_dYiOc8SlNsJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder.py --root_dir \"DataDir_O\" --config \"tmp_config.json\" --output_dir=\"temp_O\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRnwA3ltl2-T",
        "outputId": "7455db87-ac6b-46a3-a312-e6c8dc1f3522"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: 2.099618381007815\n",
            "MIN val: -0.41205071554003325\n",
            "MAD: 0.36789281040730787\n",
            "Baseline MAE: 0.36015267427192815\n",
            "data range 2.099618381007815 -0.41205071554003325\n",
            "100% 800/800 [00:28<00:00, 28.17it/s]\n",
            "df                                                  atoms  ...    target\n",
            "0    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.463775\n",
            "1    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.994273\n",
            "2    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.550223\n",
            "3    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.757501\n",
            "4    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.582040\n",
            "..                                                 ...  ...       ...\n",
            "795  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.443408\n",
            "796  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.134781\n",
            "797  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.869365\n",
            "798  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.658396\n",
            "799  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.052856\n",
            "\n",
            "[800 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 800/800 [00:00<00:00, 1321.83it/s]\n",
            "data range 2.057619009790187 -0.02318907245805235\n",
            "100% 100/100 [00:02<00:00, 45.57it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.928692\n",
            "1   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.919245\n",
            "2   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.844919\n",
            "3   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.805616\n",
            "4   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.424416\n",
            "..                                                ...  ...       ...\n",
            "95  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.395490\n",
            "96  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.241394\n",
            "97  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.440857\n",
            "98  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.472492\n",
            "99  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.433096\n",
            "\n",
            "[100 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 100/100 [00:00<00:00, 1448.78it/s]\n",
            "data range 1.977216059723446 -0.3602338110298007\n",
            "100% 100/100 [00:04<00:00, 24.68it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.737484\n",
            "1   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.740086\n",
            "2   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ... -0.004509\n",
            "3   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.185751\n",
            "4   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.363967\n",
            "..                                                ...  ...       ...\n",
            "95  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.758942\n",
            "96  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.936680\n",
            "97  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.638872\n",
            "98  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.590440\n",
            "99  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.706646\n",
            "\n",
            "[100 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 100/100 [00:00<00:00, 879.14it/s]\n",
            "n_train: 800\n",
            "n_val  : 100\n",
            "n_test : 100\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=10 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='temp_O' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_O',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 0.1482\n",
            "Train_MAE: 0.1337\n",
            "Val_MAE: 0.1008\n",
            "Train_MAE: 0.0985\n",
            "Val_MAE: 0.0964\n",
            "Train_MAE: 0.1015\n",
            "Val_MAE: 0.0848\n",
            "Train_MAE: 0.0713\n",
            "Val_MAE: 0.0861\n",
            "Train_MAE: 0.0693\n",
            "Val_MAE: 0.0928\n",
            "Train_MAE: 0.0837\n",
            "Val_MAE: 0.1237\n",
            "Train_MAE: 0.1254\n",
            "Val_MAE: 0.0929\n",
            "Train_MAE: 0.0943\n",
            "Val_MAE: 0.0780\n",
            "Train_MAE: 0.0757\n",
            "Val_MAE: 0.0845\n",
            "Train_MAE: 0.0660\n",
            "Val_MAE: 0.0904\n",
            "Train_MAE: 0.0849\n",
            "Val_MAE: 0.1145\n",
            "Train_MAE: 0.0906\n",
            "Val_MAE: 0.0678\n",
            "Train_MAE: 0.0617\n",
            "Val_MAE: 0.0722\n",
            "Train_MAE: 0.0606\n",
            "Val_MAE: 0.1633\n",
            "Train_MAE: 0.1542\n",
            "Val_MAE: 0.1147\n",
            "Train_MAE: 0.0977\n",
            "Val_MAE: 0.0729\n",
            "Train_MAE: 0.0558\n",
            "Val_MAE: 0.1082\n",
            "Train_MAE: 0.1047\n",
            "Val_MAE: 0.0829\n",
            "Train_MAE: 0.0713\n",
            "Val_MAE: 0.0667\n",
            "Train_MAE: 0.0538\n",
            "Val_MAE: 0.0754\n",
            "Train_MAE: 0.0665\n",
            "Val_MAE: 0.0704\n",
            "Train_MAE: 0.0791\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0857\n",
            "Val_MAE: 0.0759\n",
            "Train_MAE: 0.0637\n",
            "Val_MAE: 0.1019\n",
            "Train_MAE: 0.0945\n",
            "Val_MAE: 0.0720\n",
            "Train_MAE: 0.0542\n",
            "Val_MAE: 0.0572\n",
            "Train_MAE: 0.0384\n",
            "Val_MAE: 0.1074\n",
            "Train_MAE: 0.0997\n",
            "Val_MAE: 0.0564\n",
            "Train_MAE: 0.0442\n",
            "Val_MAE: 0.0887\n",
            "Train_MAE: 0.0712\n",
            "Val_MAE: 0.2128\n",
            "Train_MAE: 0.2162\n",
            "Val_MAE: 0.0621\n",
            "Train_MAE: 0.0467\n",
            "Val_MAE: 0.1185\n",
            "Train_MAE: 0.1222\n",
            "Val_MAE: 0.0476\n",
            "Train_MAE: 0.0428\n",
            "Val_MAE: 0.0518\n",
            "Train_MAE: 0.0345\n",
            "Val_MAE: 0.0456\n",
            "Train_MAE: 0.0387\n",
            "Val_MAE: 0.0487\n",
            "Train_MAE: 0.0430\n",
            "Val_MAE: 0.0536\n",
            "Train_MAE: 0.0452\n",
            "Val_MAE: 0.0878\n",
            "Train_MAE: 0.0747\n",
            "Val_MAE: 0.0450\n",
            "Train_MAE: 0.0331\n",
            "Val_MAE: 0.0587\n",
            "Train_MAE: 0.0493\n",
            "Val_MAE: 0.0578\n",
            "Train_MAE: 0.0412\n",
            "Val_MAE: 0.1578\n",
            "Train_MAE: 0.1611\n",
            "Val_MAE: 0.0775\n",
            "Train_MAE: 0.0725\n",
            "Val_MAE: 0.0638\n",
            "Train_MAE: 0.0487\n",
            "Val_MAE: 0.1028\n",
            "Train_MAE: 0.0989\n",
            "Val_MAE: 0.0899\n",
            "Train_MAE: 0.0862\n",
            "Val_MAE: 0.0454\n",
            "Train_MAE: 0.0331\n",
            "Val_MAE: 0.0456\n",
            "Train_MAE: 0.0293\n",
            "Val_MAE: 0.1355\n",
            "Train_MAE: 0.1337\n",
            "Val_MAE: 0.0620\n",
            "Train_MAE: 0.0566\n",
            "Val_MAE: 0.0719\n",
            "Train_MAE: 0.0592\n",
            "Val_MAE: 0.0823\n",
            "Train_MAE: 0.0734\n",
            "Val_MAE: 0.0659\n",
            "Train_MAE: 0.0622\n",
            "Val_MAE: 0.0635\n",
            "Train_MAE: 0.0456\n",
            "Val_MAE: 0.0519\n",
            "Train_MAE: 0.0403\n",
            "Val_MAE: 0.0738\n",
            "Train_MAE: 0.0716\n",
            "Val_MAE: 0.0454\n",
            "Train_MAE: 0.0338\n",
            "Val_MAE: 0.0554\n",
            "Train_MAE: 0.0392\n",
            "Val_MAE: 0.0754\n",
            "Train_MAE: 0.0775\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0474\n",
            "Val_MAE: 0.0570\n",
            "Train_MAE: 0.0384\n",
            "Val_MAE: 0.0785\n",
            "Train_MAE: 0.0783\n",
            "Val_MAE: 0.0428\n",
            "Train_MAE: 0.0296\n",
            "Val_MAE: 0.0483\n",
            "Train_MAE: 0.0348\n",
            "Val_MAE: 0.0679\n",
            "Train_MAE: 0.0682\n",
            "Val_MAE: 0.0530\n",
            "Train_MAE: 0.0424\n",
            "Val_MAE: 0.0457\n",
            "Train_MAE: 0.0277\n",
            "Val_MAE: 0.0786\n",
            "Train_MAE: 0.0810\n",
            "Val_MAE: 0.0614\n",
            "Train_MAE: 0.0531\n",
            "Val_MAE: 0.1412\n",
            "Train_MAE: 0.1351\n",
            "Val_MAE: 0.0456\n",
            "Train_MAE: 0.0320\n",
            "Val_MAE: 0.0833\n",
            "Train_MAE: 0.0683\n",
            "Val_MAE: 0.0733\n",
            "Train_MAE: 0.0635\n",
            "Val_MAE: 0.0674\n",
            "Train_MAE: 0.0587\n",
            "Val_MAE: 0.0521\n",
            "Train_MAE: 0.0348\n",
            "Val_MAE: 0.0772\n",
            "Train_MAE: 0.0708\n",
            "Val_MAE: 0.0555\n",
            "Train_MAE: 0.0527\n",
            "Val_MAE: 0.0518\n",
            "Train_MAE: 0.0420\n",
            "Val_MAE: 0.0522\n",
            "Train_MAE: 0.0372\n",
            "Val_MAE: 0.0377\n",
            "Train_MAE: 0.0239\n",
            "Val_MAE: 0.0417\n",
            "Train_MAE: 0.0222\n",
            "Val_MAE: 0.0546\n",
            "Train_MAE: 0.0489\n",
            "Val_MAE: 0.1058\n",
            "Train_MAE: 0.1011\n",
            "Val_MAE: 0.0475\n",
            "Train_MAE: 0.0377\n",
            "Val_MAE: 0.0545\n",
            "Train_MAE: 0.0511\n",
            "Val_MAE: 0.0908\n",
            "Train_MAE: 0.0879\n",
            "Val_MAE: 0.0440\n",
            "Train_MAE: 0.0313\n",
            "Val_MAE: 0.0440\n",
            "Train_MAE: 0.0230\n",
            "Val_MAE: 0.0387\n",
            "Train_MAE: 0.0199\n",
            "Val_MAE: 0.0406\n",
            "Train_MAE: 0.0273\n",
            "Val_MAE: 0.0434\n",
            "Train_MAE: 0.0294\n",
            "Val_MAE: 0.0523\n",
            "Train_MAE: 0.0314\n",
            "Val_MAE: 0.1287\n",
            "Train_MAE: 0.1247\n",
            "Val_MAE: 0.0740\n",
            "Train_MAE: 0.0745\n",
            "Val_MAE: 0.0495\n",
            "Train_MAE: 0.0295\n",
            "Val_MAE: 0.0475\n",
            "Train_MAE: 0.0282\n",
            "Val_MAE: 0.0518\n",
            "Train_MAE: 0.0379\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0920\n",
            "Val_MAE: 0.0432\n",
            "Train_MAE: 0.0195\n",
            "Val_MAE: 0.0538\n",
            "Train_MAE: 0.0510\n",
            "Val_MAE: 0.0435\n",
            "Train_MAE: 0.0299\n",
            "Val_MAE: 0.0562\n",
            "Train_MAE: 0.0496\n",
            "Val_MAE: 0.0405\n",
            "Train_MAE: 0.0200\n",
            "Val_MAE: 0.0411\n",
            "Train_MAE: 0.0258\n",
            "Val_MAE: 0.0531\n",
            "Train_MAE: 0.0461\n",
            "Val_MAE: 0.0418\n",
            "Train_MAE: 0.0211\n",
            "Val_MAE: 0.0548\n",
            "Train_MAE: 0.0408\n",
            "Val_MAE: 0.0400\n",
            "Train_MAE: 0.0254\n",
            "Val_MAE: 0.0481\n",
            "Train_MAE: 0.0409\n",
            "Val_MAE: 0.0397\n",
            "Train_MAE: 0.0232\n",
            "Val_MAE: 0.0451\n",
            "Train_MAE: 0.0226\n",
            "Val_MAE: 0.0586\n",
            "Train_MAE: 0.0507\n",
            "Val_MAE: 0.0428\n",
            "Train_MAE: 0.0211\n",
            "Val_MAE: 0.0474\n",
            "Train_MAE: 0.0373\n",
            "Val_MAE: 0.0402\n",
            "Train_MAE: 0.0178\n",
            "Val_MAE: 0.0717\n",
            "Train_MAE: 0.0656\n",
            "Val_MAE: 0.0420\n",
            "Train_MAE: 0.0282\n",
            "Val_MAE: 0.0398\n",
            "Train_MAE: 0.0242\n",
            "Val_MAE: 0.0599\n",
            "Train_MAE: 0.0560\n",
            "Val_MAE: 0.0430\n",
            "Train_MAE: 0.0181\n",
            "Val_MAE: 0.0582\n",
            "Train_MAE: 0.0530\n",
            "Val_MAE: 0.0725\n",
            "Train_MAE: 0.0675\n",
            "Val_MAE: 0.0425\n",
            "Train_MAE: 0.0285\n",
            "Val_MAE: 0.0353\n",
            "Train_MAE: 0.0124\n",
            "Val_MAE: 0.0451\n",
            "Train_MAE: 0.0272\n",
            "Val_MAE: 0.0433\n",
            "Train_MAE: 0.0183\n",
            "Val_MAE: 0.0519\n",
            "Train_MAE: 0.0445\n",
            "Val_MAE: 0.0474\n",
            "Train_MAE: 0.0369\n",
            "Val_MAE: 0.0443\n",
            "Train_MAE: 0.0312\n",
            "Val_MAE: 0.0485\n",
            "Train_MAE: 0.0309\n",
            "Val_MAE: 0.0484\n",
            "Train_MAE: 0.0379\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0131\n",
            "Val_MAE: 0.0396\n",
            "Train_MAE: 0.0165\n",
            "Val_MAE: 0.0608\n",
            "Train_MAE: 0.0535\n",
            "Val_MAE: 0.0592\n",
            "Train_MAE: 0.0528\n",
            "Val_MAE: 0.0393\n",
            "Train_MAE: 0.0213\n",
            "Val_MAE: 0.0393\n",
            "Train_MAE: 0.0150\n",
            "Val_MAE: 0.0460\n",
            "Train_MAE: 0.0303\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0136\n",
            "Val_MAE: 0.0553\n",
            "Train_MAE: 0.0505\n",
            "Val_MAE: 0.0392\n",
            "Train_MAE: 0.0222\n",
            "Val_MAE: 0.0349\n",
            "Train_MAE: 0.0126\n",
            "Val_MAE: 0.0469\n",
            "Train_MAE: 0.0321\n",
            "Val_MAE: 0.0462\n",
            "Train_MAE: 0.0340\n",
            "Val_MAE: 0.0420\n",
            "Train_MAE: 0.0191\n",
            "Val_MAE: 0.0437\n",
            "Train_MAE: 0.0186\n",
            "Val_MAE: 0.0371\n",
            "Train_MAE: 0.0080\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0112\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0184\n",
            "Val_MAE: 0.0375\n",
            "Train_MAE: 0.0074\n",
            "Val_MAE: 0.0378\n",
            "Train_MAE: 0.0131\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0076\n",
            "Val_MAE: 0.0380\n",
            "Train_MAE: 0.0075\n",
            "Val_MAE: 0.0419\n",
            "Train_MAE: 0.0205\n",
            "Val_MAE: 0.0392\n",
            "Train_MAE: 0.0119\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0149\n",
            "Val_MAE: 0.0364\n",
            "Train_MAE: 0.0098\n",
            "Val_MAE: 0.0380\n",
            "Train_MAE: 0.0083\n",
            "Val_MAE: 0.0374\n",
            "Train_MAE: 0.0054\n",
            "Val_MAE: 0.0395\n",
            "Train_MAE: 0.0140\n",
            "Val_MAE: 0.0374\n",
            "Train_MAE: 0.0081\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0062\n",
            "Val_MAE: 0.0402\n",
            "Train_MAE: 0.0115\n",
            "Val_MAE: 0.0377\n",
            "Train_MAE: 0.0071\n",
            "Val_MAE: 0.0384\n",
            "Train_MAE: 0.0097\n",
            "Val_MAE: 0.0419\n",
            "Train_MAE: 0.0169\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0047\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0044\n",
            "Val_MAE: 0.0369\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0392\n",
            "Train_MAE: 0.0120\n",
            "Val_MAE: 0.0379\n",
            "Train_MAE: 0.0070\n",
            "Val_MAE: 0.0390\n",
            "Train_MAE: 0.0064\n",
            "Val_MAE: 0.0386\n",
            "Train_MAE: 0.0099\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0055\n",
            "Val_MAE: 0.0400\n",
            "Train_MAE: 0.0122\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0082\n",
            "Val_MAE: 0.0375\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0380\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0078\n",
            "Val_MAE: 0.0389\n",
            "Train_MAE: 0.0057\n",
            "Val_MAE: 0.0380\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0377\n",
            "Train_MAE: 0.0044\n",
            "Val_MAE: 0.0386\n",
            "Train_MAE: 0.0066\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0053\n",
            "Val_MAE: 0.0385\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0049\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0056\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0052\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0041\n",
            "Val_MAE: 0.0379\n",
            "Train_MAE: 0.0037\n",
            "Val_MAE: 0.0380\n",
            "Train_MAE: 0.0044\n",
            "Val_MAE: 0.0378\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0379\n",
            "Train_MAE: 0.0043\n",
            "Val_MAE: 0.0379\n",
            "Train_MAE: 0.0040\n",
            "Val_MAE: 0.0379\n",
            "Train_MAE: 0.0050\n",
            "Val_MAE: 0.0378\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0378\n",
            "Train_MAE: 0.0046\n",
            "Test MAE: 0.035890071406029164\n",
            "Time taken (s): 1790.3465316295624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXpgoNTUU47l",
        "outputId": "8c6c88f2-687e-4134-8edb-6edce0b818f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 140\n",
            "drwxr-xr-x 4 root root  4096 Aug 17 13:28 .config\n",
            "drwxr-xr-x 1 root root  4096 Aug 17 13:29 sample_data\n",
            "drwxr-xr-x 1 root root  4096 Aug 20 01:31 ..\n",
            "drwxr-xr-x 6 root root  4096 Aug 20 01:34 AGRA\n",
            "drwxr-xr-x 2 root root 36864 Aug 20 01:34 DataDir_O\n",
            "drwxr-xr-x 2 root root 32768 Aug 20 01:34 DataDir_OH\n",
            "drwxr-xr-x 2 root root 12288 Aug 20 01:34 DataDir_CO\n",
            "drwxr-xr-x 2 root root 12288 Aug 20 01:34 DataDir_CHO\n",
            "drwxr-xr-x 2 root root 12288 Aug 20 01:34 DataDir_COOH\n",
            "-rw-r--r-- 1 root root  1411 Aug 20 01:34 config_example.json\n",
            "-rw-r--r-- 1 root root  1157 Aug 20 01:34 tmp_config.json\n",
            "drwxr-xr-x 1 root root  4096 Aug 20 01:34 .\n",
            "drwxr-xr-x 2 root root  4096 Aug 20 02:05 temp_O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls temp_O"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SdqCM0CU9B2",
        "outputId": "6c727c7c-bd19-4f95-9223-c6342aeb3e91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.pt\t    history_val.json\t\t      test_data_data_range\n",
            "checkpoint_199.pt   ids_train_val_test.json\t      train_data_data_range\n",
            "checkpoint_200.pt   mad\t\t\t\t      val_data_data_range\n",
            "config.json\t    prediction_results_test_set.csv\n",
            "history_train.json  prediction_results_train_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.models.alignn import ALIGNN, ALIGNNConfig\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "from alignn.graphs import Graph\n",
        "from jarvis.core.atoms import Atoms\n",
        "import pandas as pd\n",
        "from jarvis.db.figshare import data\n",
        "import torch\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tqdm import tqdm\n",
        "device = \"cpu\"\n",
        "dataset=\"AGRA_O\"\n",
        "id_tag='id'\n",
        "out_dir=\"temp_O\"\n",
        "rootdir = \"DataDir_O\"\n",
        "chkpt=\"temp_O/checkpoint_200.pt\"\n",
        "#chkpt=\"temp_O/best_model.pt\"\n",
        "csv_path=os.path.join(out_dir,\"prediction_results_test_set.csv\")\n",
        "config_path=os.path.join(out_dir,\"config.json\")\n",
        "res_df = pd.read_csv(csv_path)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "dat=pd.DataFrame(data(dataset))\n",
        "pd_merged = pd.merge(dat,res_df,on=id_tag)\n",
        "config=loadjson(config_path)\n",
        "model = ALIGNN(ALIGNNConfig(**config[\"model\"]))\n",
        "model.load_state_dict(torch.load(chkpt, map_location=device)[\"model\"])\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# output_features=1\n",
        "# model = ALIGNN(ALIGNNConfig(name=\"alignn\", output_features=output_features))\n",
        "# model.load_state_dict(torch.load(chkpt, map_location=device)[\"model\"])\n",
        "# model.eval()\n",
        "# model=model.to(device)\n",
        "x=[]\n",
        "y=[]\n",
        "z=[]\n",
        "aa=[]\n",
        "#for i,ii in (res_df.iterrows()):\n",
        "for i,ii in (pd_merged.iterrows()):\n",
        "  id=ii['id']\n",
        "  atoms=Atoms.from_dict(ii['atoms'])\n",
        "  pos_path=os.path.join(rootdir,id)\n",
        "  atoms2=Atoms.from_poscar(pos_path)\n",
        "  aa.append(aa)\n",
        "  g,lg=Graph.atom_dgl_multigraph(atoms,use_canonize=True,cutoff=8.0,neighbor_strategy=\"k-nearest\",max_neighbors=12)\n",
        "  g=g.to(device)\n",
        "  lg=lg.to(device)\n",
        "  pred=model([g,lg]).detach().cpu().numpy().tolist()\n",
        "\n",
        "  g1,lg1=Graph.atom_dgl_multigraph(atoms2,use_canonize=True,cutoff=8.0,neighbor_strategy=\"k-nearest\",max_neighbors=12)\n",
        "  g1=g1.to(device)\n",
        "  lg1=lg1.to(device)\n",
        "  pred2=model([g1,lg1]).detach().cpu().numpy().tolist()\n",
        "  print(id,pred,pred2,ii['prediction'],ii['target'])\n",
        "  x.append(ii['target'])\n",
        "  y.append(ii['prediction'])\n",
        "  z.append(pred)\n",
        "mae_old = mean_absolute_error(x,y)\n",
        "mae_new = mean_absolute_error(x,z)\n",
        "info={}\n",
        "\n",
        "info['len']=len(x)\n",
        "info['mae_old']=mae_old\n",
        "info['mae_new']=mae_new\n",
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuQ_oTt7VFwa",
        "outputId": "b1576ab6-c213-4517-c0b5-dceff6c487ae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining AGRA Oxygen dataset 1000...\n",
            "Reference:https://github.com/Feugmo-Group/AGRA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312k/312k [00:00<00:00, 435kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agra_ORR_1697 0.6642336845397949 0.6642336845397949 0.664234 0.737484\n",
            "agra_ORR_1699 0.7457066774368286 0.7457066178321838 0.745707 0.740086\n",
            "agra_ORR_1701 -0.006018240004777908 -0.006018240004777908 -0.006018 -0.004509\n",
            "agra_ORR_1703 1.10946786403656 1.10946786403656 1.109468 1.185751\n",
            "agra_ORR_1704 0.4156441390514374 0.41564419865608215 0.415644 0.363967\n",
            "agra_ORR_1706 0.5905078649520874 0.5905077457427979 0.590508 0.58769\n",
            "agra_ORR_1708 0.7908801436424255 0.7908803224563599 0.79088 0.791909\n",
            "agra_ORR_1710 0.41776761412620544 0.41776761412620544 0.417768 0.415973\n",
            "agra_ORR_1712 0.9043500423431396 0.9043500423431396 0.90435 0.889311\n",
            "agra_ORR_1714 0.5868293046951294 0.5868291258811951 0.586829 0.54608\n",
            "agra_ORR_1716 0.9305287599563599 0.9305285811424255 0.930529 0.945042\n",
            "agra_ORR_1718 0.7714067697525024 0.7714067697525024 0.771407 0.741801\n",
            "agra_ORR_1719 0.7178419232368469 0.7178419828414917 0.717842 0.650819\n",
            "agra_ORR_1721 0.8999948501586914 0.8999947905540466 0.899995 0.905054\n",
            "agra_ORR_1723 0.17331372201442719 0.17331372201442719 0.173314 0.151896\n",
            "agra_ORR_1725 1.026546597480774 1.026546835899353 1.026547 1.03971\n",
            "agra_ORR_1727 0.3433227241039276 0.3433226943016052 0.343323 0.306869\n",
            "agra_ORR_1729 -0.3942868411540985 -0.39428696036338806 -0.394287 -0.360234\n",
            "agra_ORR_1731 0.49219533801078796 0.49219533801078796 0.492195 0.575168\n",
            "agra_ORR_1733 0.8047476410865784 0.8047477006912231 0.804748 0.760261\n",
            "agra_ORR_1734 -0.008016485720872879 -0.008016545325517654 -0.008017 -0.083729\n",
            "agra_ORR_1736 0.11444346606731415 0.1144433468580246 0.114443 0.029329\n",
            "agra_ORR_1738 0.45654913783073425 0.45654913783073425 0.456549 0.364323\n",
            "agra_ORR_1740 0.2638415992259979 0.26384150981903076 0.263842 0.209879\n",
            "agra_ORR_1742 0.4864768087863922 0.4864768087863922 0.486477 0.429443\n",
            "agra_ORR_1744 1.1220942735671997 1.1220945119857788 1.122095 1.149302\n",
            "agra_ORR_1746 1.0678356885910034 1.0678356885910034 1.067836 1.116037\n",
            "agra_ORR_1748 1.0870634317398071 1.0870634317398071 1.087063 1.10383\n",
            "agra_ORR_1750 0.7178195714950562 0.7178195118904114 0.71782 0.705688\n",
            "agra_ORR_1752 1.8788801431655884 1.8788801431655884 1.87888 1.977216\n",
            "agra_ORR_1754 0.6393071413040161 0.6393072009086609 0.639307 0.611989\n",
            "agra_ORR_1756 0.36862510442733765 0.3686250150203705 0.368625 0.416809\n",
            "agra_ORR_1758 0.5882505774497986 0.5882503986358643 0.58825 0.579041\n",
            "agra_ORR_1759 0.47016850113868713 0.47016850113868713 0.470169 0.382663\n",
            "agra_ORR_1760 0.2509829103946686 0.2509829103946686 0.250983 0.184546\n",
            "agra_ORR_1761 1.2957152128219604 1.2957152128219604 1.295715 1.325048\n",
            "agra_ORR_1763 1.110552191734314 1.110552191734314 1.110552 1.152342\n",
            "agra_ORR_1765 0.8684738874435425 0.8684738874435425 0.868474 0.859375\n",
            "agra_ORR_1767 0.7474594712257385 0.7474595308303833 0.74746 0.771861\n",
            "agra_ORR_1769 0.6736321449279785 0.6736321449279785 0.673632 0.689869\n",
            "agra_ORR_1770 0.2343377321958542 0.23433803021907806 0.234338 0.151848\n",
            "agra_ORR_1772 0.7939773797988892 0.7939773797988892 0.793977 0.817462\n",
            "agra_ORR_1773 1.489410161972046 1.489410161972046 1.48941 1.475847\n",
            "agra_ORR_1775 0.3443196713924408 0.34431949257850647 0.344319 0.237104\n",
            "agra_ORR_1777 1.0383377075195312 1.0383375883102417 1.038338 1.075305\n",
            "agra_ORR_1779 1.1336761713027954 1.1336761713027954 1.133676 1.114897\n",
            "agra_ORR_1781 1.1909571886062622 1.1909571886062622 1.190957 1.153316\n",
            "agra_ORR_1783 0.43437492847442627 0.4343748092651367 0.434375 0.408317\n",
            "agra_ORR_1785 1.1829501390457153 1.1829500198364258 1.18295 1.129494\n",
            "agra_ORR_1787 1.3180328607559204 1.3180328607559204 1.318033 1.379172\n",
            "agra_ORR_1789 1.7268606424331665 1.726860523223877 1.726861 1.751249\n",
            "agra_ORR_1791 0.7290724515914917 0.7290722131729126 0.729072 0.709461\n",
            "agra_ORR_1793 0.28375244140625 0.2837524116039276 0.283752 0.291471\n",
            "agra_ORR_1795 0.40872618556022644 0.4087262451648712 0.408726 0.390607\n",
            "agra_ORR_1797 0.18240796029567719 0.1824081391096115 0.182408 0.132479\n",
            "agra_ORR_1799 0.40373867750167847 0.4037386476993561 0.403739 0.36351\n",
            "agra_ORR_1801 0.9191238880157471 0.9191238284111023 0.919124 0.863297\n",
            "agra_ORR_1803 1.2633360624313354 1.2633360624313354 1.263336 1.292304\n",
            "agra_ORR_1805 0.2740427553653717 0.2740428149700165 0.274043 0.237689\n",
            "agra_ORR_1807 0.7095034122467041 0.709503173828125 0.709503 0.71608\n",
            "agra_ORR_1809 0.33766981959342957 0.3376699388027191 0.33767 0.347241\n",
            "agra_ORR_1811 1.6151647567749023 1.6151646375656128 1.615165 1.540674\n",
            "agra_ORR_1813 0.5962299108505249 0.5962299108505249 0.59623 0.683979\n",
            "agra_ORR_1815 0.2935657203197479 0.29356566071510315 0.293566 0.282711\n",
            "agra_ORR_1817 0.6582584381103516 0.658258318901062 0.658258 0.620826\n",
            "agra_ORR_1819 0.4125424921512604 0.41254258155822754 0.412543 0.384082\n",
            "agra_ORR_1821 0.7284857034683228 0.7284858226776123 0.728486 0.694881\n",
            "agra_ORR_1822 0.8740607500076294 0.8740606307983398 0.874061 0.864251\n",
            "agra_ORR_1824 1.844724416732788 1.8447242975234985 1.844724 1.838448\n",
            "agra_ORR_1826 0.24640189111232758 0.24640192091464996 0.246402 0.203819\n",
            "agra_ORR_1828 0.3124483823776245 0.3124482333660126 0.312448 0.287668\n",
            "agra_ORR_1829 0.4537369906902313 0.4537370204925537 0.453737 0.471249\n",
            "agra_ORR_1831 0.7018229365348816 0.7018229365348816 0.701823 0.695662\n",
            "agra_ORR_1833 0.6492310762405396 0.6492308974266052 0.649231 0.611728\n",
            "agra_ORR_1835 0.7276633977890015 0.7276632785797119 0.727663 0.755703\n",
            "agra_ORR_1837 0.5704364776611328 0.5704362392425537 0.570436 0.531223\n",
            "agra_ORR_1838 0.6067394018173218 0.6067394018173218 0.606739 0.602486\n",
            "agra_ORR_1839 0.3546408712863922 0.35464075207710266 0.354641 0.279907\n",
            "agra_ORR_1841 0.7954469919204712 0.7954468727111816 0.795447 0.729415\n",
            "agra_ORR_1842 0.281551718711853 0.2815518081188202 0.281552 0.227188\n",
            "agra_ORR_1844 0.8754167556762695 0.8754166960716248 0.875417 0.919722\n",
            "agra_ORR_1846 0.5457686185836792 0.5457684993743896 0.545768 0.526198\n",
            "agra_ORR_1847 0.41996660828590393 0.4199664294719696 0.419966 0.499019\n",
            "agra_ORR_1849 0.9163510203361511 0.9163510203361511 0.916351 0.892525\n",
            "agra_ORR_1851 0.956703245639801 0.9567031860351562 0.956703 0.909574\n",
            "agra_ORR_1852 0.23294220864772797 0.23294205963611603 0.232942 0.139215\n",
            "agra_ORR_1854 0.2746410667896271 0.27464115619659424 0.274641 0.285773\n",
            "agra_ORR_1856 0.14373956620693207 0.14373941719532013 0.143739 0.117017\n",
            "agra_ORR_1858 0.7286138534545898 0.7286139130592346 0.728614 0.763879\n",
            "agra_ORR_1860 0.19806598126888275 0.19806598126888275 0.198066 0.222109\n",
            "agra_ORR_1861 0.4994346797466278 0.49943479895591736 0.499435 0.501844\n",
            "agra_ORR_1863 1.4311002492904663 1.4311002492904663 1.4311 1.444246\n",
            "agra_ORR_1865 0.3404885530471802 0.34048864245414734 0.340489 0.335675\n",
            "agra_ORR_1867 0.8586493730545044 0.858649492263794 0.858649 0.891403\n",
            "agra_ORR_1869 1.3756132125854492 1.3756130933761597 1.375613 1.345486\n",
            "agra_ORR_1871 0.7843973636627197 0.7843974828720093 0.784397 0.758942\n",
            "agra_ORR_1873 0.9261986017227173 0.9261987209320068 0.926199 0.93668\n",
            "agra_ORR_1875 0.5915154218673706 0.5915154218673706 0.591515 0.638872\n",
            "agra_ORR_1876 0.5942857265472412 0.5942857265472412 0.594286 0.59044\n",
            "agra_ORR_1877 0.67946857213974 0.67946857213974 0.679469 0.706646\n",
            "{'len': 100, 'mae_old': 0.035890019999999995, 'mae_new': 0.03589003382339477}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.edata['r'][0]"
      ],
      "metadata": {
        "id": "7JFQdV3amUmD",
        "outputId": "e5b483fb-74c0-4ad7-9d60-d2b6b428cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3826, 2.3947, 0.0000], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g1.edata['r'][0]"
      ],
      "metadata": {
        "id": "eSNFVEHLmWaI",
        "outputId": "e41c8577-a20f-4a96-ba27-9aea6b6ed766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 3.1930, 2.2578], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atoms.composition.reduced_formula, atoms2.composition.reduced_formula, atoms.density, atoms2.density"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pporgp_ZIrp",
        "outputId": "8574409b-4d6c-4b33-9b98-aed5e3fc7298"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ir3Ru4Pd3Rh5PtO', 'Ir3Ru4Pd3Rh5PtO', 5.832751652039113, 5.832751652039113)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atoms"
      ],
      "metadata": {
        "id": "fUBK8Bf5nDvA",
        "outputId": "3c21448a-bda8-4749-b577-42ca192d885d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "System\n",
              "1.0\n",
              "5.530423557016226 0.0 0.0\n",
              "0.0 4.789487294063948 0.0\n",
              "0.0 0.0 21.773357888078852\n",
              "Ir Ru Pd Rh Pt O \n",
              "3 4 3 5 1 1 \n",
              "direct\n",
              "0.0 0.0 0.3444576307928588 Ir\n",
              "0.750000482379669 0.4999997175131327 0.3444576307928588 Ir\n",
              "0.7469664433783565 0.519976482060626 0.6472395461035408 Ir\n",
              "0.500000321586446 0.0 0.3444576307928588 Ru\n",
              "0.500000321586446 0.6666662900175102 0.44815251126573713 Ru\n",
              "0.5084557061588848 0.3365541549263033 0.548321429235832 Ru\n",
              "0.7312626628341851 0.8299305122052871 0.5493624096632589 Ru\n",
              "0.250000160793223 0.4999997175131327 0.3444576307928588 Pd\n",
              "0.0 0.6666662900175102 0.44815251126573713 Pd\n",
              "0.24751338968530406 0.831271189966367 0.5510866894578369 Pd\n",
              "0.250000160793223 0.16666657250437755 0.44815251126573713 Rh\n",
              "0.750000482379669 0.16666657250437755 0.44815251126573713 Rh\n",
              "-0.01487864808447113 -0.004433722975593943 0.657534368058532 Rh\n",
              "0.5133643377427142 -0.00385950429568881 0.6532876063582962 Rh\n",
              "0.2539020193152106 0.49279917466827583 0.6543780561426878 Rh\n",
              "-0.0014161355405218968 0.3281391947344333 0.550369574775524 Pt\n",
              "0.2544641740051029 0.1554172583050498 0.7099604873289771 O"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atoms2"
      ],
      "metadata": {
        "id": "rzVMcBRkkK6_",
        "outputId": "6ca0b151-68bd-491a-f425-2040d9f3c677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "System\n",
              "1.0\n",
              "5.530423557016226 0.0 0.0\n",
              "0.0 4.789487294063948 0.0\n",
              "0.0 0.0 21.773357888078852\n",
              "Ir Ru Pd Rh Pt O \n",
              "3 4 3 5 1 1 \n",
              "direct\n",
              "0.0 0.0 0.3444576307928588 Ir\n",
              "0.750000482379669 0.4999997175131327 0.3444576307928588 Ir\n",
              "0.7469664433783565 0.519976482060626 0.6472395461035408 Ir\n",
              "0.500000321586446 0.0 0.3444576307928588 Ru\n",
              "0.500000321586446 0.6666662900175102 0.44815251126573713 Ru\n",
              "0.5084557061588848 0.3365541549263033 0.548321429235832 Ru\n",
              "0.7312626628341851 0.8299305122052871 0.5493624096632589 Ru\n",
              "0.250000160793223 0.4999997175131327 0.3444576307928588 Pd\n",
              "0.0 0.6666662900175102 0.44815251126573713 Pd\n",
              "0.24751338968530406 0.831271189966367 0.5510866894578369 Pd\n",
              "0.250000160793223 0.16666657250437755 0.44815251126573713 Rh\n",
              "0.750000482379669 0.16666657250437755 0.44815251126573713 Rh\n",
              "-0.01487864808447113 -0.004433722975593943 0.657534368058532 Rh\n",
              "0.5133643377427142 -0.00385950429568881 0.6532876063582962 Rh\n",
              "0.2539020193152106 0.49279917466827583 0.6543780561426878 Rh\n",
              "-0.0014161355405218968 0.3281391947344333 0.550369574775524 Pt\n",
              "0.2544641740051029 0.1554172583050498 0.7099604873289771 O"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(config)\n",
        "{'len': 100, 'mae_old': 0.11343228000000001, 'mae_new': 0.2405668252241325}#best\n",
        "{'len': 100, 'mae_old': 0.11343228000000001, 'mae_new': 0.22036484209213253}#200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxU3Z85UXnYN",
        "outputId": "9b920c69-6668-4d87-bd9e-c7a237c2a782"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_O',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'len': 100, 'mae_old': 0.11343228000000001, 'mae_new': 0.22036484209213253}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "ids_train_val_test = loadjson('temp_O/ids_train_val_test.json')\n",
        "#Make benchmark file\n",
        "info={}\n",
        "train_dat={}\n",
        "val_dat={}\n",
        "test_dat={}\n",
        "for ii in mem_O:\n",
        "  if ii['id'] in ids_train_val_test['id_train']:\n",
        "    train_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_val']:\n",
        "    val_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_test']:\n",
        "    test_dat[ii['id']]=ii['ead']\n",
        "info['train']=train_dat\n",
        "info['val']=val_dat\n",
        "info['test']=test_dat\n",
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=info,filename=\"AGRA_O_ead.json\")\n"
      ],
      "metadata": {
        "id": "OvOh5w_dqI-n"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_O_ead.json.zip AGRA_O_ead.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4--sXqiq5CU",
        "outputId": "83b72d44-512b-4cb1-ee1e-bb1fa90a370f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_O_ead.json (deflated 65%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make contribution file\n",
        "!cp temp_O/prediction_results_test_set.csv AI-SinglePropertyPrediction-ead-AGRA_O-test-mae.csv\n",
        "!zip AI-SinglePropertyPrediction-ead-AGRA_O-test-mae.csv.zip AI-SinglePropertyPrediction-ead-AGRA_O-test-mae.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtYburA1rC18",
        "outputId": "d5c6c666-1b9a-4002-b325-d5223d2e9cfb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI-SinglePropertyPrediction-ead-AGRA_O-test-mae.csv (deflated 66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls temp_O"
      ],
      "metadata": {
        "id": "SlT7zO_zrCys",
        "outputId": "6146931a-c948-42dc-b681-995d72ffb2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.pt\t    history_val.json\t\t      test_data_data_range\n",
            "checkpoint_199.pt   ids_train_val_test.json\t      train_data_data_range\n",
            "checkpoint_200.pt   mad\t\t\t\t      val_data_data_range\n",
            "config.json\t    prediction_results_test_set.csv\n",
            "history_train.json  prediction_results_train_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r temp_O.zip temp_O"
      ],
      "metadata": {
        "id": "89yQmMVzrCvl",
        "outputId": "008888a1-e2d5-40cd-fd6d-62aab613efe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: temp_O/ (stored 0%)\n",
            "  adding: temp_O/history_train.json (deflated 55%)\n",
            "  adding: temp_O/ids_train_val_test.json (deflated 85%)\n",
            "  adding: temp_O/prediction_results_train_set.csv (deflated 51%)\n",
            "  adding: temp_O/best_model.pt (deflated 8%)\n",
            "  adding: temp_O/mad (deflated 12%)\n",
            "  adding: temp_O/history_val.json (deflated 56%)\n",
            "  adding: temp_O/train_data_data_range (stored 0%)\n",
            "  adding: temp_O/config.json (deflated 59%)\n",
            "  adding: temp_O/test_data_data_range (stored 0%)\n",
            "  adding: temp_O/prediction_results_test_set.csv (deflated 66%)\n",
            "  adding: temp_O/val_data_data_range (stored 0%)\n",
            "  adding: temp_O/checkpoint_200.pt (deflated 8%)\n",
            "  adding: temp_O/checkpoint_199.pt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf temp_O"
      ],
      "metadata": {
        "id": "Wy9oKkmsuie0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "m8v6CTajunfr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "f09sRJXduoaW",
        "outputId": "448c9958-ff78-42a7-f90f-e8e2a46fc753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder.py --root_dir \"DataDir_OH\" --config \"tmp_config.json\" --output_dir=\"temp_OH\""
      ],
      "metadata": {
        "id": "6hO-4KJKl9Gg",
        "outputId": "dbfce116-7f1b-4cf5-9730-c4dcbe0bfa93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: 1.4080818709252014\n",
            "MIN val: -0.05679336959980219\n",
            "MAD: 0.2767198030216958\n",
            "Baseline MAE: 0.2738898930675022\n",
            "data range 1.3599219447111892 -0.05679336959980219\n",
            "100% 701/701 [00:17<00:00, 39.86it/s]\n",
            "df                                                  atoms  ...    target\n",
            "0    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.237832\n",
            "1    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.689550\n",
            "2    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.271353\n",
            "3    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.441851\n",
            "4    {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.286755\n",
            "..                                                 ...  ...       ...\n",
            "696  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.868584\n",
            "697  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.989472\n",
            "698  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.481818\n",
            "699  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.297804\n",
            "700  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.824942\n",
            "\n",
            "[701 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 701/701 [00:00<00:00, 1162.07it/s]\n",
            "data range 1.2843501005903306 0.09074498051136004\n",
            "100% 87/87 [00:02<00:00, 39.66it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.976175\n",
            "1   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.090745\n",
            "2   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.737328\n",
            "3   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.162293\n",
            "4   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.446188\n",
            "..                                                ...  ...       ...\n",
            "82  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.154914\n",
            "83  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.214202\n",
            "84  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.119840\n",
            "85  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.085673\n",
            "86  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.029557\n",
            "\n",
            "[87 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 87/87 [00:00<00:00, 949.95it/s]\n",
            "data range 1.4080818709252014 0.11337033264338459\n",
            "100% 87/87 [00:03<00:00, 22.08it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.700568\n",
            "1   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.374283\n",
            "2   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.327672\n",
            "3   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.364027\n",
            "4   {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.677096\n",
            "..                                                ...  ...       ...\n",
            "82  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.962456\n",
            "83  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  1.129809\n",
            "84  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.837444\n",
            "85  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.553940\n",
            "86  {'lattice_mat': [[5.530423557016226, 0.0, 0.0]...  ...  0.612715\n",
            "\n",
            "[87 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 87/87 [00:00<00:00, 1384.02it/s]\n",
            "n_train: 701\n",
            "n_val  : 87\n",
            "n_test : 87\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=10 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='temp_OH' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_OH',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 0.1740\n",
            "Train_MAE: 0.1596\n",
            "Val_MAE: 0.0724\n",
            "Train_MAE: 0.0674\n",
            "Val_MAE: 0.0627\n",
            "Train_MAE: 0.0535\n",
            "Val_MAE: 0.0674\n",
            "Train_MAE: 0.0499\n",
            "Val_MAE: 0.0664\n",
            "Train_MAE: 0.0489\n",
            "Val_MAE: 0.0704\n",
            "Train_MAE: 0.0500\n",
            "Val_MAE: 0.0604\n",
            "Train_MAE: 0.0513\n",
            "Val_MAE: 0.0569\n",
            "Train_MAE: 0.0376\n",
            "Val_MAE: 0.0671\n",
            "Train_MAE: 0.0525\n",
            "Val_MAE: 0.0773\n",
            "Train_MAE: 0.0553\n",
            "Val_MAE: 0.1579\n",
            "Train_MAE: 0.1409\n",
            "Val_MAE: 0.1187\n",
            "Train_MAE: 0.1014\n",
            "Val_MAE: 0.1063\n",
            "Train_MAE: 0.0953\n",
            "Val_MAE: 0.0596\n",
            "Train_MAE: 0.0376\n",
            "Val_MAE: 0.0518\n",
            "Train_MAE: 0.0441\n",
            "Val_MAE: 0.0919\n",
            "Train_MAE: 0.0987\n",
            "Val_MAE: 0.0730\n",
            "Train_MAE: 0.0599\n",
            "Val_MAE: 0.0810\n",
            "Train_MAE: 0.0784\n",
            "Val_MAE: 0.0516\n",
            "Train_MAE: 0.0429\n",
            "Val_MAE: 0.0605\n",
            "Train_MAE: 0.0488\n",
            "Val_MAE: 0.1013\n",
            "Train_MAE: 0.1067\n",
            "Val_MAE: 0.0939\n",
            "Train_MAE: 0.0950\n",
            "Val_MAE: 0.0566\n",
            "Train_MAE: 0.0433\n",
            "Val_MAE: 0.0749\n",
            "Train_MAE: 0.0735\n",
            "Val_MAE: 0.0418\n",
            "Train_MAE: 0.0343\n",
            "Val_MAE: 0.0674\n",
            "Train_MAE: 0.0691\n",
            "Val_MAE: 0.1110\n",
            "Train_MAE: 0.1006\n",
            "Val_MAE: 0.0977\n",
            "Train_MAE: 0.0916\n",
            "Val_MAE: 0.1655\n",
            "Train_MAE: 0.1564\n",
            "Val_MAE: 0.0480\n",
            "Train_MAE: 0.0315\n",
            "Val_MAE: 0.0556\n",
            "Train_MAE: 0.0389\n",
            "Val_MAE: 0.0653\n",
            "Train_MAE: 0.0494\n",
            "Val_MAE: 0.0550\n",
            "Train_MAE: 0.0500\n",
            "Val_MAE: 0.0540\n",
            "Train_MAE: 0.0342\n",
            "Val_MAE: 0.0528\n",
            "Train_MAE: 0.0290\n",
            "Val_MAE: 0.0460\n",
            "Train_MAE: 0.0268\n",
            "Val_MAE: 0.1549\n",
            "Train_MAE: 0.1447\n",
            "Val_MAE: 0.1113\n",
            "Train_MAE: 0.1152\n",
            "Val_MAE: 0.0573\n",
            "Train_MAE: 0.0354\n",
            "Val_MAE: 0.0458\n",
            "Train_MAE: 0.0294\n",
            "Val_MAE: 0.0732\n",
            "Train_MAE: 0.0711\n",
            "Val_MAE: 0.0621\n",
            "Train_MAE: 0.0633\n",
            "Val_MAE: 0.0796\n",
            "Train_MAE: 0.0845\n",
            "Val_MAE: 0.0503\n",
            "Train_MAE: 0.0474\n",
            "Val_MAE: 0.0749\n",
            "Train_MAE: 0.0579\n",
            "Val_MAE: 0.0440\n",
            "Train_MAE: 0.0326\n",
            "Val_MAE: 0.0855\n",
            "Train_MAE: 0.0884\n",
            "Val_MAE: 0.0501\n",
            "Train_MAE: 0.0405\n",
            "Val_MAE: 0.0923\n",
            "Train_MAE: 0.0834\n",
            "Val_MAE: 0.1015\n",
            "Train_MAE: 0.1112\n",
            "Val_MAE: 0.0401\n",
            "Train_MAE: 0.0233\n",
            "Val_MAE: 0.0536\n",
            "Train_MAE: 0.0429\n",
            "Val_MAE: 0.0705\n",
            "Train_MAE: 0.0710\n",
            "Val_MAE: 0.0381\n",
            "Train_MAE: 0.0243\n",
            "Val_MAE: 0.0493\n",
            "Train_MAE: 0.0417\n",
            "Val_MAE: 0.0773\n",
            "Train_MAE: 0.0787\n",
            "Val_MAE: 0.0442\n",
            "Train_MAE: 0.0236\n",
            "Val_MAE: 0.0635\n",
            "Train_MAE: 0.0499\n",
            "Val_MAE: 0.0437\n",
            "Train_MAE: 0.0239\n",
            "Val_MAE: 0.0685\n",
            "Train_MAE: 0.0554\n",
            "Val_MAE: 0.0590\n",
            "Train_MAE: 0.0459\n",
            "Val_MAE: 0.0419\n",
            "Train_MAE: 0.0200\n",
            "Val_MAE: 0.0404\n",
            "Train_MAE: 0.0277\n",
            "Val_MAE: 0.0605\n",
            "Train_MAE: 0.0488\n",
            "Val_MAE: 0.0754\n",
            "Train_MAE: 0.0662\n",
            "Val_MAE: 0.0406\n",
            "Train_MAE: 0.0274\n",
            "Val_MAE: 0.0393\n",
            "Train_MAE: 0.0220\n",
            "Val_MAE: 0.0448\n",
            "Train_MAE: 0.0239\n",
            "Val_MAE: 0.0748\n",
            "Train_MAE: 0.0789\n",
            "Val_MAE: 0.0666\n",
            "Train_MAE: 0.0575\n",
            "Val_MAE: 0.0413\n",
            "Train_MAE: 0.0231\n",
            "Val_MAE: 0.0409\n",
            "Train_MAE: 0.0314\n",
            "Val_MAE: 0.0919\n",
            "Train_MAE: 0.0896\n",
            "Val_MAE: 0.0397\n",
            "Train_MAE: 0.0229\n",
            "Val_MAE: 0.0492\n",
            "Train_MAE: 0.0480\n",
            "Val_MAE: 0.0413\n",
            "Train_MAE: 0.0188\n",
            "Val_MAE: 0.0361\n",
            "Train_MAE: 0.0237\n",
            "Val_MAE: 0.0608\n",
            "Train_MAE: 0.0462\n",
            "Val_MAE: 0.0373\n",
            "Train_MAE: 0.0226\n",
            "Val_MAE: 0.0653\n",
            "Train_MAE: 0.0557\n",
            "Val_MAE: 0.0383\n",
            "Train_MAE: 0.0189\n",
            "Val_MAE: 0.0399\n",
            "Train_MAE: 0.0164\n",
            "Val_MAE: 0.0452\n",
            "Train_MAE: 0.0264\n",
            "Val_MAE: 0.0531\n",
            "Train_MAE: 0.0420\n",
            "Val_MAE: 0.0345\n",
            "Train_MAE: 0.0142\n",
            "Val_MAE: 0.0526\n",
            "Train_MAE: 0.0367\n",
            "Val_MAE: 0.0451\n",
            "Train_MAE: 0.0252\n",
            "Val_MAE: 0.0649\n",
            "Train_MAE: 0.0650\n",
            "Val_MAE: 0.0358\n",
            "Train_MAE: 0.0152\n",
            "Val_MAE: 0.0631\n",
            "Train_MAE: 0.0639\n",
            "Val_MAE: 0.0582\n",
            "Train_MAE: 0.0532\n",
            "Val_MAE: 0.0494\n",
            "Train_MAE: 0.0324\n",
            "Val_MAE: 0.1017\n",
            "Train_MAE: 0.0972\n",
            "Val_MAE: 0.0421\n",
            "Train_MAE: 0.0255\n",
            "Val_MAE: 0.0360\n",
            "Train_MAE: 0.0295\n",
            "Val_MAE: 0.0650\n",
            "Train_MAE: 0.0545\n",
            "Val_MAE: 0.0699\n",
            "Train_MAE: 0.0605\n",
            "Val_MAE: 0.0556\n",
            "Train_MAE: 0.0409\n",
            "Val_MAE: 0.0444\n",
            "Train_MAE: 0.0253\n",
            "Val_MAE: 0.0760\n",
            "Train_MAE: 0.0802\n",
            "Val_MAE: 0.0399\n",
            "Train_MAE: 0.0165\n",
            "Val_MAE: 0.0371\n",
            "Train_MAE: 0.0113\n",
            "Val_MAE: 0.0586\n",
            "Train_MAE: 0.0469\n",
            "Val_MAE: 0.0392\n",
            "Train_MAE: 0.0169\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0131\n",
            "Val_MAE: 0.0374\n",
            "Train_MAE: 0.0103\n",
            "Val_MAE: 0.0403\n",
            "Train_MAE: 0.0174\n",
            "Val_MAE: 0.0389\n",
            "Train_MAE: 0.0280\n",
            "Val_MAE: 0.1064\n",
            "Train_MAE: 0.1126\n",
            "Val_MAE: 0.0484\n",
            "Train_MAE: 0.0475\n",
            "Val_MAE: 0.0430\n",
            "Train_MAE: 0.0383\n",
            "Val_MAE: 0.0654\n",
            "Train_MAE: 0.0556\n",
            "Val_MAE: 0.0422\n",
            "Train_MAE: 0.0182\n",
            "Val_MAE: 0.0497\n",
            "Train_MAE: 0.0428\n",
            "Val_MAE: 0.0392\n",
            "Train_MAE: 0.0151\n",
            "Val_MAE: 0.0411\n",
            "Train_MAE: 0.0310\n",
            "Val_MAE: 0.0404\n",
            "Train_MAE: 0.0204\n",
            "Val_MAE: 0.0365\n",
            "Train_MAE: 0.0146\n",
            "Val_MAE: 0.0454\n",
            "Train_MAE: 0.0239\n",
            "Val_MAE: 0.0367\n",
            "Train_MAE: 0.0234\n",
            "Val_MAE: 0.0421\n",
            "Train_MAE: 0.0179\n",
            "Val_MAE: 0.0367\n",
            "Train_MAE: 0.0101\n",
            "Val_MAE: 0.0390\n",
            "Train_MAE: 0.0261\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0200\n",
            "Val_MAE: 0.0396\n",
            "Train_MAE: 0.0318\n",
            "Val_MAE: 0.0387\n",
            "Train_MAE: 0.0178\n",
            "Val_MAE: 0.0357\n",
            "Train_MAE: 0.0225\n",
            "Val_MAE: 0.0396\n",
            "Train_MAE: 0.0134\n",
            "Val_MAE: 0.0493\n",
            "Train_MAE: 0.0450\n",
            "Val_MAE: 0.0466\n",
            "Train_MAE: 0.0258\n",
            "Val_MAE: 0.0348\n",
            "Train_MAE: 0.0198\n",
            "Val_MAE: 0.0337\n",
            "Train_MAE: 0.0120\n",
            "Val_MAE: 0.0406\n",
            "Train_MAE: 0.0146\n",
            "Val_MAE: 0.0382\n",
            "Train_MAE: 0.0128\n",
            "Val_MAE: 0.0387\n",
            "Train_MAE: 0.0149\n",
            "Val_MAE: 0.0356\n",
            "Train_MAE: 0.0165\n",
            "Val_MAE: 0.0339\n",
            "Train_MAE: 0.0133\n",
            "Val_MAE: 0.0329\n",
            "Train_MAE: 0.0135\n",
            "Val_MAE: 0.0400\n",
            "Train_MAE: 0.0142\n",
            "Val_MAE: 0.0360\n",
            "Train_MAE: 0.0082\n",
            "Val_MAE: 0.0356\n",
            "Train_MAE: 0.0222\n",
            "Val_MAE: 0.0330\n",
            "Train_MAE: 0.0157\n",
            "Val_MAE: 0.0349\n",
            "Train_MAE: 0.0106\n",
            "Val_MAE: 0.0345\n",
            "Train_MAE: 0.0073\n",
            "Val_MAE: 0.0558\n",
            "Train_MAE: 0.0436\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0207\n",
            "Val_MAE: 0.0369\n",
            "Train_MAE: 0.0088\n",
            "Val_MAE: 0.0452\n",
            "Train_MAE: 0.0283\n",
            "Val_MAE: 0.0329\n",
            "Train_MAE: 0.0080\n",
            "Val_MAE: 0.0384\n",
            "Train_MAE: 0.0128\n",
            "Val_MAE: 0.0363\n",
            "Train_MAE: 0.0085\n",
            "Val_MAE: 0.0344\n",
            "Train_MAE: 0.0048\n",
            "Val_MAE: 0.0346\n",
            "Train_MAE: 0.0054\n",
            "Val_MAE: 0.0334\n",
            "Train_MAE: 0.0156\n",
            "Val_MAE: 0.0372\n",
            "Train_MAE: 0.0099\n",
            "Val_MAE: 0.0340\n",
            "Train_MAE: 0.0149\n",
            "Val_MAE: 0.0350\n",
            "Train_MAE: 0.0060\n",
            "Val_MAE: 0.0356\n",
            "Train_MAE: 0.0078\n",
            "Val_MAE: 0.0456\n",
            "Train_MAE: 0.0286\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0065\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0153\n",
            "Val_MAE: 0.0354\n",
            "Train_MAE: 0.0183\n",
            "Val_MAE: 0.0337\n",
            "Train_MAE: 0.0069\n",
            "Val_MAE: 0.0339\n",
            "Train_MAE: 0.0077\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0041\n",
            "Val_MAE: 0.0355\n",
            "Train_MAE: 0.0067\n",
            "Val_MAE: 0.0345\n",
            "Train_MAE: 0.0051\n",
            "Val_MAE: 0.0375\n",
            "Train_MAE: 0.0100\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0340\n",
            "Train_MAE: 0.0054\n",
            "Val_MAE: 0.0359\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0357\n",
            "Train_MAE: 0.0058\n",
            "Val_MAE: 0.0340\n",
            "Train_MAE: 0.0108\n",
            "Val_MAE: 0.0339\n",
            "Train_MAE: 0.0057\n",
            "Val_MAE: 0.0354\n",
            "Train_MAE: 0.0058\n",
            "Val_MAE: 0.0352\n",
            "Train_MAE: 0.0051\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0039\n",
            "Val_MAE: 0.0355\n",
            "Train_MAE: 0.0059\n",
            "Val_MAE: 0.0339\n",
            "Train_MAE: 0.0075\n",
            "Val_MAE: 0.0344\n",
            "Train_MAE: 0.0041\n",
            "Val_MAE: 0.0343\n",
            "Train_MAE: 0.0035\n",
            "Val_MAE: 0.0346\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0349\n",
            "Train_MAE: 0.0043\n",
            "Val_MAE: 0.0349\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0350\n",
            "Train_MAE: 0.0045\n",
            "Val_MAE: 0.0344\n",
            "Train_MAE: 0.0034\n",
            "Val_MAE: 0.0345\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0338\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0341\n",
            "Train_MAE: 0.0041\n",
            "Val_MAE: 0.0343\n",
            "Train_MAE: 0.0046\n",
            "Val_MAE: 0.0343\n",
            "Train_MAE: 0.0034\n",
            "Val_MAE: 0.0343\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0349\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0344\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0341\n",
            "Train_MAE: 0.0033\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0030\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0040\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0345\n",
            "Train_MAE: 0.0035\n",
            "Val_MAE: 0.0342\n",
            "Train_MAE: 0.0037\n",
            "Test MAE: 0.02463258820018549\n",
            "Time taken (s): 1565.4100110530853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "ids_train_val_test = loadjson('temp_OH/ids_train_val_test.json')\n",
        "#Make benchmark file\n",
        "info={}\n",
        "train_dat={}\n",
        "val_dat={}\n",
        "test_dat={}\n",
        "for ii in mem_OH:\n",
        "  if ii['id'] in ids_train_val_test['id_train']:\n",
        "    train_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_val']:\n",
        "    val_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_test']:\n",
        "    test_dat[ii['id']]=ii['ead']\n",
        "info['train']=train_dat\n",
        "info['val']=val_dat\n",
        "info['test']=test_dat\n",
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=info,filename=\"AGRA_OH_ead.json\")\n"
      ],
      "metadata": {
        "id": "thHkTm6NrYJr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_OH_ead.json.zip AGRA_OH_ead.json"
      ],
      "metadata": {
        "id": "7N_4KRwUro9f",
        "outputId": "cb23635b-66e4-4343-8b2b-cbd282a034ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_OH_ead.json (deflated 65%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make contribution file\n",
        "!cp temp_OH/prediction_results_test_set.csv AI-SinglePropertyPrediction-ead-AGRA_OH-test-mae.csv\n",
        "!zip AI-SinglePropertyPrediction-ead-AGRA_OH-test-mae.csv.zip AI-SinglePropertyPrediction-ead-AGRA_OH-test-mae.csv"
      ],
      "metadata": {
        "id": "wzXq-w9crxRw",
        "outputId": "0c68b00f-a40a-4b7c-898e-957111577b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI-SinglePropertyPrediction-ead-AGRA_OH-test-mae.csv (deflated 67%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNP7KiWz06sW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "m2or9aearxPA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r temp_OH.zip temp_OH"
      ],
      "metadata": {
        "id": "FmHex8KTrxJq",
        "outputId": "7f32ddb6-7e57-4312-a49d-a7e116d27fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: temp_OH/ (stored 0%)\n",
            "  adding: temp_OH/history_train.json (deflated 55%)\n",
            "  adding: temp_OH/ids_train_val_test.json (deflated 85%)\n",
            "  adding: temp_OH/prediction_results_train_set.csv (deflated 52%)\n",
            "  adding: temp_OH/best_model.pt (deflated 8%)\n",
            "  adding: temp_OH/mad (deflated 11%)\n",
            "  adding: temp_OH/history_val.json (deflated 56%)\n",
            "  adding: temp_OH/train_data_data_range (stored 0%)\n",
            "  adding: temp_OH/config.json (deflated 59%)\n",
            "  adding: temp_OH/test_data_data_range (stored 0%)\n",
            "  adding: temp_OH/prediction_results_test_set.csv (deflated 67%)\n",
            "  adding: temp_OH/val_data_data_range (stored 0%)\n",
            "  adding: temp_OH/checkpoint_200.pt (deflated 8%)\n",
            "  adding: temp_OH/checkpoint_199.pt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHjPgclKymAv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder.py --root_dir \"DataDir_CO\" --config \"tmp_config.json\" --output_dir=\"temp_CO\""
      ],
      "metadata": {
        "id": "KeWVo0fHptQr",
        "outputId": "62536db5-a3a1-4eaa-8731-eece6eca11b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: -0.82876\n",
            "MIN val: -2.2856\n",
            "MAD: 0.18882752940004252\n",
            "Baseline MAE: 0.12505212417657038\n",
            "data range -0.82876 -2.2856\n",
            "100% 155/155 [00:10<00:00, 14.24it/s]\n",
            "df                                                  atoms  ...    target\n",
            "0    {'lattice_mat': [[10.0819997787, 0.0, 0.0], [5...  ... -1.815340\n",
            "1    {'lattice_mat': [[10.0819997787, 0.0, 0.0], [5...  ... -2.161600\n",
            "2    {'lattice_mat': [[10.0819997787, 0.0, 0.0], [5...  ... -2.180620\n",
            "3    {'lattice_mat': [[10.0819997787, 0.0, 0.0], [5...  ... -2.093670\n",
            "4    {'lattice_mat': [[10.0819997787, 0.0, 0.0], [5...  ... -2.067250\n",
            "..                                                 ...  ...       ...\n",
            "150  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.808897\n",
            "151  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.077303\n",
            "152  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.776628\n",
            "153  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.145740\n",
            "154  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.999687\n",
            "\n",
            "[155 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 155/155 [00:00<00:00, 459.33it/s]\n",
            "data range -1.01340087 -2.2255343\n",
            "100% 19/19 [00:01<00:00, 15.43it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.225534\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.022248\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.161603\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.087276\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.188344\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.013401\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.578131\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.732958\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.984655\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.011920\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.025661\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.152781\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.008057\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.775031\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.183526\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.063772\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.935352\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.731796\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.986519\n",
            "\n",
            "[19 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 19/19 [00:00<00:00, 272.48it/s]\n",
            "data range -1.72102697 -2.16428696\n",
            "100% 19/19 [00:02<00:00,  7.61it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.102508\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.882076\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.721027\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.164287\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.734300\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.957928\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.928054\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.991408\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.877777\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.790850\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.769163\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.882859\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.010432\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.797656\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.734330\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.116612\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.031270\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.113921\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.936452\n",
            "\n",
            "[19 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 19/19 [00:00<00:00, 288.68it/s]\n",
            "n_train: 155\n",
            "n_val  : 19\n",
            "n_test : 19\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=10 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='temp_CO' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_CO',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 0.7860\n",
            "Train_MAE: 0.8302\n",
            "Val_MAE: 0.4212\n",
            "Train_MAE: 0.3279\n",
            "Val_MAE: 0.3261\n",
            "Train_MAE: 0.2732\n",
            "Val_MAE: 0.4036\n",
            "Train_MAE: 0.2964\n",
            "Val_MAE: 0.1461\n",
            "Train_MAE: 0.1679\n",
            "Val_MAE: 0.1830\n",
            "Train_MAE: 0.1572\n",
            "Val_MAE: 0.1498\n",
            "Train_MAE: 0.1197\n",
            "Val_MAE: 0.1605\n",
            "Train_MAE: 0.1373\n",
            "Val_MAE: 0.1567\n",
            "Train_MAE: 0.1037\n",
            "Val_MAE: 0.1823\n",
            "Train_MAE: 0.1290\n",
            "Val_MAE: 0.0879\n",
            "Train_MAE: 0.0836\n",
            "Val_MAE: 0.1384\n",
            "Train_MAE: 0.1063\n",
            "Val_MAE: 0.2058\n",
            "Train_MAE: 0.1731\n",
            "Val_MAE: 0.2824\n",
            "Train_MAE: 0.1639\n",
            "Val_MAE: 0.1085\n",
            "Train_MAE: 0.0695\n",
            "Val_MAE: 0.1565\n",
            "Train_MAE: 0.0803\n",
            "Val_MAE: 0.0891\n",
            "Train_MAE: 0.0934\n",
            "Val_MAE: 0.1393\n",
            "Train_MAE: 0.1160\n",
            "Val_MAE: 0.0807\n",
            "Train_MAE: 0.1015\n",
            "Val_MAE: 0.0647\n",
            "Train_MAE: 0.1671\n",
            "Val_MAE: 0.0749\n",
            "Train_MAE: 0.0593\n",
            "Val_MAE: 0.1284\n",
            "Train_MAE: 0.0631\n",
            "Val_MAE: 0.0635\n",
            "Train_MAE: 0.0724\n",
            "Val_MAE: 0.1929\n",
            "Train_MAE: 0.1707\n",
            "Val_MAE: 0.0568\n",
            "Train_MAE: 0.0641\n",
            "Val_MAE: 0.4275\n",
            "Train_MAE: 0.3718\n",
            "Val_MAE: 0.2316\n",
            "Train_MAE: 0.1126\n",
            "Val_MAE: 0.1084\n",
            "Train_MAE: 0.0835\n",
            "Val_MAE: 0.0831\n",
            "Train_MAE: 0.0863\n",
            "Val_MAE: 0.2948\n",
            "Train_MAE: 0.2596\n",
            "Val_MAE: 0.1293\n",
            "Train_MAE: 0.1104\n",
            "Val_MAE: 0.3172\n",
            "Train_MAE: 0.3431\n",
            "Val_MAE: 0.0729\n",
            "Train_MAE: 0.1026\n",
            "Val_MAE: 0.1807\n",
            "Train_MAE: 0.2582\n",
            "Val_MAE: 0.1436\n",
            "Train_MAE: 0.1131\n",
            "Val_MAE: 0.0862\n",
            "Train_MAE: 0.0804\n",
            "Val_MAE: 0.1212\n",
            "Train_MAE: 0.1252\n",
            "Val_MAE: 0.1961\n",
            "Train_MAE: 0.2556\n",
            "Val_MAE: 0.1065\n",
            "Train_MAE: 0.1446\n",
            "Val_MAE: 0.0789\n",
            "Train_MAE: 0.0882\n",
            "Val_MAE: 0.1630\n",
            "Train_MAE: 0.0937\n",
            "Val_MAE: 0.1328\n",
            "Train_MAE: 0.0718\n",
            "Val_MAE: 0.1841\n",
            "Train_MAE: 0.1116\n",
            "Val_MAE: 0.0847\n",
            "Train_MAE: 0.0515\n",
            "Val_MAE: 0.0997\n",
            "Train_MAE: 0.0935\n",
            "Val_MAE: 0.0890\n",
            "Train_MAE: 0.0569\n",
            "Val_MAE: 0.1138\n",
            "Train_MAE: 0.1041\n",
            "Val_MAE: 0.1313\n",
            "Train_MAE: 0.1009\n",
            "Val_MAE: 0.2423\n",
            "Train_MAE: 0.1582\n",
            "Val_MAE: 0.1350\n",
            "Train_MAE: 0.1356\n",
            "Val_MAE: 0.1086\n",
            "Train_MAE: 0.1142\n",
            "Val_MAE: 0.1758\n",
            "Train_MAE: 0.1063\n",
            "Val_MAE: 0.1042\n",
            "Train_MAE: 0.0920\n",
            "Val_MAE: 0.1190\n",
            "Train_MAE: 0.1143\n",
            "Val_MAE: 0.1457\n",
            "Train_MAE: 0.1077\n",
            "Val_MAE: 0.0992\n",
            "Train_MAE: 0.0505\n",
            "Val_MAE: 0.1043\n",
            "Train_MAE: 0.0460\n",
            "Val_MAE: 0.1290\n",
            "Train_MAE: 0.1668\n",
            "Val_MAE: 0.1101\n",
            "Train_MAE: 0.0578\n",
            "Val_MAE: 0.0941\n",
            "Train_MAE: 0.1166\n",
            "Val_MAE: 0.1176\n",
            "Train_MAE: 0.1152\n",
            "Val_MAE: 0.1124\n",
            "Train_MAE: 0.0857\n",
            "Val_MAE: 0.1213\n",
            "Train_MAE: 0.0468\n",
            "Val_MAE: 0.2608\n",
            "Train_MAE: 0.1982\n",
            "Val_MAE: 0.1102\n",
            "Train_MAE: 0.0623\n",
            "Val_MAE: 0.1546\n",
            "Train_MAE: 0.1492\n",
            "Val_MAE: 0.1356\n",
            "Train_MAE: 0.0390\n",
            "Val_MAE: 0.2785\n",
            "Train_MAE: 0.2230\n",
            "Val_MAE: 0.1140\n",
            "Train_MAE: 0.0316\n",
            "Val_MAE: 0.1366\n",
            "Train_MAE: 0.0746\n",
            "Val_MAE: 0.1561\n",
            "Train_MAE: 0.0615\n",
            "Val_MAE: 0.1295\n",
            "Train_MAE: 0.0611\n",
            "Val_MAE: 0.1664\n",
            "Train_MAE: 0.1218\n",
            "Val_MAE: 0.1448\n",
            "Train_MAE: 0.0345\n",
            "Val_MAE: 0.2125\n",
            "Train_MAE: 0.1666\n",
            "Val_MAE: 0.1264\n",
            "Train_MAE: 0.0428\n",
            "Val_MAE: 0.2011\n",
            "Train_MAE: 0.1227\n",
            "Val_MAE: 0.1166\n",
            "Train_MAE: 0.0411\n",
            "Val_MAE: 0.1347\n",
            "Train_MAE: 0.0724\n",
            "Val_MAE: 0.1192\n",
            "Train_MAE: 0.1732\n",
            "Val_MAE: 0.2423\n",
            "Train_MAE: 0.1960\n",
            "Val_MAE: 0.1247\n",
            "Train_MAE: 0.0363\n",
            "Val_MAE: 0.1382\n",
            "Train_MAE: 0.0461\n",
            "Val_MAE: 0.1405\n",
            "Train_MAE: 0.1383\n",
            "Val_MAE: 0.1272\n",
            "Train_MAE: 0.0714\n",
            "Val_MAE: 0.1110\n",
            "Train_MAE: 0.0263\n",
            "Val_MAE: 0.1137\n",
            "Train_MAE: 0.0557\n",
            "Val_MAE: 0.1205\n",
            "Train_MAE: 0.0323\n",
            "Val_MAE: 0.1295\n",
            "Train_MAE: 0.0286\n",
            "Val_MAE: 0.1149\n",
            "Train_MAE: 0.0529\n",
            "Val_MAE: 0.1203\n",
            "Train_MAE: 0.0525\n",
            "Val_MAE: 0.1114\n",
            "Train_MAE: 0.0181\n",
            "Val_MAE: 0.1054\n",
            "Train_MAE: 0.0318\n",
            "Val_MAE: 0.1076\n",
            "Train_MAE: 0.0209\n",
            "Val_MAE: 0.1061\n",
            "Train_MAE: 0.0224\n",
            "Val_MAE: 0.1069\n",
            "Train_MAE: 0.0649\n",
            "Val_MAE: 0.1043\n",
            "Train_MAE: 0.0113\n",
            "Val_MAE: 0.1008\n",
            "Train_MAE: 0.0185\n",
            "Val_MAE: 0.1134\n",
            "Train_MAE: 0.0541\n",
            "Val_MAE: 0.1114\n",
            "Train_MAE: 0.0251\n",
            "Val_MAE: 0.1062\n",
            "Train_MAE: 0.0150\n",
            "Val_MAE: 0.1154\n",
            "Train_MAE: 0.0461\n",
            "Val_MAE: 0.1109\n",
            "Train_MAE: 0.0983\n",
            "Val_MAE: 0.0963\n",
            "Train_MAE: 0.0474\n",
            "Val_MAE: 0.1101\n",
            "Train_MAE: 0.0119\n",
            "Val_MAE: 0.1023\n",
            "Train_MAE: 0.0261\n",
            "Val_MAE: 0.1150\n",
            "Train_MAE: 0.0660\n",
            "Val_MAE: 0.1042\n",
            "Train_MAE: 0.0284\n",
            "Val_MAE: 0.1071\n",
            "Train_MAE: 0.0422\n",
            "Val_MAE: 0.1154\n",
            "Train_MAE: 0.0695\n",
            "Val_MAE: 0.1076\n",
            "Train_MAE: 0.0695\n",
            "Val_MAE: 0.1058\n",
            "Train_MAE: 0.0266\n",
            "Val_MAE: 0.1048\n",
            "Train_MAE: 0.0124\n",
            "Val_MAE: 0.0965\n",
            "Train_MAE: 0.0329\n",
            "Val_MAE: 0.1015\n",
            "Train_MAE: 0.0273\n",
            "Val_MAE: 0.1238\n",
            "Train_MAE: 0.0501\n",
            "Val_MAE: 0.1050\n",
            "Train_MAE: 0.0815\n",
            "Val_MAE: 0.1153\n",
            "Train_MAE: 0.0294\n",
            "Val_MAE: 0.1033\n",
            "Train_MAE: 0.0148\n",
            "Val_MAE: 0.1022\n",
            "Train_MAE: 0.0141\n",
            "Val_MAE: 0.1068\n",
            "Train_MAE: 0.0150\n",
            "Val_MAE: 0.0975\n",
            "Train_MAE: 0.0142\n",
            "Val_MAE: 0.0997\n",
            "Train_MAE: 0.0596\n",
            "Val_MAE: 0.1073\n",
            "Train_MAE: 0.0285\n",
            "Val_MAE: 0.1008\n",
            "Train_MAE: 0.0245\n",
            "Val_MAE: 0.1108\n",
            "Train_MAE: 0.0389\n",
            "Val_MAE: 0.1075\n",
            "Train_MAE: 0.0108\n",
            "Val_MAE: 0.1033\n",
            "Train_MAE: 0.0102\n",
            "Val_MAE: 0.1006\n",
            "Train_MAE: 0.0206\n",
            "Val_MAE: 0.1029\n",
            "Train_MAE: 0.0223\n",
            "Val_MAE: 0.0976\n",
            "Train_MAE: 0.0418\n",
            "Val_MAE: 0.1010\n",
            "Train_MAE: 0.0123\n",
            "Val_MAE: 0.0992\n",
            "Train_MAE: 0.0214\n",
            "Val_MAE: 0.1035\n",
            "Train_MAE: 0.0163\n",
            "Val_MAE: 0.0986\n",
            "Train_MAE: 0.0065\n",
            "Val_MAE: 0.0987\n",
            "Train_MAE: 0.0118\n",
            "Val_MAE: 0.0956\n",
            "Train_MAE: 0.0168\n",
            "Val_MAE: 0.0975\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.1016\n",
            "Train_MAE: 0.0135\n",
            "Val_MAE: 0.1092\n",
            "Train_MAE: 0.0286\n",
            "Val_MAE: 0.1039\n",
            "Train_MAE: 0.0150\n",
            "Val_MAE: 0.1019\n",
            "Train_MAE: 0.0077\n",
            "Val_MAE: 0.1005\n",
            "Train_MAE: 0.0112\n",
            "Val_MAE: 0.0983\n",
            "Train_MAE: 0.0239\n",
            "Val_MAE: 0.0977\n",
            "Train_MAE: 0.0092\n",
            "Val_MAE: 0.1006\n",
            "Train_MAE: 0.0090\n",
            "Val_MAE: 0.0966\n",
            "Train_MAE: 0.0080\n",
            "Val_MAE: 0.0995\n",
            "Train_MAE: 0.0130\n",
            "Val_MAE: 0.0955\n",
            "Train_MAE: 0.0132\n",
            "Val_MAE: 0.0997\n",
            "Train_MAE: 0.0087\n",
            "Val_MAE: 0.0944\n",
            "Train_MAE: 0.0205\n",
            "Val_MAE: 0.0976\n",
            "Train_MAE: 0.0059\n",
            "Val_MAE: 0.0978\n",
            "Train_MAE: 0.0090\n",
            "Val_MAE: 0.0977\n",
            "Train_MAE: 0.0132\n",
            "Val_MAE: 0.0987\n",
            "Train_MAE: 0.0110\n",
            "Val_MAE: 0.0948\n",
            "Train_MAE: 0.0345\n",
            "Val_MAE: 0.0980\n",
            "Train_MAE: 0.0143\n",
            "Val_MAE: 0.0992\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0133\n",
            "Val_MAE: 0.0973\n",
            "Train_MAE: 0.0156\n",
            "Val_MAE: 0.0966\n",
            "Train_MAE: 0.0144\n",
            "Val_MAE: 0.0965\n",
            "Train_MAE: 0.0094\n",
            "Val_MAE: 0.0986\n",
            "Train_MAE: 0.0180\n",
            "Val_MAE: 0.0983\n",
            "Train_MAE: 0.0114\n",
            "Val_MAE: 0.0941\n",
            "Train_MAE: 0.0212\n",
            "Val_MAE: 0.0992\n",
            "Train_MAE: 0.0177\n",
            "Val_MAE: 0.0990\n",
            "Train_MAE: 0.0069\n",
            "Val_MAE: 0.0959\n",
            "Train_MAE: 0.0080\n",
            "Val_MAE: 0.0973\n",
            "Train_MAE: 0.0097\n",
            "Val_MAE: 0.0979\n",
            "Train_MAE: 0.0162\n",
            "Val_MAE: 0.0963\n",
            "Train_MAE: 0.0065\n",
            "Val_MAE: 0.0969\n",
            "Train_MAE: 0.0113\n",
            "Val_MAE: 0.0976\n",
            "Train_MAE: 0.0074\n",
            "Val_MAE: 0.0991\n",
            "Train_MAE: 0.0097\n",
            "Val_MAE: 0.0974\n",
            "Train_MAE: 0.0154\n",
            "Val_MAE: 0.0970\n",
            "Train_MAE: 0.0069\n",
            "Val_MAE: 0.0955\n",
            "Train_MAE: 0.0102\n",
            "Val_MAE: 0.0960\n",
            "Train_MAE: 0.0095\n",
            "Val_MAE: 0.0982\n",
            "Train_MAE: 0.0055\n",
            "Val_MAE: 0.0968\n",
            "Train_MAE: 0.0132\n",
            "Val_MAE: 0.0972\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0965\n",
            "Train_MAE: 0.0155\n",
            "Val_MAE: 0.0962\n",
            "Train_MAE: 0.0128\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0107\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0097\n",
            "Val_MAE: 0.0953\n",
            "Train_MAE: 0.0121\n",
            "Val_MAE: 0.0957\n",
            "Train_MAE: 0.0117\n",
            "Val_MAE: 0.0963\n",
            "Train_MAE: 0.0103\n",
            "Val_MAE: 0.0959\n",
            "Train_MAE: 0.0123\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0102\n",
            "Val_MAE: 0.0960\n",
            "Train_MAE: 0.0071\n",
            "Val_MAE: 0.0962\n",
            "Train_MAE: 0.0109\n",
            "Val_MAE: 0.0957\n",
            "Train_MAE: 0.0122\n",
            "Val_MAE: 0.0972\n",
            "Train_MAE: 0.0120\n",
            "Val_MAE: 0.0965\n",
            "Train_MAE: 0.0095\n",
            "Val_MAE: 0.0967\n",
            "Train_MAE: 0.0070\n",
            "Val_MAE: 0.0962\n",
            "Train_MAE: 0.0133\n",
            "Val_MAE: 0.0961\n",
            "Train_MAE: 0.0123\n",
            "Val_MAE: 0.0969\n",
            "Train_MAE: 0.0107\n",
            "Val_MAE: 0.0962\n",
            "Train_MAE: 0.0119\n",
            "Test MAE: 0.13493223566758006\n",
            "Time taken (s): 970.8024513721466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "ids_train_val_test = loadjson('temp_CO/ids_train_val_test.json')\n",
        "#Make benchmark file\n",
        "info={}\n",
        "train_dat={}\n",
        "val_dat={}\n",
        "test_dat={}\n",
        "for ii in mem_CO:\n",
        "  if ii['id'] in ids_train_val_test['id_train']:\n",
        "    train_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_val']:\n",
        "    val_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_test']:\n",
        "    test_dat[ii['id']]=ii['ead']\n",
        "info['train']=train_dat\n",
        "info['val']=val_dat\n",
        "info['test']=test_dat\n",
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=info,filename=\"AGRA_CO_ead.json\")\n"
      ],
      "metadata": {
        "id": "jklfLVzCtvkp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_CO_ead.json.zip AGRA_CO_ead.json"
      ],
      "metadata": {
        "id": "Po9f_kXNtvh5",
        "outputId": "fb594dfc-3606-4913-befb-a5776bb3970c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_CO_ead.json (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make contribution file\n",
        "!cp temp_CO/prediction_results_test_set.csv AI-SinglePropertyPrediction-ead-AGRA_CO-test-mae.csv\n",
        "!zip AI-SinglePropertyPrediction-ead-AGRA_CO-test-mae.csv.zip AI-SinglePropertyPrediction-ead-AGRA_CO-test-mae.csv"
      ],
      "metadata": {
        "id": "WY4kcjfWt5k4",
        "outputId": "42f42753-f8dd-4489-bbb8-d38b39dcf5bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI-SinglePropertyPrediction-ead-AGRA_CO-test-mae.csv (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "#!zip -r temp_CO.zip temp_CO"
      ],
      "metadata": {
        "id": "5cDye0N1t5h3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r temp_CO.zip temp_CO"
      ],
      "metadata": {
        "id": "R56gN_EQtvfO",
        "outputId": "7763f01b-cded-450c-a69e-acd02f853298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: temp_CO/ (stored 0%)\n",
            "  adding: temp_CO/history_train.json (deflated 55%)\n",
            "  adding: temp_CO/ids_train_val_test.json (deflated 86%)\n",
            "  adding: temp_CO/prediction_results_train_set.csv (deflated 53%)\n",
            "  adding: temp_CO/best_model.pt (deflated 8%)\n",
            "  adding: temp_CO/mad (deflated 11%)\n",
            "  adding: temp_CO/history_val.json (deflated 55%)\n",
            "  adding: temp_CO/train_data_data_range (stored 0%)\n",
            "  adding: temp_CO/config.json (deflated 59%)\n",
            "  adding: temp_CO/test_data_data_range (stored 0%)\n",
            "  adding: temp_CO/prediction_results_test_set.csv (deflated 64%)\n",
            "  adding: temp_CO/val_data_data_range (stored 0%)\n",
            "  adding: temp_CO/checkpoint_200.pt (deflated 8%)\n",
            "  adding: temp_CO/checkpoint_199.pt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder.py --root_dir \"DataDir_CHO\" --config \"tmp_config.json\" --output_dir=\"temp_CHO\""
      ],
      "metadata": {
        "id": "4XFjQfyupv06",
        "outputId": "7024f7e5-fe8c-4c00-8c08-0bb09d04fb95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: -0.439552285\n",
            "MIN val: -2.472420325\n",
            "MAD: 0.24996257928669408\n",
            "Baseline MAE: 0.32956586632059826\n",
            "data range -0.439552285 -2.472420325\n",
            "100% 172/172 [00:12<00:00, 13.41it/s]\n",
            "df                                                  atoms  ...    target\n",
            "0    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.447092\n",
            "1    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.546783\n",
            "2    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.561247\n",
            "3    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -2.017618\n",
            "4    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.517757\n",
            "..                                                 ...  ...       ...\n",
            "167  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.480037\n",
            "168  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.639793\n",
            "169  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.623042\n",
            "170  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.538801\n",
            "171  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.688805\n",
            "\n",
            "[172 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 172/172 [00:00<00:00, 457.86it/s]\n",
            "data range -0.600265585 -1.573116415\n",
            "100% 21/21 [00:01<00:00, 15.37it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.407846\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.537478\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.476909\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.230363\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.573116\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.366202\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.495976\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.349712\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.352238\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.253195\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.302927\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.162202\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.422363\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.536768\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.314213\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.014175\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.150503\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.224455\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.600266\n",
            "19  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.901306\n",
            "20  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.088751\n",
            "\n",
            "[21 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 21/21 [00:00<00:00, 414.55it/s]\n",
            "data range -0.524739855 -1.633781365\n",
            "100% 21/21 [00:01<00:00, 17.71it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.551308\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.428074\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.942704\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.187494\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.030318\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.014411\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.450160\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.615609\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.734070\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.441621\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.633781\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.352441\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.259807\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.267363\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.737742\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.524740\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.414207\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.452047\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.427005\n",
            "19  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.241166\n",
            "20  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -1.447563\n",
            "\n",
            "[21 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 21/21 [00:00<00:00, 470.83it/s]\n",
            "n_train: 172\n",
            "n_val  : 21\n",
            "n_test : 21\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=10 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='temp_CHO' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_CHO',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 0.2138\n",
            "Train_MAE: 0.4010\n",
            "Val_MAE: 0.3498\n",
            "Train_MAE: 0.2736\n",
            "Val_MAE: 0.1703\n",
            "Train_MAE: 0.2415\n",
            "Val_MAE: 0.1545\n",
            "Train_MAE: 0.1610\n",
            "Val_MAE: 0.1632\n",
            "Train_MAE: 0.1312\n",
            "Val_MAE: 0.1260\n",
            "Train_MAE: 0.1048\n",
            "Val_MAE: 0.0892\n",
            "Train_MAE: 0.0997\n",
            "Val_MAE: 0.0699\n",
            "Train_MAE: 0.0929\n",
            "Val_MAE: 0.0728\n",
            "Train_MAE: 0.0928\n",
            "Val_MAE: 0.0608\n",
            "Train_MAE: 0.0573\n",
            "Val_MAE: 0.1742\n",
            "Train_MAE: 0.1619\n",
            "Val_MAE: 0.0959\n",
            "Train_MAE: 0.1229\n",
            "Val_MAE: 0.1226\n",
            "Train_MAE: 0.0993\n",
            "Val_MAE: 0.1517\n",
            "Train_MAE: 0.1058\n",
            "Val_MAE: 0.0707\n",
            "Train_MAE: 0.0777\n",
            "Val_MAE: 0.1327\n",
            "Train_MAE: 0.1203\n",
            "Val_MAE: 0.0569\n",
            "Train_MAE: 0.0710\n",
            "Val_MAE: 0.2655\n",
            "Train_MAE: 0.2393\n",
            "Val_MAE: 0.0809\n",
            "Train_MAE: 0.0842\n",
            "Val_MAE: 0.0930\n",
            "Train_MAE: 0.1570\n",
            "Val_MAE: 0.0497\n",
            "Train_MAE: 0.0834\n",
            "Val_MAE: 0.0919\n",
            "Train_MAE: 0.0664\n",
            "Val_MAE: 0.0488\n",
            "Train_MAE: 0.0572\n",
            "Val_MAE: 0.0915\n",
            "Train_MAE: 0.0648\n",
            "Val_MAE: 0.0552\n",
            "Train_MAE: 0.0733\n",
            "Val_MAE: 0.0780\n",
            "Train_MAE: 0.0570\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0348\n",
            "Val_MAE: 0.0578\n",
            "Train_MAE: 0.0309\n",
            "Val_MAE: 0.2100\n",
            "Train_MAE: 0.1714\n",
            "Val_MAE: 0.3601\n",
            "Train_MAE: 0.3676\n",
            "Val_MAE: 0.0852\n",
            "Train_MAE: 0.0832\n",
            "Val_MAE: 0.0943\n",
            "Train_MAE: 0.0802\n",
            "Val_MAE: 0.3556\n",
            "Train_MAE: 0.3614\n",
            "Val_MAE: 0.1265\n",
            "Train_MAE: 0.1615\n",
            "Val_MAE: 0.0905\n",
            "Train_MAE: 0.0704\n",
            "Val_MAE: 0.0933\n",
            "Train_MAE: 0.0794\n",
            "Val_MAE: 0.0490\n",
            "Train_MAE: 0.0549\n",
            "Val_MAE: 0.0522\n",
            "Train_MAE: 0.0394\n",
            "Val_MAE: 0.2335\n",
            "Train_MAE: 0.2066\n",
            "Val_MAE: 0.1757\n",
            "Train_MAE: 0.1902\n",
            "Val_MAE: 0.0609\n",
            "Train_MAE: 0.0610\n",
            "Val_MAE: 0.0450\n",
            "Train_MAE: 0.0653\n",
            "Val_MAE: 0.0804\n",
            "Train_MAE: 0.0522\n",
            "Val_MAE: 0.0627\n",
            "Train_MAE: 0.0533\n",
            "Val_MAE: 0.1076\n",
            "Train_MAE: 0.1660\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0443\n",
            "Val_MAE: 0.0919\n",
            "Train_MAE: 0.0800\n",
            "Val_MAE: 0.1153\n",
            "Train_MAE: 0.1830\n",
            "Val_MAE: 0.2881\n",
            "Train_MAE: 0.2924\n",
            "Val_MAE: 0.1704\n",
            "Train_MAE: 0.2135\n",
            "Val_MAE: 0.1005\n",
            "Train_MAE: 0.1070\n",
            "Val_MAE: 0.0661\n",
            "Train_MAE: 0.0397\n",
            "Val_MAE: 0.3321\n",
            "Train_MAE: 0.3040\n",
            "Val_MAE: 0.0794\n",
            "Train_MAE: 0.0441\n",
            "Val_MAE: 0.0665\n",
            "Train_MAE: 0.0421\n",
            "Val_MAE: 0.0835\n",
            "Train_MAE: 0.0677\n",
            "Val_MAE: 0.0662\n",
            "Train_MAE: 0.0437\n",
            "Val_MAE: 0.1172\n",
            "Train_MAE: 0.0677\n",
            "Val_MAE: 0.1135\n",
            "Train_MAE: 0.0599\n",
            "Val_MAE: 0.0663\n",
            "Train_MAE: 0.0226\n",
            "Val_MAE: 0.1992\n",
            "Train_MAE: 0.2552\n",
            "Val_MAE: 0.1133\n",
            "Train_MAE: 0.1101\n",
            "Val_MAE: 0.0670\n",
            "Train_MAE: 0.0792\n",
            "Val_MAE: 0.2822\n",
            "Train_MAE: 0.2385\n",
            "Val_MAE: 0.0625\n",
            "Train_MAE: 0.0278\n",
            "Val_MAE: 0.0674\n",
            "Train_MAE: 0.0672\n",
            "Val_MAE: 0.0820\n",
            "Train_MAE: 0.0411\n",
            "Val_MAE: 0.0831\n",
            "Train_MAE: 0.0708\n",
            "Val_MAE: 0.1085\n",
            "Train_MAE: 0.1282\n",
            "Val_MAE: 0.0720\n",
            "Train_MAE: 0.0232\n",
            "Val_MAE: 0.0587\n",
            "Train_MAE: 0.0322\n",
            "Val_MAE: 0.0818\n",
            "Train_MAE: 0.0834\n",
            "Val_MAE: 0.0749\n",
            "Train_MAE: 0.0325\n",
            "Val_MAE: 0.0652\n",
            "Train_MAE: 0.0310\n",
            "Val_MAE: 0.0697\n",
            "Train_MAE: 0.0319\n",
            "Val_MAE: 0.1177\n",
            "Train_MAE: 0.1317\n",
            "Val_MAE: 0.0874\n",
            "Train_MAE: 0.0698\n",
            "Val_MAE: 0.0879\n",
            "Train_MAE: 0.0450\n",
            "Val_MAE: 0.0707\n",
            "Train_MAE: 0.0312\n",
            "Val_MAE: 0.0636\n",
            "Train_MAE: 0.0237\n",
            "Val_MAE: 0.1227\n",
            "Train_MAE: 0.0705\n",
            "Val_MAE: 0.0715\n",
            "Train_MAE: 0.0254\n",
            "Val_MAE: 0.0554\n",
            "Train_MAE: 0.0510\n",
            "Val_MAE: 0.0948\n",
            "Train_MAE: 0.0648\n",
            "Val_MAE: 0.0556\n",
            "Train_MAE: 0.0695\n",
            "Val_MAE: 0.0684\n",
            "Train_MAE: 0.0214\n",
            "Val_MAE: 0.1448\n",
            "Train_MAE: 0.1293\n",
            "Val_MAE: 0.0575\n",
            "Train_MAE: 0.0963\n",
            "Val_MAE: 0.0735\n",
            "Train_MAE: 0.0582\n",
            "Val_MAE: 0.0570\n",
            "Train_MAE: 0.0468\n",
            "Val_MAE: 0.0546\n",
            "Train_MAE: 0.0242\n",
            "Val_MAE: 0.0662\n",
            "Train_MAE: 0.0237\n",
            "Val_MAE: 0.0627\n",
            "Train_MAE: 0.0149\n",
            "Val_MAE: 0.0607\n",
            "Train_MAE: 0.0137\n",
            "Val_MAE: 0.0651\n",
            "Train_MAE: 0.0120\n",
            "Val_MAE: 0.0559\n",
            "Train_MAE: 0.0290\n",
            "Val_MAE: 0.0841\n",
            "Train_MAE: 0.0338\n",
            "Val_MAE: 0.0505\n",
            "Train_MAE: 0.0487\n",
            "Val_MAE: 0.0830\n",
            "Train_MAE: 0.0321\n",
            "Val_MAE: 0.0505\n",
            "Train_MAE: 0.0263\n",
            "Val_MAE: 0.1003\n",
            "Train_MAE: 0.0664\n",
            "Val_MAE: 0.0668\n",
            "Train_MAE: 0.0161\n",
            "Val_MAE: 0.0686\n",
            "Train_MAE: 0.0185\n",
            "Val_MAE: 0.0892\n",
            "Train_MAE: 0.0498\n",
            "Val_MAE: 0.0949\n",
            "Train_MAE: 0.0300\n",
            "Val_MAE: 0.0577\n",
            "Train_MAE: 0.0263\n",
            "Val_MAE: 0.0654\n",
            "Train_MAE: 0.0220\n",
            "Val_MAE: 0.0598\n",
            "Train_MAE: 0.0160\n",
            "Val_MAE: 0.0838\n",
            "Train_MAE: 0.0412\n",
            "Val_MAE: 0.0552\n",
            "Train_MAE: 0.0285\n",
            "Val_MAE: 0.0726\n",
            "Train_MAE: 0.0172\n",
            "Val_MAE: 0.0679\n",
            "Train_MAE: 0.0145\n",
            "Val_MAE: 0.0604\n",
            "Train_MAE: 0.0134\n",
            "Val_MAE: 0.0744\n",
            "Train_MAE: 0.0157\n",
            "Val_MAE: 0.0723\n",
            "Train_MAE: 0.0179\n",
            "Val_MAE: 0.0616\n",
            "Train_MAE: 0.0253\n",
            "Val_MAE: 0.0586\n",
            "Train_MAE: 0.0139\n",
            "Val_MAE: 0.0673\n",
            "Train_MAE: 0.0128\n",
            "Val_MAE: 0.0489\n",
            "Train_MAE: 0.0603\n",
            "Val_MAE: 0.0512\n",
            "Train_MAE: 0.0376\n",
            "Val_MAE: 0.0679\n",
            "Train_MAE: 0.0167\n",
            "Val_MAE: 0.0808\n",
            "Train_MAE: 0.0334\n",
            "Val_MAE: 0.0598\n",
            "Train_MAE: 0.0088\n",
            "Val_MAE: 0.0697\n",
            "Train_MAE: 0.0126\n",
            "Val_MAE: 0.0540\n",
            "Train_MAE: 0.0099\n",
            "Val_MAE: 0.0745\n",
            "Train_MAE: 0.0324\n",
            "Val_MAE: 0.0640\n",
            "Train_MAE: 0.0095\n",
            "Val_MAE: 0.0591\n",
            "Train_MAE: 0.0090\n",
            "Val_MAE: 0.0586\n",
            "Train_MAE: 0.0114\n",
            "Val_MAE: 0.0951\n",
            "Train_MAE: 0.0485\n",
            "Val_MAE: 0.0600\n",
            "Train_MAE: 0.0186\n",
            "Val_MAE: 0.0507\n",
            "Train_MAE: 0.0524\n",
            "Val_MAE: 0.1020\n",
            "Train_MAE: 0.0495\n",
            "Val_MAE: 0.0605\n",
            "Train_MAE: 0.0133\n",
            "Val_MAE: 0.0628\n",
            "Train_MAE: 0.0111\n",
            "Val_MAE: 0.0512\n",
            "Train_MAE: 0.0378\n",
            "Val_MAE: 0.0604\n",
            "Train_MAE: 0.0057\n",
            "Val_MAE: 0.0705\n",
            "Train_MAE: 0.0158\n",
            "Val_MAE: 0.0598\n",
            "Train_MAE: 0.0067\n",
            "Val_MAE: 0.0681\n",
            "Train_MAE: 0.0169\n",
            "Val_MAE: 0.0714\n",
            "Train_MAE: 0.0127\n",
            "Val_MAE: 0.0617\n",
            "Train_MAE: 0.0145\n",
            "Val_MAE: 0.0638\n",
            "Train_MAE: 0.0054\n",
            "Val_MAE: 0.0686\n",
            "Train_MAE: 0.0117\n",
            "Val_MAE: 0.0771\n",
            "Train_MAE: 0.0270\n",
            "Val_MAE: 0.0535\n",
            "Train_MAE: 0.0246\n",
            "Val_MAE: 0.0671\n",
            "Train_MAE: 0.0068\n",
            "Val_MAE: 0.0671\n",
            "Train_MAE: 0.0124\n",
            "Val_MAE: 0.0721\n",
            "Train_MAE: 0.0186\n",
            "Val_MAE: 0.0606\n",
            "Train_MAE: 0.0130\n",
            "Val_MAE: 0.0568\n",
            "Train_MAE: 0.0157\n",
            "Val_MAE: 0.0697\n",
            "Train_MAE: 0.0144\n",
            "Val_MAE: 0.0594\n",
            "Train_MAE: 0.0105\n",
            "Val_MAE: 0.0580\n",
            "Train_MAE: 0.0179\n",
            "Val_MAE: 0.0683\n",
            "Train_MAE: 0.0081\n",
            "Val_MAE: 0.0638\n",
            "Train_MAE: 0.0053\n",
            "Val_MAE: 0.0637\n",
            "Train_MAE: 0.0060\n",
            "Val_MAE: 0.0608\n",
            "Train_MAE: 0.0096\n",
            "Val_MAE: 0.0640\n",
            "Train_MAE: 0.0046\n",
            "Val_MAE: 0.0620\n",
            "Train_MAE: 0.0040\n",
            "Val_MAE: 0.0691\n",
            "Train_MAE: 0.0105\n",
            "Val_MAE: 0.0720\n",
            "Train_MAE: 0.0144\n",
            "Val_MAE: 0.0615\n",
            "Train_MAE: 0.0125\n",
            "Val_MAE: 0.0589\n",
            "Train_MAE: 0.0163\n",
            "Val_MAE: 0.0641\n",
            "Train_MAE: 0.0043\n",
            "Val_MAE: 0.0724\n",
            "Train_MAE: 0.0153\n",
            "Val_MAE: 0.0634\n",
            "Train_MAE: 0.0055\n",
            "Val_MAE: 0.0713\n",
            "Train_MAE: 0.0146\n",
            "Val_MAE: 0.0741\n",
            "Train_MAE: 0.0161\n",
            "Val_MAE: 0.0646\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0658\n",
            "Train_MAE: 0.0044\n",
            "Val_MAE: 0.0669\n",
            "Train_MAE: 0.0052\n",
            "Val_MAE: 0.0650\n",
            "Train_MAE: 0.0039\n",
            "Val_MAE: 0.0712\n",
            "Train_MAE: 0.0158\n",
            "Val_MAE: 0.0615\n",
            "Train_MAE: 0.0072\n",
            "Val_MAE: 0.0681\n",
            "Train_MAE: 0.0079\n",
            "Val_MAE: 0.0637\n",
            "Train_MAE: 0.0030\n",
            "Val_MAE: 0.0663\n",
            "Train_MAE: 0.0051\n",
            "Val_MAE: 0.0634\n",
            "Train_MAE: 0.0033\n",
            "Val_MAE: 0.0651\n",
            "Train_MAE: 0.0029\n",
            "Val_MAE: 0.0672\n",
            "Train_MAE: 0.0061\n",
            "Val_MAE: 0.0631\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0670\n",
            "Train_MAE: 0.0060\n",
            "Val_MAE: 0.0639\n",
            "Train_MAE: 0.0025\n",
            "Val_MAE: 0.0660\n",
            "Train_MAE: 0.0059\n",
            "Val_MAE: 0.0633\n",
            "Train_MAE: 0.0026\n",
            "Val_MAE: 0.0627\n",
            "Train_MAE: 0.0033\n",
            "Val_MAE: 0.0653\n",
            "Train_MAE: 0.0035\n",
            "Val_MAE: 0.0646\n",
            "Train_MAE: 0.0035\n",
            "Val_MAE: 0.0626\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0654\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0676\n",
            "Train_MAE: 0.0073\n",
            "Val_MAE: 0.0624\n",
            "Train_MAE: 0.0049\n",
            "Val_MAE: 0.0644\n",
            "Train_MAE: 0.0028\n",
            "Val_MAE: 0.0651\n",
            "Train_MAE: 0.0031\n",
            "Val_MAE: 0.0636\n",
            "Train_MAE: 0.0025\n",
            "Val_MAE: 0.0638\n",
            "Train_MAE: 0.0024\n",
            "Val_MAE: 0.0642\n",
            "Train_MAE: 0.0025\n",
            "Val_MAE: 0.0638\n",
            "Train_MAE: 0.0024\n",
            "Val_MAE: 0.0639\n",
            "Train_MAE: 0.0026\n",
            "Test MAE: 0.10616383666083926\n",
            "Time taken (s): 1116.3374495506287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "ids_train_val_test = loadjson('temp_CHO/ids_train_val_test.json')\n",
        "#Make benchmark file\n",
        "info={}\n",
        "train_dat={}\n",
        "val_dat={}\n",
        "test_dat={}\n",
        "for ii in mem_CHO:\n",
        "  if ii['id'] in ids_train_val_test['id_train']:\n",
        "    train_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_val']:\n",
        "    val_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_test']:\n",
        "    test_dat[ii['id']]=ii['ead']\n",
        "info['train']=train_dat\n",
        "info['val']=val_dat\n",
        "info['test']=test_dat\n",
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=info,filename=\"AGRA_CHO_ead.json\")\n"
      ],
      "metadata": {
        "id": "2bCVl3GhuH53"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_CHO_ead.json.zip AGRA_CHO_ead.json"
      ],
      "metadata": {
        "id": "2Lxe9BC5uH3M",
        "outputId": "c7406718-539c-42a0-ae09-2b7158654a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_CHO_ead.json (deflated 74%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make contribution file\n",
        "!cp temp_CHO/prediction_results_test_set.csv AI-SinglePropertyPrediction-ead-AGRA_CHO-test-mae.csv\n",
        "!zip AI-SinglePropertyPrediction-ead-AGRA_CHO-test-mae.csv.zip AI-SinglePropertyPrediction-ead-AGRA_CHO-test-mae.csv"
      ],
      "metadata": {
        "id": "kR6o6uTwuH0g",
        "outputId": "af91ce6b-facc-41c9-c2ea-64336e4bc3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI-SinglePropertyPrediction-ead-AGRA_CHO-test-mae.csv (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "#!zip -r temp_CO.zip temp_CO"
      ],
      "metadata": {
        "id": "Fst0GZW2uHx4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!zip -r temp_CHO.zip temp_CHO"
      ],
      "metadata": {
        "id": "MfOwF3EKuHvD",
        "outputId": "e6bf7fec-7193-4953-bf98-a2251f2070f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: temp_CHO/ (stored 0%)\n",
            "  adding: temp_CHO/history_train.json (deflated 55%)\n",
            "  adding: temp_CHO/ids_train_val_test.json (deflated 87%)\n",
            "  adding: temp_CHO/prediction_results_train_set.csv (deflated 53%)\n",
            "  adding: temp_CHO/best_model.pt (deflated 8%)\n",
            "  adding: temp_CHO/mad (deflated 10%)\n",
            "  adding: temp_CHO/history_val.json (deflated 55%)\n",
            "  adding: temp_CHO/train_data_data_range (stored 0%)\n",
            "  adding: temp_CHO/config.json (deflated 59%)\n",
            "  adding: temp_CHO/test_data_data_range (stored 0%)\n",
            "  adding: temp_CHO/prediction_results_test_set.csv (deflated 64%)\n",
            "  adding: temp_CHO/val_data_data_range (stored 0%)\n",
            "  adding: temp_CHO/checkpoint_200.pt (deflated 8%)\n",
            "  adding: temp_CHO/checkpoint_199.pt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckCmaH-1uHss"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ4dze7EuHpy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder.py --root_dir \"DataDir_COOH\" --config \"tmp_config.json\" --output_dir=\"temp_COOH\""
      ],
      "metadata": {
        "id": "S43n_qwipx--",
        "outputId": "38741679-b41e-4c6f-c887-1b33c60fcf75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: 0.115324435\n",
            "MIN val: -1.534700825\n",
            "MAD: 0.21199695208163266\n",
            "Baseline MAE: 0.1488003000063776\n",
            "data range 0.115324435 -1.534700825\n",
            "100% 224/224 [00:16<00:00, 13.23it/s]\n",
            "df                                                  atoms  ...    target\n",
            "0    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.892219\n",
            "1    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.750434\n",
            "2    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.957250\n",
            "3    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.802952\n",
            "4    {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.812909\n",
            "..                                                 ...  ...       ...\n",
            "219  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.596949\n",
            "220  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.921388\n",
            "221  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.867938\n",
            "222  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ...  0.014851\n",
            "223  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.170864\n",
            "\n",
            "[224 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 224/224 [00:00<00:00, 454.85it/s]\n",
            "data range 0.058952785 -0.923790655\n",
            "100% 28/28 [00:01<00:00, 15.95it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.389294\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.347076\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.517039\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.616786\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.688430\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.778367\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.885001\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.633498\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.776570\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.675798\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.883475\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.871722\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.885247\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.902893\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.877880\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.817749\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.220892\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ...  0.058953\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.156426\n",
            "19  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.896580\n",
            "20  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.916725\n",
            "21  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.838828\n",
            "22  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.658576\n",
            "23  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.805247\n",
            "24  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.650910\n",
            "25  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.826772\n",
            "26  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.899242\n",
            "27  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.923791\n",
            "\n",
            "[28 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 28/28 [00:00<00:00, 449.07it/s]\n",
            "data range -0.487002185 -0.932503375\n",
            "100% 28/28 [00:02<00:00, 11.32it/s]\n",
            "df                                                 atoms  ...    target\n",
            "0   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.786517\n",
            "1   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.831811\n",
            "2   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.834781\n",
            "3   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.709855\n",
            "4   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.551595\n",
            "5   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.769933\n",
            "6   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.679497\n",
            "7   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.715977\n",
            "8   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.572773\n",
            "9   {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.551509\n",
            "10  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.707817\n",
            "11  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.796137\n",
            "12  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.797173\n",
            "13  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.779019\n",
            "14  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.835719\n",
            "15  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.814704\n",
            "16  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.932503\n",
            "17  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.721866\n",
            "18  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.792422\n",
            "19  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.790070\n",
            "20  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.487002\n",
            "21  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.850985\n",
            "22  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.692882\n",
            "23  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.850181\n",
            "24  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.800784\n",
            "25  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.840693\n",
            "26  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.859608\n",
            "27  {'lattice_mat': [[10.0823001862, 0.0, 0.0], [5...  ... -0.894732\n",
            "\n",
            "[28 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 28/28 [00:00<00:00, 264.12it/s]\n",
            "n_train: 224\n",
            "n_val  : 28\n",
            "n_test : 28\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=10 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='temp_COOH' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 10,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp_COOH',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 0.7507\n",
            "Train_MAE: 0.7679\n",
            "Val_MAE: 0.2049\n",
            "Train_MAE: 0.2055\n",
            "Val_MAE: 0.1547\n",
            "Train_MAE: 0.1374\n",
            "Val_MAE: 0.2192\n",
            "Train_MAE: 0.1117\n",
            "Val_MAE: 0.1422\n",
            "Train_MAE: 0.0756\n",
            "Val_MAE: 0.0921\n",
            "Train_MAE: 0.0560\n",
            "Val_MAE: 0.1090\n",
            "Train_MAE: 0.0799\n",
            "Val_MAE: 0.0749\n",
            "Train_MAE: 0.0541\n",
            "Val_MAE: 0.0725\n",
            "Train_MAE: 0.0914\n",
            "Val_MAE: 0.2156\n",
            "Train_MAE: 0.0710\n",
            "Val_MAE: 0.2481\n",
            "Train_MAE: 0.0749\n",
            "Val_MAE: 0.1889\n",
            "Train_MAE: 0.2146\n",
            "Val_MAE: 0.0976\n",
            "Train_MAE: 0.1023\n",
            "Val_MAE: 0.0620\n",
            "Train_MAE: 0.0609\n",
            "Val_MAE: 0.2678\n",
            "Train_MAE: 0.2402\n",
            "Val_MAE: 0.0845\n",
            "Train_MAE: 0.0583\n",
            "Val_MAE: 0.0668\n",
            "Train_MAE: 0.0459\n",
            "Val_MAE: 0.0727\n",
            "Train_MAE: 0.0534\n",
            "Val_MAE: 0.1095\n",
            "Train_MAE: 0.0874\n",
            "Val_MAE: 0.0693\n",
            "Train_MAE: 0.0529\n",
            "Val_MAE: 0.1129\n",
            "Train_MAE: 0.0601\n",
            "Val_MAE: 0.1715\n",
            "Train_MAE: 0.1462\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0401\n",
            "Val_MAE: 0.0664\n",
            "Train_MAE: 0.1502\n",
            "Val_MAE: 0.1562\n",
            "Train_MAE: 0.1046\n",
            "Val_MAE: 0.1693\n",
            "Train_MAE: 0.1244\n",
            "Val_MAE: 0.1302\n",
            "Train_MAE: 0.0797\n",
            "Val_MAE: 0.1911\n",
            "Train_MAE: 0.0427\n",
            "Val_MAE: 0.0809\n",
            "Train_MAE: 0.0945\n",
            "Val_MAE: 0.3123\n",
            "Train_MAE: 0.3597\n",
            "Val_MAE: 0.0604\n",
            "Train_MAE: 0.1397\n",
            "Val_MAE: 0.0976\n",
            "Train_MAE: 0.0733\n",
            "Val_MAE: 0.1390\n",
            "Train_MAE: 0.1000\n",
            "Val_MAE: 0.0780\n",
            "Train_MAE: 0.0503\n",
            "Val_MAE: 0.0555\n",
            "Train_MAE: 0.0843\n",
            "Val_MAE: 0.0707\n",
            "Train_MAE: 0.0537\n",
            "Val_MAE: 0.0779\n",
            "Train_MAE: 0.0383\n",
            "Val_MAE: 0.0688\n",
            "Train_MAE: 0.0352\n",
            "Val_MAE: 0.0631\n",
            "Train_MAE: 0.0412\n",
            "Val_MAE: 0.1029\n",
            "Train_MAE: 0.0526\n",
            "Val_MAE: 0.0848\n",
            "Train_MAE: 0.1366\n",
            "Val_MAE: 0.2507\n",
            "Train_MAE: 0.1783\n",
            "Val_MAE: 0.0490\n",
            "Train_MAE: 0.0404\n",
            "Val_MAE: 0.0610\n",
            "Train_MAE: 0.0401\n",
            "Val_MAE: 0.1617\n",
            "Train_MAE: 0.1835\n",
            "Val_MAE: 0.1049\n",
            "Train_MAE: 0.1367\n",
            "Val_MAE: 0.1972\n",
            "Train_MAE: 0.0980\n",
            "Val_MAE: 0.2691\n",
            "Train_MAE: 0.2408\n",
            "Val_MAE: 0.0722\n",
            "Train_MAE: 0.0992\n",
            "Val_MAE: 0.1087\n",
            "Train_MAE: 0.0636\n",
            "Val_MAE: 0.0527\n",
            "Train_MAE: 0.0615\n",
            "Val_MAE: 0.2671\n",
            "Train_MAE: 0.2063\n",
            "Val_MAE: 0.0616\n",
            "Train_MAE: 0.0504\n",
            "Val_MAE: 0.0679\n",
            "Train_MAE: 0.0269\n",
            "Val_MAE: 0.1004\n",
            "Train_MAE: 0.0532\n",
            "Val_MAE: 0.0932\n",
            "Train_MAE: 0.0885\n",
            "Val_MAE: 0.0777\n",
            "Train_MAE: 0.0605\n",
            "Val_MAE: 0.0520\n",
            "Train_MAE: 0.0285\n",
            "Val_MAE: 0.0571\n",
            "Train_MAE: 0.0378\n",
            "Val_MAE: 0.1416\n",
            "Train_MAE: 0.1475\n",
            "Val_MAE: 0.0450\n",
            "Train_MAE: 0.0414\n",
            "Val_MAE: 0.1438\n",
            "Train_MAE: 0.1181\n",
            "Val_MAE: 0.0610\n",
            "Train_MAE: 0.0769\n",
            "Val_MAE: 0.0899\n",
            "Train_MAE: 0.0681\n",
            "Val_MAE: 0.0699\n",
            "Train_MAE: 0.0717\n",
            "Val_MAE: 0.0689\n",
            "Train_MAE: 0.0860\n",
            "Val_MAE: 0.0687\n",
            "Train_MAE: 0.0707\n",
            "Val_MAE: 0.0536\n",
            "Train_MAE: 0.0200\n",
            "Val_MAE: 0.0987\n",
            "Train_MAE: 0.0768\n",
            "Val_MAE: 0.0632\n",
            "Train_MAE: 0.0220\n",
            "Val_MAE: 0.0610\n",
            "Train_MAE: 0.0244\n",
            "Val_MAE: 0.0931\n",
            "Train_MAE: 0.0491\n",
            "Val_MAE: 0.0707\n",
            "Train_MAE: 0.0242\n",
            "Val_MAE: 0.0532\n",
            "Train_MAE: 0.0381\n",
            "Val_MAE: 0.0921\n",
            "Train_MAE: 0.0288\n",
            "Val_MAE: 0.0690\n",
            "Train_MAE: 0.0203\n",
            "Val_MAE: 0.0840\n",
            "Train_MAE: 0.0903\n",
            "Val_MAE: 0.1261\n",
            "Train_MAE: 0.0867\n",
            "Val_MAE: 0.1085\n",
            "Train_MAE: 0.0537\n",
            "Val_MAE: 0.1340\n",
            "Train_MAE: 0.1755\n",
            "Val_MAE: 0.0731\n",
            "Train_MAE: 0.0240\n",
            "Val_MAE: 0.1259\n",
            "Train_MAE: 0.0887\n",
            "Val_MAE: 0.0522\n",
            "Train_MAE: 0.0272\n",
            "Val_MAE: 0.0616\n",
            "Train_MAE: 0.0486\n",
            "Val_MAE: 0.0596\n",
            "Train_MAE: 0.0188\n",
            "Val_MAE: 0.0636\n",
            "Train_MAE: 0.0128\n",
            "Val_MAE: 0.0708\n",
            "Train_MAE: 0.0175\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0305\n",
            "Val_MAE: 0.0849\n",
            "Train_MAE: 0.0256\n",
            "Val_MAE: 0.0578\n",
            "Train_MAE: 0.0432\n",
            "Val_MAE: 0.0581\n",
            "Train_MAE: 0.0482\n",
            "Val_MAE: 0.0640\n",
            "Train_MAE: 0.0132\n",
            "Val_MAE: 0.0676\n",
            "Train_MAE: 0.0166\n",
            "Val_MAE: 0.0655\n",
            "Train_MAE: 0.0586\n",
            "Val_MAE: 0.0694\n",
            "Train_MAE: 0.0201\n",
            "Val_MAE: 0.1202\n",
            "Train_MAE: 0.0956\n",
            "Val_MAE: 0.1560\n",
            "Train_MAE: 0.1706\n",
            "Val_MAE: 0.1104\n",
            "Train_MAE: 0.0506\n",
            "Val_MAE: 0.1088\n",
            "Train_MAE: 0.0758\n",
            "Val_MAE: 0.1017\n",
            "Train_MAE: 0.1187\n",
            "Val_MAE: 0.0636\n",
            "Train_MAE: 0.0437\n",
            "Val_MAE: 0.0730\n",
            "Train_MAE: 0.0657\n",
            "Val_MAE: 0.0759\n",
            "Train_MAE: 0.0769\n",
            "Val_MAE: 0.0974\n",
            "Train_MAE: 0.0687\n",
            "Val_MAE: 0.0779\n",
            "Train_MAE: 0.0369\n",
            "Val_MAE: 0.0569\n",
            "Train_MAE: 0.0140\n",
            "Val_MAE: 0.0558\n",
            "Train_MAE: 0.0250\n",
            "Val_MAE: 0.0567\n",
            "Train_MAE: 0.0316\n",
            "Val_MAE: 0.0600\n",
            "Train_MAE: 0.0134\n",
            "Val_MAE: 0.0801\n",
            "Train_MAE: 0.0906\n",
            "Val_MAE: 0.0566\n",
            "Train_MAE: 0.0186\n",
            "Val_MAE: 0.1137\n",
            "Train_MAE: 0.0811\n",
            "Val_MAE: 0.0628\n",
            "Train_MAE: 0.0527\n",
            "Val_MAE: 0.0560\n",
            "Train_MAE: 0.0274\n",
            "Val_MAE: 0.0665\n",
            "Train_MAE: 0.0325\n",
            "Val_MAE: 0.0578\n",
            "Train_MAE: 0.0160\n",
            "Val_MAE: 0.0621\n",
            "Train_MAE: 0.0079\n",
            "Val_MAE: 0.0741\n",
            "Train_MAE: 0.0403\n",
            "Val_MAE: 0.0627\n",
            "Train_MAE: 0.0150\n",
            "Val_MAE: 0.0617\n",
            "Train_MAE: 0.0110\n",
            "Val_MAE: 0.0559\n",
            "Train_MAE: 0.0134\n",
            "Val_MAE: 0.0672\n",
            "Train_MAE: 0.0303\n",
            "Val_MAE: 0.0562\n",
            "Train_MAE: 0.0181\n",
            "Val_MAE: 0.0598\n",
            "Train_MAE: 0.0304\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0070\n",
            "Val_MAE: 0.0647\n",
            "Train_MAE: 0.0094\n",
            "Val_MAE: 0.0624\n",
            "Train_MAE: 0.0085\n",
            "Val_MAE: 0.0601\n",
            "Train_MAE: 0.0065\n",
            "Val_MAE: 0.0526\n",
            "Train_MAE: 0.0241\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0064\n",
            "Val_MAE: 0.0563\n",
            "Train_MAE: 0.0245\n",
            "Val_MAE: 0.0566\n",
            "Train_MAE: 0.0143\n",
            "Val_MAE: 0.0539\n",
            "Train_MAE: 0.0279\n",
            "Val_MAE: 0.0565\n",
            "Train_MAE: 0.0100\n",
            "Val_MAE: 0.0587\n",
            "Train_MAE: 0.0090\n",
            "Val_MAE: 0.0571\n",
            "Train_MAE: 0.0320\n",
            "Val_MAE: 0.0562\n",
            "Train_MAE: 0.0394\n",
            "Val_MAE: 0.0697\n",
            "Train_MAE: 0.0218\n",
            "Val_MAE: 0.0619\n",
            "Train_MAE: 0.0154\n",
            "Val_MAE: 0.0808\n",
            "Train_MAE: 0.0504\n",
            "Val_MAE: 0.0610\n",
            "Train_MAE: 0.0114\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0070\n",
            "Val_MAE: 0.0537\n",
            "Train_MAE: 0.0065\n",
            "Val_MAE: 0.0537\n",
            "Train_MAE: 0.0113\n",
            "Val_MAE: 0.0620\n",
            "Train_MAE: 0.0130\n",
            "Val_MAE: 0.0574\n",
            "Train_MAE: 0.0099\n",
            "Val_MAE: 0.0558\n",
            "Train_MAE: 0.0112\n",
            "Val_MAE: 0.0778\n",
            "Train_MAE: 0.0440\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0135\n",
            "Val_MAE: 0.0610\n",
            "Train_MAE: 0.0535\n",
            "Val_MAE: 0.0551\n",
            "Train_MAE: 0.0085\n",
            "Val_MAE: 0.0605\n",
            "Train_MAE: 0.0103\n",
            "Val_MAE: 0.0563\n",
            "Train_MAE: 0.0191\n",
            "Val_MAE: 0.0574\n",
            "Train_MAE: 0.0063\n",
            "Val_MAE: 0.0558\n",
            "Train_MAE: 0.0040\n",
            "Val_MAE: 0.0532\n",
            "Train_MAE: 0.0050\n",
            "Val_MAE: 0.0584\n",
            "Train_MAE: 0.0056\n",
            "Val_MAE: 0.0556\n",
            "Train_MAE: 0.0054\n",
            "Val_MAE: 0.0538\n",
            "Train_MAE: 0.0117\n",
            "Val_MAE: 0.0542\n",
            "Train_MAE: 0.0111\n",
            "Val_MAE: 0.0539\n",
            "Train_MAE: 0.0071\n",
            "Val_MAE: 0.0565\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0535\n",
            "Train_MAE: 0.0038\n",
            "Val_MAE: 0.0562\n",
            "Train_MAE: 0.0045\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0115\n",
            "Val_MAE: 0.0568\n",
            "Train_MAE: 0.0074\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0033\n",
            "Val_MAE: 0.0572\n",
            "Train_MAE: 0.0067\n",
            "Val_MAE: 0.0545\n",
            "Train_MAE: 0.0179\n",
            "Val_MAE: 0.0530\n",
            "Train_MAE: 0.0116\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0561\n",
            "Train_MAE: 0.0033\n",
            "Val_MAE: 0.0550\n",
            "Train_MAE: 0.0027\n",
            "Val_MAE: 0.0571\n",
            "Train_MAE: 0.0045\n",
            "Val_MAE: 0.0567\n",
            "Train_MAE: 0.0029\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0085\n",
            "Val_MAE: 0.0550\n",
            "Train_MAE: 0.0110\n",
            "Val_MAE: 0.0556\n",
            "Train_MAE: 0.0032\n",
            "Val_MAE: 0.0549\n",
            "Train_MAE: 0.0042\n",
            "Val_MAE: 0.0551\n",
            "Train_MAE: 0.0020\n",
            "Val_MAE: 0.0561\n",
            "Train_MAE: 0.0028\n",
            "Val_MAE: 0.0550\n",
            "Train_MAE: 0.0051\n",
            "Val_MAE: 0.0557\n",
            "Train_MAE: 0.0023\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0083\n",
            "Val_MAE: 0.0565\n",
            "Train_MAE: 0.0029\n",
            "Val_MAE: 0.0548\n",
            "Train_MAE: 0.0036\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0031\n",
            "Val_MAE: 0.0548\n",
            "Train_MAE: 0.0046\n",
            "Val_MAE: 0.0553\n",
            "Train_MAE: 0.0026\n",
            "Val_MAE: 0.0544\n",
            "Train_MAE: 0.0029\n",
            "Val_MAE: 0.0550\n",
            "Train_MAE: 0.0024\n",
            "Val_MAE: 0.0548\n",
            "Train_MAE: 0.0022\n",
            "Val_MAE: 0.0555\n",
            "Train_MAE: 0.0023\n",
            "Val_MAE: 0.0543\n",
            "Train_MAE: 0.0052\n",
            "Val_MAE: 0.0545\n",
            "Train_MAE: 0.0024\n",
            "Val_MAE: 0.0545\n",
            "Train_MAE: 0.0028\n",
            "Val_MAE: 0.0546\n",
            "Train_MAE: 0.0024\n",
            "Val_MAE: 0.0547\n",
            "Train_MAE: 0.0029\n",
            "Val_MAE: 0.0548\n",
            "Train_MAE: 0.0028\n",
            "Val_MAE: 0.0543\n",
            "Train_MAE: 0.0038\n",
            "Test MAE: 0.048530868121555874\n",
            "Time taken (s): 1451.3567202091217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "ids_train_val_test = loadjson('temp_COOH/ids_train_val_test.json')\n",
        "#Make benchmark file\n",
        "info={}\n",
        "train_dat={}\n",
        "val_dat={}\n",
        "test_dat={}\n",
        "for ii in mem_COOH:\n",
        "  if ii['id'] in ids_train_val_test['id_train']:\n",
        "    train_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_val']:\n",
        "    val_dat[ii['id']]=ii['ead']\n",
        "  if ii['id'] in ids_train_val_test['id_test']:\n",
        "    test_dat[ii['id']]=ii['ead']\n",
        "info['train']=train_dat\n",
        "info['val']=val_dat\n",
        "info['test']=test_dat\n",
        "from jarvis.db.jsonutils import dumpjson\n",
        "dumpjson(data=info,filename=\"AGRA_COOH_ead.json\")\n"
      ],
      "metadata": {
        "id": "3BX_aa28uU5v"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip AGRA_COOH_ead.json.zip AGRA_COOH_ead.json"
      ],
      "metadata": {
        "id": "hhshsJUfuU8V",
        "outputId": "5350aba2-95a1-4282-cec3-22437b0e415f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AGRA_COOH_ead.json (deflated 74%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make contribution file\n",
        "!cp temp_COOH/prediction_results_test_set.csv AI-SinglePropertyPrediction-ead-AGRA_COOH-test-mae.csv\n",
        "!zip AI-SinglePropertyPrediction-ead-AGRA_COOH-test-mae.csv.zip AI-SinglePropertyPrediction-ead-AGRA_COOH-test-mae.csv"
      ],
      "metadata": {
        "id": "C4eRFkEDuU-x",
        "outputId": "c80fa905-da77-4cd4-8ded-9ce2b9b47c2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI-SinglePropertyPrediction-ead-AGRA_COOH-test-mae.csv (deflated 67%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "#!zip -r temp_CO.zip temp_CO"
      ],
      "metadata": {
        "id": "Cuc_NFtQuVBb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!zip -r temp_COOH.zip temp_COOH"
      ],
      "metadata": {
        "id": "nK1_yiPiuVDv",
        "outputId": "4e0d226d-165e-4298-8182-795d7b40cf29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: temp_COOH/ (stored 0%)\n",
            "  adding: temp_COOH/history_train.json (deflated 54%)\n",
            "  adding: temp_COOH/ids_train_val_test.json (deflated 87%)\n",
            "  adding: temp_COOH/prediction_results_train_set.csv (deflated 52%)\n",
            "  adding: temp_COOH/best_model.pt (deflated 8%)\n",
            "  adding: temp_COOH/mad (deflated 12%)\n",
            "  adding: temp_COOH/history_val.json (deflated 55%)\n",
            "  adding: temp_COOH/train_data_data_range (stored 0%)\n",
            "  adding: temp_COOH/config.json (deflated 59%)\n",
            "  adding: temp_COOH/test_data_data_range (stored 0%)\n",
            "  adding: temp_COOH/prediction_results_test_set.csv (deflated 67%)\n",
            "  adding: temp_COOH/val_data_data_range (stored 0%)\n",
            "  adding: temp_COOH/checkpoint_200.pt (deflated 8%)\n",
            "  adding: temp_COOH/checkpoint_199.pt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.csv"
      ],
      "metadata": {
        "id": "A2kT46mxuVGG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLpkf-BSNe3M"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}