{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_ALIGNN_model_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdJIQOB9kcK3fQKyYV+TZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/Training_ALIGNN_model_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZGR6D82ij-"
      },
      "source": [
        "# [ALIGNN](https://github.com/usnistgov/alignn) example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFrl_N-S1Bxk",
        "outputId": "1223d7cb-af38-42b6-e4ef-61ed7ae6c5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install alignn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alignn\n",
            "  Downloading alignn-2021.11.14-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 11.5 MB/s \n",
            "\u001b[?25hCollecting flake8>=3.9.1\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting pydocstyle>=6.0.0\n",
            "  Downloading pydocstyle-6.1.1-py3-none-any.whl (37 kB)\n",
            "Collecting jarvis-tools>=2021.07.19\n",
            "  Downloading jarvis_tools-2021.10.3-py2.py3-none-any.whl (947 kB)\n",
            "\u001b[K     |████████████████████████████████| 947 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite>=0.4.7\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting pycodestyle>=2.7.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 901 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from alignn) (2.4.7)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from alignn) (0.22.2.post1)\n",
            "Collecting scipy>=1.6.1\n",
            "  Downloading scipy-1.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 25 kB/s \n",
            "\u001b[?25hCollecting dgl-cu101>=0.6.0\n",
            "  Downloading dgl_cu101-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 89 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from alignn) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from alignn) (1.19.5)\n",
            "Collecting pandas>=1.2.3\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 31.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.7/dist-packages (from alignn) (4.62.3)\n",
            "Collecting matplotlib>=3.4.1\n",
            "  Downloading matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 17.8 MB/s \n",
            "\u001b[?25hCollecting dgl>=0.6.0\n",
            "  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.6.0->alignn) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.6.0->alignn) (2.23.0)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.3\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.9.1->alignn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.9.1->alignn) (3.10.0.2)\n",
            "Collecting xmltodict>=0.11.0\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from jarvis-tools>=2021.07.19->alignn) (0.11.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from jarvis-tools>=2021.07.19->alignn) (1.1.0)\n",
            "Collecting spglib>=1.14.1\n",
            "  Downloading spglib-1.16.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[K     |████████████████████████████████| 292 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.1->alignn) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.1->alignn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.1->alignn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.1->alignn) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->alignn) (2018.9)\n",
            "Requirement already satisfied: snowballstemmer in /usr/local/lib/python3.7/dist-packages (from pydocstyle>=6.0.0->alignn) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.1->alignn) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (1.24.3)\n",
            "Installing collected packages: xmltodict, spglib, scipy, pyflakes, pycodestyle, mccabe, matplotlib, importlib-metadata, pytorch-ignite, pydocstyle, pydantic, pandas, jarvis-tools, flake8, dgl-cu101, dgl, alignn\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.2\n",
            "    Uninstalling importlib-metadata-4.8.2:\n",
            "      Successfully uninstalled importlib-metadata-4.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed alignn-2021.11.14 dgl-0.6.1 dgl-cu101-0.6.1 flake8-4.0.1 importlib-metadata-4.2.0 jarvis-tools-2021.10.3 matplotlib-3.4.3 mccabe-0.6.1 pandas-1.3.4 pycodestyle-2.8.0 pydantic-1.8.2 pydocstyle-6.1.1 pyflakes-2.4.0 pytorch-ignite-0.4.7 scipy-1.7.2 spglib-1.16.2 xmltodict-0.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyyE-cHL2iOn",
        "outputId": "9016b18f-239d-418e-f8a9-b7c05dd73c1b"
      },
      "source": [
        "import os\n",
        "# Clone ALIGNN repo to get example folder\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "\n",
        "os.chdir('alignn')\n",
        "# Install using setup.py in case pip didn't work\n",
        "# !python setup.py develop\n",
        "\n",
        "!pip install dgl-cu111 # Colab has cuda 11.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alignn'...\n",
            "remote: Enumerating objects: 2034, done.\u001b[K\n",
            "remote: Counting objects: 100% (2034/2034), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1033/1033), done.\u001b[K\n",
            "remote: Total 2034 (delta 1295), reused 1596 (delta 937), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2034/2034), 1.05 MiB | 10.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1295/1295), done.\n",
            "Collecting dgl-cu111\n",
            "  Downloading dgl_cu111-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (41.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.0 MB 28 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2021.10.8)\n",
            "Installing collected packages: dgl-cu111\n",
            "Successfully installed dgl-cu111-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsJg4A_s2umV"
      },
      "source": [
        "Example folder with id_prop.csv and 'POSCAR files.'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy1tmx3V2uC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d714dc89-cd1d-4a4e-ebb4-e4b84a2f086b"
      },
      "source": [
        "!ls \"alignn/examples/sample_data\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config_example.json\t  POSCAR-JVASP-64045.vasp  POSCAR-JVASP-86097.vasp\n",
            "id_prop.csv\t\t  POSCAR-JVASP-64240.vasp  POSCAR-JVASP-86205.vasp\n",
            "POSCAR-JVASP-107772.vasp  POSCAR-JVASP-64377.vasp  POSCAR-JVASP-86436.vasp\n",
            "POSCAR-JVASP-10.vasp\t  POSCAR-JVASP-64584.vasp  POSCAR-JVASP-86726.vasp\n",
            "POSCAR-JVASP-13526.vasp   POSCAR-JVASP-64664.vasp  POSCAR-JVASP-86968.vasp\n",
            "POSCAR-JVASP-1372.vasp\t  POSCAR-JVASP-64719.vasp  POSCAR-JVASP-89025.vasp\n",
            "POSCAR-JVASP-14014.vasp   POSCAR-JVASP-64906.vasp  POSCAR-JVASP-89265.vasp\n",
            "POSCAR-JVASP-14441.vasp   POSCAR-JVASP-65062.vasp  POSCAR-JVASP-90228.vasp\n",
            "POSCAR-JVASP-14873.vasp   POSCAR-JVASP-65101.vasp  POSCAR-JVASP-90532.vasp\n",
            "POSCAR-JVASP-15345.vasp   POSCAR-JVASP-655.vasp    POSCAR-JVASP-90856.vasp\n",
            "POSCAR-JVASP-1996.vasp\t  POSCAR-JVASP-676.vasp    POSCAR-JVASP-97378.vasp\n",
            "POSCAR-JVASP-21210.vasp   POSCAR-JVASP-76308.vasp  POSCAR-JVASP-97499.vasp\n",
            "POSCAR-JVASP-22556.vasp   POSCAR-JVASP-76309.vasp  POSCAR-JVASP-97570.vasp\n",
            "POSCAR-JVASP-27901.vasp   POSCAR-JVASP-76312.vasp  POSCAR-JVASP-97677.vasp\n",
            "POSCAR-JVASP-28397.vasp   POSCAR-JVASP-76313.vasp  POSCAR-JVASP-97799.vasp\n",
            "POSCAR-JVASP-28565.vasp   POSCAR-JVASP-76318.vasp  POSCAR-JVASP-97915.vasp\n",
            "POSCAR-JVASP-28634.vasp   POSCAR-JVASP-76515.vasp  POSCAR-JVASP-97984.vasp\n",
            "POSCAR-JVASP-28704.vasp   POSCAR-JVASP-76516.vasp  POSCAR-JVASP-98167.vasp\n",
            "POSCAR-JVASP-42300.vasp   POSCAR-JVASP-76525.vasp  POSCAR-JVASP-98224.vasp\n",
            "POSCAR-JVASP-48166.vasp   POSCAR-JVASP-76528.vasp  POSCAR-JVASP-98225.vasp\n",
            "POSCAR-JVASP-50332.vasp   POSCAR-JVASP-76536.vasp  POSCAR-JVASP-98284.vasp\n",
            "POSCAR-JVASP-60596.vasp   POSCAR-JVASP-76548.vasp  POSCAR-JVASP-98550.vasp\n",
            "POSCAR-JVASP-60702.vasp   POSCAR-JVASP-76549.vasp  scripts\n",
            "POSCAR-JVASP-63912.vasp   POSCAR-JVASP-76562.vasp\n",
            "POSCAR-JVASP-64003.vasp   POSCAR-JVASP-76567.vasp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUNiKBBV211E"
      },
      "source": [
        "# 50 materials and their bandgap data generated with the script [generate_sample_data_reg.py](https://github.com/usnistgov/alignn/blob/main/alignn/examples/sample_data/scripts/generate_sample_data_reg.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbzuGCA332yS"
      },
      "source": [
        "# Train a model for 3 epochs and batch size of 2. Other parameters are provided in `config_example.json` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNHla4FDKRre"
      },
      "source": [
        "Command line train_folder.py is used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JkSMwx2cfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563c5749-0330-4901-d830-489c7d2fdbcf"
      },
      "source": [
        "import time\n",
        "t1=time.time()\n",
        "!train_folder.py --root_dir \"alignn/examples/sample_data\" --epochs 3 --config \"alignn/examples/sample_data/config_example.json\" --output_dir=temp\n",
        "t2=time.time()\n",
        "print ('Time in s',t2-t1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Using backend: pytorch\n",
            "MAX val: 6.149\n",
            "MIN val: 0.0\n",
            "MAD: 1.0520696\n",
            "Baseline MAE: 0.7102749999999998\n",
            "data range 6.149 0.0\n",
            "  0% 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/jarvis/core/graphs.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  r = torch.tensor(r).type(torch.get_default_dtype())\n",
            "100% 40/40 [00:01<00:00, 24.46it/s]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 40/40 [00:00<00:00, 231.05it/s]\n",
            "data range 1.681 0.0\n",
            "100% 5/5 [00:00<00:00, 22.09it/s]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 410.83it/s]\n",
            "data range 0.658 0.0\n",
            "100% 5/5 [00:00<00:00, 32.10it/s]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 387.07it/s]\n",
            "n_train: 40\n",
            "n_val: 5\n",
            "n_test: 5\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=3 batch_size=2 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False distributed=False n_early_stopping=None output_dir='temp' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 2,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 3,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "name='alignn' alignn_layers=4 gcn_layers=4 atom_input_features=92 edge_input_features=80 triplet_input_features=40 embedding_features=64 hidden_features=256 output_features=1 link='identity' zero_inflated=False classification=False\n",
            "Val_MAE: 1.5965\n",
            "Train_MAE: 1.5343\n",
            "Val_MAE: 0.7214\n",
            "Train_MAE: 1.3734\n",
            "Val_MAE: 0.3790\n",
            "Train_MAE: 1.4235\n",
            "Test MAE: 0.6168567091226578\n",
            "Time in s 56.610183000564575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOWVk7MV1hQ3"
      },
      "source": [
        "Use pretrained models such as models trained on JARVIS-DFT, QM9, Materials project, hMOF etc. databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16HHZ7TD3uRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27dfdb2b-7072-4860-cfeb-6ab73a10b7d3"
      },
      "source": [
        "!pretrained.py -h"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "usage: pretrained.py [-h] [--model_name MODEL_NAME]\n",
            "                     [--file_format FILE_FORMAT] [--file_path FILE_PATH]\n",
            "                     [--cutoff CUTOFF]\n",
            "\n",
            "Atomistic Line Graph Neural Network Pretrained Models\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model_name MODEL_NAME\n",
            "                        Choose a model from these 38\n",
            "                        models:jv_formation_energy_peratom_alignn,\n",
            "                        jv_optb88vdw_total_energy_alignn,\n",
            "                        jv_optb88vdw_bandgap_alignn, jv_mbj_bandgap_alignn,\n",
            "                        jv_spillage_alignn, jv_slme_alignn,\n",
            "                        jv_bulk_modulus_kv_alignn, jv_shear_modulus_gv_alignn,\n",
            "                        jv_n-Seebeck_alignn, jv_n-powerfact_alignn,\n",
            "                        jv_magmom_oszicar_alignn,\n",
            "                        jv_kpoint_length_unit_alignn, jv_avg_elec_mass_alignn,\n",
            "                        jv_avg_hole_mass_alignn, jv_epsx_alignn,\n",
            "                        jv_mepsx_alignn, jv_max_efg_alignn, jv_ehull_alignn,\n",
            "                        jv_dfpt_piezo_max_dielectric_alignn,\n",
            "                        jv_dfpt_piezo_max_dij_alignn,\n",
            "                        jv_exfoliation_energy_alignn, mp_e_form_alignnn,\n",
            "                        mp_gappbe_alignnn, qm9_U0_alignn, qm9_U_alignn,\n",
            "                        qm9_alpha_alignn, qm9_gap_alignn, qm9_G_alignn,\n",
            "                        qm9_HOMO_alignn, qm9_LUMO_alignn, qm9_ZPVE_alignn,\n",
            "                        hmof_co2_absp_alignnn, hmof_max_co2_adsp_alignnn,\n",
            "                        hmof_surface_area_m2g_alignnn,\n",
            "                        hmof_surface_area_m2cm3_alignnn, hmof_pld_alignnn,\n",
            "                        hmof_lcd_alignnn, hmof_void_fraction_alignnn\n",
            "  --file_format FILE_FORMAT\n",
            "                        poscar/cif/xyz/pdb file format.\n",
            "  --file_path FILE_PATH\n",
            "                        Path to file.\n",
            "  --cutoff CUTOFF       Distance cut-off for graph constuction, usually 8 for\n",
            "                        solids and 5 for molecules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bIT4hL71wmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cc5eff-ab18-497e-c348-190537e96f5c"
      },
      "source": [
        "!pretrained.py --model_name jv_formation_energy_peratom_alignn --file_format poscar --file_path alignn/examples/sample_data/POSCAR-JVASP-10.vasp"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "100% 47.5M/47.5M [00:02<00:00, 17.2MiB/s]\n",
            "name='alignn' alignn_layers=4 gcn_layers=4 atom_input_features=92 edge_input_features=80 triplet_input_features=40 embedding_features=64 hidden_features=256 output_features=1 link='identity' zero_inflated=False classification=False\n",
            "/usr/local/lib/python3.7/dist-packages/jarvis/core/graphs.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  r = torch.tensor(r).type(torch.get_default_dtype())\n",
            "Predicted value: jv_formation_energy_peratom_alignn alignn/examples/sample_data/POSCAR-JVASP-10.vasp [-0.7033944725990295]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v62Vzv2_2M2s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}