{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_ALIGNN_model_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/Training_ALIGNN_model_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZGR6D82ij-"
      },
      "source": [
        "# Table of contents\n",
        "\n",
        "1. Installing [ALIGNN](https://github.com/usnistgov/alignn)\n",
        "2. Example training for regression on 50 materials,\n",
        "3. Using pre-trained models to make fast predictions\n",
        "4. Using ALIGNN-FF model to predict the unrelaxed energy (fast), optimized strcture and energy, and EV curve\n",
        "5. Train ALIGNN-FF on a new dataset\n",
        "6. Training [JARVIS-DFT](https://jarvis.nist.gov/jarvisdft) 2D exfoliation energy model \n",
        "7. Training [QM9](http://quantum-machine.org/datasets/) U0 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFrl_N-S1Bxk",
        "outputId": "63f0c5bd-ff78-4a23-a694-2eeda33165e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --pre dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install --pre dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
        "!pip install alignn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu117/dgl-1.0.1%2Bcu117-cp38-cp38-manylinux1_x86_64.whl (266.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (3.0)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Installing collected packages: psutil, dgl\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-1.0.1+cu117 psutil-5.9.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb>=1.3.3\n",
            "  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from dglgo) (6.0)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml>=0.17.20\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.10.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.2.1)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting numpydoc>=1.1.0\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.10.1\n",
            "  Downloading isort-6.0.0b2-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting pycodestyle>=2.10.0\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx>=4.2\n",
            "  Downloading sphinx-6.1.3-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.8/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (4.64.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.13.1+cu116)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.26.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (555 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m555.3/555.3 KB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.25.1)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Collecting docutils<0.20,>=0.18\n",
            "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (6.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Collecting Pygments>=2.13\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7047 sha256=fdfd11f57a5434bc57fbd281984515cbf55a52a9e7bfa07bc96074073f7c5c9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, Pygments, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pygments-2.14.0 autopep8-2.0.2 dglgo-0.0.2 docutils-0.19 isort-6.0.0b2 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.5 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 sphinx-6.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alignn\n",
            "  Downloading alignn-2023.1.10-py2.py3-none-any.whl (15.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jarvis-tools>=2021.07.19\n",
            "  Downloading jarvis_tools-2023.1.8-py2.py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.3/973.3 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12.0\n",
            "  Downloading torch-1.12.0-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.8/dist-packages (from alignn) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.3.5)\n",
            "Collecting flake8>=3.9.1\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydocstyle>=6.0.0\n",
            "  Downloading pydocstyle-6.3.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pycodestyle>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from alignn) (2.10.0)\n",
            "Requirement already satisfied: dgl>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.0.1+cu117)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.22.4)\n",
            "Collecting pytorch-ignite==0.5.0.dev20221024\n",
            "  Downloading pytorch_ignite-0.5.0.dev20221024-py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing<3,>=2.2.1\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.10.5)\n",
            "Requirement already satisfied: matplotlib>=3.4.1 in /usr/local/lib/python3.8/dist-packages (from alignn) (3.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.2.1)\n",
            "Collecting ase\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from alignn) (1.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite==0.5.0.dev20221024->alignn) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.0->alignn) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl>=0.6.0->alignn) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl>=0.6.0->alignn) (3.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl>=0.6.0->alignn) (5.9.4)\n",
            "Collecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.1.0,>=3.0.0\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict>=0.11.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting spglib>=1.14.1\n",
            "  Downloading spglib-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.1/515.1 KB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.8/dist-packages (from jarvis-tools>=2021.07.19->alignn) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from jarvis-tools>=2021.07.19->alignn) (0.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->alignn) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->alignn) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->alignn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->alignn) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->alignn) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->alignn) (2022.7.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pydocstyle>=6.0.0->alignn) (2.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.2->alignn) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.1->alignn) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2.10)\n",
            "Installing collected packages: xmltodict, torch, spglib, pyparsing, pyflakes, pydocstyle, mccabe, pytorch-ignite, flake8, jarvis-tools, ase, alignn\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alignn-2023.1.10 ase-3.22.1 flake8-6.0.0 jarvis-tools-2023.1.8 mccabe-0.7.0 pydocstyle-6.3.0 pyflakes-3.0.1 pyparsing-2.4.7 pytorch-ignite-0.5.0.dev20221024 spglib-2.0.2 torch-1.12.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyyE-cHL2iOn",
        "outputId": "0a7ba9de-938e-41ea-da43-98bc798bc48f"
      },
      "source": [
        "import os\n",
        "!pwd\n",
        "os.chdir('/content')\n",
        "# Clone ALIGNN repo to get example folder\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "\n",
        "os.chdir('alignn')\n",
        "# Install using setup.py in case pip didn't work\n",
        "# !python setup.py develop\n",
        "\n",
        "#!pip install dgl-cu111 # Colab has cuda 11.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'alignn'...\n",
            "remote: Enumerating objects: 3330, done.\u001b[K\n",
            "remote: Counting objects: 100% (924/924), done.\u001b[K\n",
            "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
            "remote: Total 3330 (delta 711), reused 779 (delta 642), pack-reused 2406\u001b[K\n",
            "Receiving objects: 100% (3330/3330), 32.70 MiB | 15.49 MiB/s, done.\n",
            "Resolving deltas: 100% (1887/1887), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsJg4A_s2umV"
      },
      "source": [
        "Example folder with id_prop.csv and 'POSCAR files.'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy1tmx3V2uC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26bb7a9-c2a7-412d-d2fa-5983a747e6b4"
      },
      "source": [
        "!ls \"alignn/examples/sample_data\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config_example.json\t  POSCAR-JVASP-64045.vasp  POSCAR-JVASP-86097.vasp\n",
            "id_prop.csv\t\t  POSCAR-JVASP-64240.vasp  POSCAR-JVASP-86205.vasp\n",
            "POSCAR-JVASP-107772.vasp  POSCAR-JVASP-64377.vasp  POSCAR-JVASP-86436.vasp\n",
            "POSCAR-JVASP-10.vasp\t  POSCAR-JVASP-64584.vasp  POSCAR-JVASP-86726.vasp\n",
            "POSCAR-JVASP-13526.vasp   POSCAR-JVASP-64664.vasp  POSCAR-JVASP-86968.vasp\n",
            "POSCAR-JVASP-1372.vasp\t  POSCAR-JVASP-64719.vasp  POSCAR-JVASP-89025.vasp\n",
            "POSCAR-JVASP-14014.vasp   POSCAR-JVASP-64906.vasp  POSCAR-JVASP-89265.vasp\n",
            "POSCAR-JVASP-14441.vasp   POSCAR-JVASP-65062.vasp  POSCAR-JVASP-90228.vasp\n",
            "POSCAR-JVASP-14873.vasp   POSCAR-JVASP-65101.vasp  POSCAR-JVASP-90532.vasp\n",
            "POSCAR-JVASP-15345.vasp   POSCAR-JVASP-655.vasp    POSCAR-JVASP-90856.vasp\n",
            "POSCAR-JVASP-1996.vasp\t  POSCAR-JVASP-676.vasp    POSCAR-JVASP-97378.vasp\n",
            "POSCAR-JVASP-21210.vasp   POSCAR-JVASP-76308.vasp  POSCAR-JVASP-97499.vasp\n",
            "POSCAR-JVASP-22556.vasp   POSCAR-JVASP-76309.vasp  POSCAR-JVASP-97570.vasp\n",
            "POSCAR-JVASP-27901.vasp   POSCAR-JVASP-76312.vasp  POSCAR-JVASP-97677.vasp\n",
            "POSCAR-JVASP-28397.vasp   POSCAR-JVASP-76313.vasp  POSCAR-JVASP-97799.vasp\n",
            "POSCAR-JVASP-28565.vasp   POSCAR-JVASP-76318.vasp  POSCAR-JVASP-97915.vasp\n",
            "POSCAR-JVASP-28634.vasp   POSCAR-JVASP-76515.vasp  POSCAR-JVASP-97984.vasp\n",
            "POSCAR-JVASP-28704.vasp   POSCAR-JVASP-76516.vasp  POSCAR-JVASP-98167.vasp\n",
            "POSCAR-JVASP-42300.vasp   POSCAR-JVASP-76525.vasp  POSCAR-JVASP-98224.vasp\n",
            "POSCAR-JVASP-48166.vasp   POSCAR-JVASP-76528.vasp  POSCAR-JVASP-98225.vasp\n",
            "POSCAR-JVASP-50332.vasp   POSCAR-JVASP-76536.vasp  POSCAR-JVASP-98284.vasp\n",
            "POSCAR-JVASP-60596.vasp   POSCAR-JVASP-76548.vasp  POSCAR-JVASP-98550.vasp\n",
            "POSCAR-JVASP-60702.vasp   POSCAR-JVASP-76549.vasp  scripts\n",
            "POSCAR-JVASP-63912.vasp   POSCAR-JVASP-76562.vasp\n",
            "POSCAR-JVASP-64003.vasp   POSCAR-JVASP-76567.vasp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUNiKBBV211E"
      },
      "source": [
        "# 50 materials and their bandgap data generated with the script [generate_sample_data_reg.py](https://github.com/usnistgov/alignn/blob/main/alignn/examples/sample_data/scripts/generate_sample_data_reg.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbzuGCA332yS"
      },
      "source": [
        "# Train a model for 3 epochs and batch size of 2. Other parameters are provided in `config_example.json` file. For an involved training, use higher batch size such as 16 and epochs such as 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNHla4FDKRre"
      },
      "source": [
        "Command line train_folder.py is used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JkSMwx2cfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7c3335-a869-441a-80b4-75a4350488ff"
      },
      "source": [
        "import time\n",
        "t1=time.time()\n",
        "!train_folder.py --root_dir \"alignn/examples/sample_data\" --epochs 3 --batch_size 2 --config \"alignn/examples/sample_data/config_example.json\" --output_dir=temp\n",
        "t2=time.time()\n",
        "print ('Time in s',t2-t1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "MAX val: 6.149\n",
            "MIN val: 0.0\n",
            "MAD: 1.0520696\n",
            "Baseline MAE: 0.7102749999999998\n",
            "data range 6.149 0.0\n",
            "  0% 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "100% 40/40 [00:01<00:00, 23.34it/s]\n",
            "df                                                 atoms  ... target\n",
            "0   {'lattice_mat': [[-0.0, 4.517300851474054, 4.5...  ...  0.000\n",
            "1   {'lattice_mat': [[7.709535704177289, 2.46207e-...  ...  0.000\n",
            "2   {'lattice_mat': [[4.191262576674699, 0.0, -0.0...  ...  0.016\n",
            "3   {'lattice_mat': [[-0.0, 5.040771484524319, 5.0...  ...  0.000\n",
            "4   {'lattice_mat': [[1.6712283e-08, -2.5080296697...  ...  6.149\n",
            "5   {'lattice_mat': [[3.93712543178282, 0.0, 2.273...  ...  3.851\n",
            "6   {'lattice_mat': [[4.927781968323723, -0.0, 0.0...  ...  0.000\n",
            "7   {'lattice_mat': [[5.157077730332642, 0.0020004...  ...  4.030\n",
            "8   {'lattice_mat': [[9.067075684180468, -0.0, 0.0...  ...  1.197\n",
            "9   {'lattice_mat': [[3.790914410660539, -0.0, 0.0...  ...  0.000\n",
            "10  {'lattice_mat': [[3.2250494729190726, 2.216578...  ...  0.689\n",
            "11  {'lattice_mat': [[0.0, 5.129874508851702, 5.12...  ...  0.000\n",
            "12  {'lattice_mat': [[7.843871888963013, 0.0, 0.0]...  ...  0.924\n",
            "13  {'lattice_mat': [[3.3542337275744103, 0.0, 0.0...  ...  0.051\n",
            "14  {'lattice_mat': [[4.084155317570781, -1.066825...  ...  0.000\n",
            "15  {'lattice_mat': [[4.839493559425439, 9.7116505...  ...  0.000\n",
            "16  {'lattice_mat': [[1.6777483798834445, -2.90594...  ...  0.000\n",
            "17  {'lattice_mat': [[4.509029640475962, 0.0564034...  ...  4.907\n",
            "18  {'lattice_mat': [[4.089078911208881, 0.0, 0.0]...  ...  0.000\n",
            "19  {'lattice_mat': [[0.0, 4.893247728183244, 4.89...  ...  0.000\n",
            "20  {'lattice_mat': [[5.194393535053021, 0.0345773...  ...  0.000\n",
            "21  {'lattice_mat': [[3.5666343258756448, 0.0, 0.0...  ...  0.000\n",
            "22  {'lattice_mat': [[-0.0127275386492899, 4.47534...  ...  0.482\n",
            "23  {'lattice_mat': [[6.603532697435508, 0.0, -0.0...  ...  4.072\n",
            "24  {'lattice_mat': [[10.725911963093319, 1.159968...  ...  0.000\n",
            "25  {'lattice_mat': [[3.292134155794691, 0.0, 0.0]...  ...  0.502\n",
            "26  {'lattice_mat': [[10.37325585559557, -2.271858...  ...  1.569\n",
            "27  {'lattice_mat': [[-0.0, 5.037541505850243, 5.0...  ...  0.000\n",
            "28  {'lattice_mat': [[5.140164879556414, 0.3718366...  ...  0.000\n",
            "29  {'lattice_mat': [[9.407270982425844, 0.0171637...  ...  2.472\n",
            "30  {'lattice_mat': [[3.566933224304235, 0.0, -0.0...  ...  0.000\n",
            "31  {'lattice_mat': [[0.0, 4.936437902689708, 4.93...  ...  0.000\n",
            "32  {'lattice_mat': [[4.927229198330356, -0.0, -0....  ...  2.122\n",
            "33  {'lattice_mat': [[4.376835486482439, 0.0086562...  ...  0.000\n",
            "34  {'lattice_mat': [[0.0, 4.901572410735, 4.90157...  ...  0.000\n",
            "35  {'lattice_mat': [[4.284492173131309, 1.636192e...  ...  0.000\n",
            "36  {'lattice_mat': [[5.587070827330502, -0.006443...  ...  1.517\n",
            "37  {'lattice_mat': [[6.9098665629767275, 0.128626...  ...  2.341\n",
            "38  {'lattice_mat': [[0.0, 5.104615296684174, 5.10...  ...  0.000\n",
            "39  {'lattice_mat': [[6.850665464204784, -0.0, 0.0...  ...  0.560\n",
            "\n",
            "[40 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 40/40 [00:00<00:00, 667.30it/s]\n",
            "data range 1.681 0.0\n",
            "100% 5/5 [00:00<00:00, 19.24it/s]\n",
            "df                                                atoms  ... target\n",
            "0  {'lattice_mat': [[5.464512229851642, 0.0, -2.0...  ...  0.239\n",
            "1  {'lattice_mat': [[3.8114364321417686, 0.0, 0.0...  ...  0.000\n",
            "2  {'lattice_mat': [[3.5058938597621094, -3.08124...  ...  1.681\n",
            "3  {'lattice_mat': [[-1.833590720595598, 1.833590...  ...  0.000\n",
            "4  {'lattice_mat': [[0.0, 5.1858714074842, 5.1858...  ...  0.000\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 741.70it/s]\n",
            "data range 0.658 0.0\n",
            "100% 5/5 [00:00<00:00, 26.34it/s]\n",
            "df                                                atoms  ... target\n",
            "0  {'lattice_mat': [[-0.0, 4.326757913323647, 4.3...  ...  0.000\n",
            "1  {'lattice_mat': [[0.0, -3.9587610833154616, 0....  ...  0.658\n",
            "2  {'lattice_mat': [[4.157436115454804, -0.0, 0.0...  ...  0.000\n",
            "3  {'lattice_mat': [[-2.2512310528422197, 1.49649...  ...  0.000\n",
            "4  {'lattice_mat': [[7.2963518353359165, 0.0, 0.0...  ...  0.472\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 726.71it/s]\n",
            "n_train: 40\n",
            "n_val: 5\n",
            "n_test: 5\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=3 batch_size=2 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False normalize_graph_level_loss=False distributed=False n_early_stopping=None output_dir='temp' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 2,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 3,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "Val_MAE: 1.6030\n",
            "Train_MAE: 1.5383\n",
            "Val_MAE: 0.7162\n",
            "Train_MAE: 1.3723\n",
            "Val_MAE: 0.3797\n",
            "Train_MAE: 1.4241\n",
            "Test MAE: 0.61751669049263\n",
            "Time taken (s): 71.14949226379395\n",
            "Time in s 84.25245714187622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "tE8JPqIWQ10F",
        "outputId": "3aa56624-c5af-4efa-c2b8-f337f1ad294a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alignn\tLICENSE.rst  pyproject.toml  README.md\tsetup.py  temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model produces *.pt files which are the trained models."
      ],
      "metadata": {
        "id": "WnlQxz2eRSoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls temp"
      ],
      "metadata": {
        "id": "ARFUTpZjQ9JN",
        "outputId": "0eeeb2ed-974d-4dac-d031-1c6327b28d01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_2.pt\t\t mad\n",
            "checkpoint_3.pt\t\t prediction_results_test_set.csv\n",
            "config.json\t\t prediction_results_train_set.csv\n",
            "history_train.json\t test_data_data_range\n",
            "history_val.json\t train_data_data_range\n",
            "ids_train_val_test.json  val_data_data_range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load a trained model above as the following:"
      ],
      "metadata": {
        "id": "5dWY2SN3SAWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from alignn.models.alignn import ALIGNN, ALIGNNConfig\n",
        "import torch\n",
        "output_features =  1\n",
        "filename = 'temp/checkpoint_3.pt'\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "model = ALIGNN(ALIGNNConfig(name=\"alignn\", output_features=output_features))\n",
        "model.load_state_dict(torch.load(filename, map_location=device)[\"model\"])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "KKwVQwvCRfkD",
        "outputId": "141b693d-8d46-4b63-f08c-25e538876128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALIGNN(\n",
              "  (atom_embedding): MLPLayer(\n",
              "    (layer): Sequential(\n",
              "      (0): Linear(in_features=92, out_features=256, bias=True)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "  )\n",
              "  (edge_embedding): Sequential(\n",
              "    (0): RBFExpansion()\n",
              "    (1): MLPLayer(\n",
              "      (layer): Sequential(\n",
              "        (0): Linear(in_features=80, out_features=64, bias=True)\n",
              "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU()\n",
              "      )\n",
              "    )\n",
              "    (2): MLPLayer(\n",
              "      (layer): Sequential(\n",
              "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (angle_embedding): Sequential(\n",
              "    (0): RBFExpansion()\n",
              "    (1): MLPLayer(\n",
              "      (layer): Sequential(\n",
              "        (0): Linear(in_features=40, out_features=64, bias=True)\n",
              "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU()\n",
              "      )\n",
              "    )\n",
              "    (2): MLPLayer(\n",
              "      (layer): Sequential(\n",
              "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (alignn_layers): ModuleList(\n",
              "    (0): ALIGNNConv(\n",
              "      (node_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (edge_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ALIGNNConv(\n",
              "      (node_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (edge_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): ALIGNNConv(\n",
              "      (node_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (edge_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): ALIGNNConv(\n",
              "      (node_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (edge_update): EdgeGatedGraphConv(\n",
              "        (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (gcn_layers): ModuleList(\n",
              "    (0): EdgeGatedGraphConv(\n",
              "      (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): EdgeGatedGraphConv(\n",
              "      (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): EdgeGatedGraphConv(\n",
              "      (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): EdgeGatedGraphConv(\n",
              "      (src_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (edge_gate): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_edges): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (src_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dst_update): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bn_nodes): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (readout): AvgPooling()\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can build graph for a given structure and make a prediction as follows:"
      ],
      "metadata": {
        "id": "N7cNP1YqShuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.core.atoms import Atoms\n",
        "from alignn.graphs import Graph\n",
        "cutoff = 8.0\n",
        "max_neighbors = 12\n",
        "atoms = Atoms.from_poscar('alignn/examples/sample_data/POSCAR-JVASP-10.vasp')\n",
        "g, lg = Graph.atom_dgl_multigraph(\n",
        "    atoms, cutoff=float(cutoff), max_neighbors=max_neighbors,\n",
        ")\n",
        "out_data = (\n",
        "    model([g.to(device), lg.to(device)])\n",
        "    .detach()\n",
        "    .cpu()\n",
        "    .numpy()\n",
        "    .flatten()\n",
        "    .tolist()\n",
        ")\n",
        "print ('output', out_data[0])"
      ],
      "metadata": {
        "id": "kfr_EGHRS_aU",
        "outputId": "007e3854-64d4-456c-80f9-3d37b2c83686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/alignn/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 2.280003309249878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already trained multiple models on several large datasets which can be used with the pretrained.py executable."
      ],
      "metadata": {
        "id": "QbzTNJ-WTgfF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOWVk7MV1hQ3"
      },
      "source": [
        "Use pretrained models such as models trained on JARVIS-DFT, QM9, Materials project, hMOF etc. databases. The models are downloaded from figshare. See the list here: https://github.com/usnistgov/alignn/blob/main/alignn/pretrained.py#L28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16HHZ7TD3uRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc90fa8-3a4d-4c64-8c4a-1cb5b9ef1429"
      },
      "source": [
        "!pretrained.py -h"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: pretrained.py\n",
            "       [-h]\n",
            "       [--model_name MODEL_NAME]\n",
            "       [--file_format FILE_FORMAT]\n",
            "       [--file_path FILE_PATH]\n",
            "       [--cutoff CUTOFF]\n",
            "       [--max_neighbors MAX_NEIGHBORS]\n",
            "\n",
            "Atomistic\n",
            "Line Graph\n",
            "Neural\n",
            "Network\n",
            "Pretrained\n",
            "Models\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model_name MODEL_NAME\n",
            "    Choose a\n",
            "    model from\n",
            "    these 40 mo\n",
            "    dels:jv_for\n",
            "    mation_ener\n",
            "    gy_peratom_\n",
            "    alignn, jv_\n",
            "    optb88vdw_t\n",
            "    otal_energy\n",
            "    _alignn, jv\n",
            "    _optb88vdw_\n",
            "    bandgap_ali\n",
            "    gnn, jv_mbj\n",
            "    _bandgap_al\n",
            "    ignn, jv_sp\n",
            "    illage_alig\n",
            "    nn, jv_slme\n",
            "    _alignn, jv\n",
            "    _bulk_modul\n",
            "    us_kv_align\n",
            "    n, jv_shear\n",
            "    _modulus_gv\n",
            "    _alignn,\n",
            "    jv_n-Seebec\n",
            "    k_alignn,\n",
            "    jv_n-powerf\n",
            "    act_alignn,\n",
            "    jv_magmom_o\n",
            "    szicar_alig\n",
            "    nn, jv_kpoi\n",
            "    nt_length_u\n",
            "    nit_alignn,\n",
            "    jv_avg_elec\n",
            "    _mass_align\n",
            "    n, jv_avg_h\n",
            "    ole_mass_al\n",
            "    ignn, jv_ep\n",
            "    sx_alignn, \n",
            "    jv_mepsx_al\n",
            "    ignn, jv_ma\n",
            "    x_efg_align\n",
            "    n, jv_ehull\n",
            "    _alignn, jv\n",
            "    _dfpt_piezo\n",
            "    _max_dielec\n",
            "    tric_alignn\n",
            "    , jv_dfpt_p\n",
            "    iezo_max_di\n",
            "    j_alignn, j\n",
            "    v_exfoliati\n",
            "    on_energy_a\n",
            "    lignn, jv_s\n",
            "    upercon_tc_\n",
            "    alignn, mp_\n",
            "    e_form_alig\n",
            "    nnn, mp_gap\n",
            "    pbe_alignnn\n",
            "    , qm9_U0_al\n",
            "    ignn, qm9_U\n",
            "    _alignn, qm\n",
            "    9_alpha_ali\n",
            "    gnn, qm9_ga\n",
            "    p_alignn, q\n",
            "    m9_G_alignn\n",
            "    , qm9_HOMO_\n",
            "    alignn, qm9\n",
            "    _LUMO_align\n",
            "    n, qm9_ZPVE\n",
            "    _alignn, hm\n",
            "    of_co2_absp\n",
            "    _alignnn, h\n",
            "    mof_max_co2\n",
            "    _adsp_align\n",
            "    nn, hmof_su\n",
            "    rface_area_\n",
            "    m2g_alignnn\n",
            "    , hmof_surf\n",
            "    ace_area_m2\n",
            "    cm3_alignnn\n",
            "    , hmof_pld_\n",
            "    alignnn, hm\n",
            "    of_lcd_alig\n",
            "    nnn, hmof_v\n",
            "    oid_fractio\n",
            "    n_alignnn, \n",
            "    jv_pdos_ali\n",
            "    gnn\n",
            "  --file_format FILE_FORMAT\n",
            "    poscar/cif/\n",
            "    xyz/pdb\n",
            "    file\n",
            "    format.\n",
            "  --file_path FILE_PATH\n",
            "    Path to\n",
            "    file.\n",
            "  --cutoff CUTOFF\n",
            "    Distance\n",
            "    cut-off for\n",
            "    graph const\n",
            "    uction,\n",
            "    usually 8\n",
            "    for solids\n",
            "    and 5 for\n",
            "    molecules.\n",
            "  --max_neighbors MAX_NEIGHBORS\n",
            "    Maximum\n",
            "    number of\n",
            "    nearest\n",
            "    neighbors\n",
            "    in the\n",
            "    periodic\n",
            "    atomistic\n",
            "    graph const\n",
            "    ruction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bIT4hL71wmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e20954b-16af-46cc-85fd-a13a890f3965"
      },
      "source": [
        "!pretrained.py --model_name jv_formation_energy_peratom_alignn --file_format poscar --file_path alignn/examples/sample_data/POSCAR-JVASP-10.vasp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 47.5M/47.5M [00:02<00:00, 17.3MiB/s]\n",
            "Using chk file jv_formation_energy_peratom_alignn/checkpoint_300.pt from  ['jv_formation_energy_peratom_alignn/checkpoint_300.pt']\n",
            "Path /usr/local/bin/jv_formation_energy_peratom_alignn.zip\n",
            "Predicted value: jv_formation_energy_peratom_alignn alignn/examples/sample_data/POSCAR-JVASP-10.vasp [-0.70339435338974]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ALIGNN-FF pretrained model to get unrelaxed energy and relaxed structure"
      ],
      "metadata": {
        "id": "yMhz-GpH2hfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!run_alignn_ff.py --file_path alignn/examples/sample_data/POSCAR-JVASP-10.vasp --task=\"unrelaxed_energy\""
      ],
      "metadata": {
        "id": "6X67E61h2kge",
        "outputId": "caf2c660-0816-4ba3-a1dd-65b9086b1555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_path /usr/local/lib/python3.8/dist-packages/alignn/ff\n",
            "/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "Energy(eV) (-11.776981830596924, array([[ 0.0000000e+00,  3.7252903e-09,  9.3132257e-10],\n",
            "       [ 0.0000000e+00,  2.1071173e-07, -1.7778256e-03],\n",
            "       [ 0.0000000e+00, -2.1059532e-07,  1.7777842e-03]], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!run_alignn_ff.py --file_path alignn/examples/sample_data/POSCAR-JVASP-10.vasp --task=\"optimize\""
      ],
      "metadata": {
        "id": "sGiXomqD21eE",
        "outputId": "a53d8552-6079-401f-9b56-4d4cc154ceb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_path /usr/local/lib/python3.8/dist-packages/alignn/ff\n",
            "OPTIMIZATION\n",
            "/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "a= 1.678 Ang b= 2.906 Ang c= 6.221 Ang Volume= 60.658 amu/a3 PE=-11.77698 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.676 Ang b= 2.903 Ang c= 6.223 Ang Volume= 60.556 amu/a3 PE=-11.77832 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.673 Ang b= 2.897 Ang c= 6.228 Ang Volume= 60.355 amu/a3 PE=-11.78092 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.668 Ang b= 2.888 Ang c= 6.235 Ang Volume= 60.062 amu/a3 PE=-11.78462 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.661 Ang b= 2.877 Ang c= 6.245 Ang Volume= 59.692 amu/a3 PE=-11.78918 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.653 Ang b= 2.863 Ang c= 6.259 Ang Volume= 59.261 amu/a3 PE=-11.79420 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.644 Ang b= 2.848 Ang c= 6.277 Ang Volume= 58.798 amu/a3 PE=-11.79909 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.635 Ang b= 2.832 Ang c= 6.301 Ang Volume= 58.340 amu/a3 PE=-11.80319 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.624 Ang b= 2.814 Ang c= 6.335 Ang Volume= 57.907 amu/a3 PE=-11.80618 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.614 Ang b= 2.796 Ang c= 6.382 Ang Volume= 57.614 amu/a3 PE=-11.80765 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.606 Ang b= 2.782 Ang c= 6.443 Ang Volume= 57.575 amu/a3 PE=-11.80819 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.606 Ang b= 2.782 Ang c= 6.445 Ang Volume= 57.617 amu/a3 PE=-11.80841 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.607 Ang b= 2.784 Ang c= 6.448 Ang Volume= 57.698 amu/a3 PE=-11.80883 eV KE= 0.00000 eV T= 0.000 K \n",
            "a= 1.608 Ang b= 2.786 Ang c= 6.453 Ang Volume= 57.818 amu/a3 PE=-11.80939 eV KE= 0.00000 eV T= 0.000 K \n",
            "initial struct:\n",
            "VSe2\n",
            "1.0\n",
            "1.6777483798834445 -2.9059452409270157 -1.1e-15\n",
            "1.6777483798834438 2.9059452409270126 -7e-16\n",
            "-6.5e-15 -8e-16 6.220805465667012\n",
            "V Se\n",
            "1 2\n",
            "Cartesian\n",
            "0.0 0.0 0.0\n",
            "1.67775 -0.9686519372999812 4.6529213966213625\n",
            "1.67775 0.9686519372999813 1.5678886033786343\n",
            "\n",
            "final struct:\n",
            "VSe2\n",
            "1.0\n",
            "1.6083028523964393 -2.785663635086563 2.655152296612777e-06\n",
            "1.6083028607260765 2.7856636398956796 -2.6472172418701082e-06\n",
            "1.4710913464149131e-08 -5.675435468951426e-06 6.452587626731316\n",
            "V Se\n",
            "1 2\n",
            "Cartesian\n",
            "1.6086832039991955e-06 -3.397640580244233e-07 1.7983984100003832e-06\n",
            "1.6083040624446991 -0.9285619719519722 4.822446846707405\n",
            "1.6083040553107482 0.928556433459851 1.630144955964686\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!run_alignn_ff.py --file_path alignn/examples/sample_data/POSCAR-JVASP-10.vasp --task=\"ev_curve\""
      ],
      "metadata": {
        "id": "lSkc-nuZ3jWw",
        "outputId": "3b256d30-4923-4236-fb2d-291aaf33b43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_path /usr/local/lib/python3.8/dist-packages/alignn/ff\n",
            "/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "E [-11.59964418 -11.74018407 -11.77280045 -11.78283548 -11.78363013\n",
            " -11.77698183 -11.76358366 -11.74409294 -11.71868992 -11.68687391]\n",
            "V [52.00698610745743, 53.66666028373519, 55.3612736919685, 57.09119028249023, 58.85677400563329, 60.6583888117305, 62.496398651114745, 64.3711674741189, 66.28305923107584, 68.23243787231843]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train ALIGNN-FF model"
      ],
      "metadata": {
        "id": "1EJ8-7dk3rva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!train_folder_ff.py --root_dir \"alignn/examples/sample_data_ff\" --config \"alignn/examples/sample_data_ff/config_example_atomwise.json\" --output_dir=temp"
      ],
      "metadata": {
        "id": "-_gLKbTf3uk7",
        "outputId": "aad9500a-60be-4f3d-dd78-410d0bd8843d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len dataset 50\n",
            "MAX val: -24.52653862\n",
            "MIN val: -42.04135008\n",
            "MAD: 7.884625411000001\n",
            "Baseline MAE: 7.128754169400001\n",
            "data range -24.52653862 -42.04135008\n",
            "\r  0% 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "100% 40/40 [00:00<00:00, 43.98it/s]\n",
            "df        target  ...    jid\n",
            "0  -24.558198  ...  15609\n",
            "1  -42.030165  ...  15608\n",
            "2  -42.040710  ...  15608\n",
            "3  -24.544487  ...  15609\n",
            "4  -24.549292  ...  15609\n",
            "5  -42.040186  ...  15608\n",
            "6  -42.016896  ...  15608\n",
            "7  -42.041135  ...  15608\n",
            "8  -42.030172  ...  15608\n",
            "9  -29.311899  ...  15607\n",
            "10 -42.041350  ...  15608\n",
            "11 -24.549425  ...  15609\n",
            "12 -42.038933  ...  15608\n",
            "13 -42.040889  ...  15608\n",
            "14 -42.039553  ...  15608\n",
            "15 -42.029257  ...  15608\n",
            "16 -29.312428  ...  15607\n",
            "17 -42.040889  ...  15608\n",
            "18 -29.312862  ...  15607\n",
            "19 -24.544738  ...  15609\n",
            "20 -42.019225  ...  15608\n",
            "21 -42.039996  ...  15608\n",
            "22 -42.039996  ...  15608\n",
            "23 -24.549290  ...  15609\n",
            "24 -42.002229  ...  15608\n",
            "25 -42.030166  ...  15608\n",
            "26 -24.549425  ...  15609\n",
            "27 -24.552079  ...  15609\n",
            "28 -42.016896  ...  15608\n",
            "29 -42.040184  ...  15608\n",
            "30 -29.313096  ...  15607\n",
            "31 -24.527151  ...  15609\n",
            "32 -42.032726  ...  15608\n",
            "33 -24.552075  ...  15609\n",
            "34 -24.527154  ...  15609\n",
            "35 -29.312800  ...  15607\n",
            "36 -42.002227  ...  15608\n",
            "37 -24.558202  ...  15609\n",
            "38 -24.526539  ...  15609\n",
            "39 -42.030172  ...  15608\n",
            "\n",
            "[40 rows x 6 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 40/40 [00:00<00:00, 849.26it/s]\n",
            "data range -24.54474058 -42.04071003\n",
            "100% 5/5 [00:00<00:00, 53.24it/s]\n",
            "df       target  ...    jid\n",
            "0 -24.544741  ...  15609\n",
            "1 -24.558797  ...  15609\n",
            "2 -42.040710  ...  15608\n",
            "3 -29.312159  ...  15607\n",
            "4 -29.311952  ...  15607\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 458.63it/s]\n",
            "data range -24.55819782 -42.03955494\n",
            "100% 5/5 [00:00<00:00, 46.61it/s]\n",
            "df       target  ...    jid\n",
            "0 -24.558198  ...  15609\n",
            "1 -42.039555  ...  15608\n",
            "2 -29.312791  ...  15607\n",
            "3 -42.029256  ...  15608\n",
            "4 -29.312429  ...  15607\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 554.61it/s]\n",
            "n_train: 40\n",
            "n_val: 5\n",
            "n_test: 5\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=3 batch_size=2 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='l1' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=False progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=False num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False normalize_graph_level_loss=False distributed=False n_early_stopping=None output_dir='temp' model=ALIGNNAtomWiseConfig(name='alignn_atomwise', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, grad_multiplier=-1, calculate_gradient=True, atomwise_output_features=3, graphwise_weight=0.85, gradwise_weight=0.05, stresswise_weight=0.05, atomwise_weight=0.05, link='identity', zero_inflated=False, classification=False)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 2,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'l1',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 3,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'atomwise_output_features': 3,\n",
            "           'atomwise_weight': 0.05,\n",
            "           'calculate_gradient': True,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'grad_multiplier': -1,\n",
            "           'gradwise_weight': 0.05,\n",
            "           'graphwise_weight': 0.85,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn_atomwise',\n",
            "           'output_features': 1,\n",
            "           'stresswise_weight': 0.05,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': False,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': False,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "TrainLoss Epoch 0 total 130.12498193979263 out 7.480552700161934 atom 0.4205492946298318 grad 0.01733575374173365 stress 2.5176925698766857\n",
            "Saving data for epoch: 0\n",
            "ValLoss Epoch 0 total 0.9229794442653656 out 0.36248016357421875 atom 0.20344786350178765 grad 0.009460022839114873 stress 2.8547235106405164\n",
            "TrainLoss Epoch 1 total 19.854396045207977 out 0.9548561573028564 atom 0.20680722037683308 grad 0.016850458171060415 stress 3.398183008581307\n",
            "ValLoss Epoch 1 total 3.4113743901252747 out 1.8229036331176758 atom 0.25263089152722384 grad 0.008425975667720801 stress 2.863325897164085\n",
            "TrainLoss Epoch 2 total 22.987701281905174 out 1.1715710639953614 atom 0.16559625868690392 grad 0.0169404602865175 stress 2.8884559912202747\n",
            "ValLoss Epoch 2 total 1.0481610596179962 out 0.4372735023498535 atom 0.1825272994406987 grad 0.008752041482572772 stress 2.8566820792004335\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([10, 3, 3])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "TestLoss 2 2.405210852622986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated model is saved as best_model.pt"
      ],
      "metadata": {
        "id": "M-6U-D-V40lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr temp"
      ],
      "metadata": {
        "id": "qvgrKa9q4oBu",
        "outputId": "a03f84af-e26f-468f-e0a0-ac00fda6ca84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 110996\n",
            "-rw-r--r-- 1 root root 48648565 Mar  6 15:01 checkpoint_2.pt\n",
            "-rw-r--r-- 1 root root 48648565 Mar  6 15:01 checkpoint_3.pt\n",
            "-rw-r--r-- 1 root root      244 Mar  6 15:01 prediction_results_test_set.csv\n",
            "-rw-r--r-- 1 root root      222 Mar  6 15:01 prediction_results_train_set.csv\n",
            "drwxr-xr-x 6 root root     4096 Mar  6 15:03 ..\n",
            "-rw-r--r-- 1 root root       68 Mar  6 15:03 mad\n",
            "-rw-r--r-- 1 root root      489 Mar  6 15:03 ids_train_val_test.json\n",
            "-rw-r--r-- 1 root root       34 Mar  6 15:03 train_data_data_range\n",
            "-rw-r--r-- 1 root root       34 Mar  6 15:03 val_data_data_range\n",
            "-rw-r--r-- 1 root root       34 Mar  6 15:03 test_data_data_range\n",
            "-rw-r--r-- 1 root root     1785 Mar  6 15:03 config.json\n",
            "-rw-r--r-- 1 root root 16177149 Mar  6 15:04 best_model.pt\n",
            "-rw-r--r-- 1 root root    98076 Mar  6 15:04 Train_results.json\n",
            "-rw-r--r-- 1 root root     9479 Mar  6 15:04 Val_results.json\n",
            "-rw-r--r-- 1 root root      249 Mar  6 15:06 history_train.json\n",
            "-rw-r--r-- 1 root root      254 Mar  6 15:06 history_val.json\n",
            "drwxr-xr-x 2 root root     4096 Mar  6 15:06 .\n",
            "-rw-r--r-- 1 root root    14736 Mar  6 15:06 Test_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train a model for JARVIS-DFT 2D Exfoliation energy"
      ],
      "metadata": {
        "id": "kC8yi5z7Sh3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are quite a few datasets available here:https://jarvis-tools.readthedocs.io/en/master/databases.html\n",
        "In the following example, we will use the JARVIS-DFT 2D dataset"
      ],
      "metadata": {
        "id": "01bLUnEF4anq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data in id_prop.csv format"
      ],
      "metadata": {
        "id": "6e0uz_WaUmbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.figshare import data as jdata\n",
        "from jarvis.core.atoms import Atoms\n",
        "import os\n",
        "\n",
        "cwd = os.getcwd() #current working directory\n",
        "temp_dir_name = \"DataDir_ExfoEnergy\" \n",
        "os.makedirs(temp_dir_name)\n",
        "os.chdir(temp_dir_name)\n",
        "\n",
        "dft_3d = jdata(\"dft_3d\")\n",
        "prop = \"exfoliation_energy\" #\"optb88vdw_bandgap\"\n",
        "f = open(\"id_prop.csv\", \"w\")\n",
        "# count = 0\n",
        "for i in dft_3d:\n",
        "    atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "    jid = i[\"jid\"]\n",
        "    poscar_name = \"POSCAR-\" + jid + \".vasp\"\n",
        "    target = i[prop]\n",
        "    if target != \"na\":\n",
        "        atoms.write_poscar(poscar_name)\n",
        "        f.write(\"%s,%6f\\n\" % (poscar_name, target))\n",
        "        # count += 1\n",
        "        # if count == max_samples:\n",
        "        #     break\n",
        "f.close()\n",
        "\n",
        "os.chdir(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apVVRqVgSdbG",
        "outputId": "4f74186b-113d-4b22-a2dd-be1f925d602c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40.8M/40.8M [00:02<00:00, 16.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v62Vzv2_2M2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1b636b-0c75-4313-8f0c-98814b541fae"
      },
      "source": [
        "!ls -altr  DataDir_ExfoEnergy/*.vasp | wc -l\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !wc -l DataDir_ExfoEnergy/id_prop.csv "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW9wmpsToBR",
        "outputId": "e3e4b957-3668-4e5a-b543-a40fe62951dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "813 DataDir_ExfoEnergy/id_prop.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "t1=time.time()\n",
        "!train_folder.py --root_dir \"DataDir_ExfoEnergy\" --epochs 1 --batch_size 64 --config \"alignn/examples/sample_data/config_example.json\" --output_dir=\"ExfoEnOut\"\n",
        "t2=time.time()\n",
        "print ('Time in s',t2-t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8aEhUTHT-AV",
        "outputId": "f6c8ab96-9a28-4294-d433-9a400c4ad6d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX val: 948.93\n",
            "MIN val: 0.03\n",
            "MAD: 62.629814227293544\n",
            "Baseline MAE: 61.033631528964854\n",
            "data range 948.93 0.03\n",
            "\r  0% 0/650 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/alignn/graphs.py:237: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
            "  g.ndata[\"lattice_mat\"] = torch.tensor(\n",
            "100% 650/650 [00:19<00:00, 34.17it/s]\n",
            "df                                                  atoms  ...  target\n",
            "0    {'lattice_mat': [[4.068739385474898, 0.0, 0.0]...  ...  124.80\n",
            "1    {'lattice_mat': [[7.709090937662098, -2.102315...  ...   97.28\n",
            "2    {'lattice_mat': [[4.18330070114463, -2.1811718...  ...   98.21\n",
            "3    {'lattice_mat': [[3.274124772794936, 0.0, 0.0]...  ...   39.40\n",
            "4    {'lattice_mat': [[3.2508933612187385, -3.80957...  ...   86.61\n",
            "..                                                 ...  ...     ...\n",
            "645  {'lattice_mat': [[6.96345111183412, 0.01744498...  ...   82.79\n",
            "646  {'lattice_mat': [[6.074176070684672, 0.0, 0.0]...  ...   95.03\n",
            "647  {'lattice_mat': [[3.5368172151577393, 0.0, 0.0...  ...   44.70\n",
            "648  {'lattice_mat': [[3.8974643117938466, 3e-16, -...  ...   37.07\n",
            "649  {'lattice_mat': [[1.977626102103902, -3.425348...  ...  200.25\n",
            "\n",
            "[650 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 650/650 [00:00<00:00, 1401.86it/s]\n",
            "data range 388.51 18.3\n",
            "100% 81/81 [00:01<00:00, 44.27it/s]\n",
            "df                                                 atoms  ...  target\n",
            "0   {'lattice_mat': [[5.948019721865907, 0.0021082...  ...   65.55\n",
            "1   {'lattice_mat': [[4.265342521259204, 0.0, -0.0...  ...  132.96\n",
            "2   {'lattice_mat': [[6.5042951955071375, 0.0, 0.0...  ...  170.78\n",
            "3   {'lattice_mat': [[6.310092154720664, -0.097687...  ...   96.39\n",
            "4   {'lattice_mat': [[3.6418347517587497, 0.0, 0.0...  ...  106.02\n",
            "..                                                ...  ...     ...\n",
            "76  {'lattice_mat': [[6.289948246336297, -3.555869...  ...   48.54\n",
            "77  {'lattice_mat': [[4.197506462853729, 0.0, 0.0]...  ...  221.48\n",
            "78  {'lattice_mat': [[4.121696885293283, 1e-16, -0...  ...   57.38\n",
            "79  {'lattice_mat': [[3.2363551559768626, 0.003364...  ...   79.55\n",
            "80  {'lattice_mat': [[3.465913931489915, -0.001517...  ...   55.34\n",
            "\n",
            "[81 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 81/81 [00:00<00:00, 1401.91it/s]\n",
            "data range 903.94 0.95\n",
            "100% 81/81 [00:01<00:00, 48.38it/s]\n",
            "df                                                 atoms  ...  target\n",
            "0   {'lattice_mat': [[2.1089700482587457, -3.65284...  ...   27.17\n",
            "1   {'lattice_mat': [[2.0635670442116743, -3.57420...  ...   82.29\n",
            "2   {'lattice_mat': [[3.58228425458374, -6.2046991...  ...   87.81\n",
            "3   {'lattice_mat': [[2.040488820334205, -3.534229...  ...  144.32\n",
            "4   {'lattice_mat': [[2.179274206250364, -3.774614...  ...   33.70\n",
            "..                                                ...  ...     ...\n",
            "76  {'lattice_mat': [[0.0, 4.545975624945906, -0.0...  ...   54.29\n",
            "77  {'lattice_mat': [[9.430790786281582, -0.0, -0....  ...   78.64\n",
            "78  {'lattice_mat': [[4.148345402828182, 0.0, 0.0]...  ...   55.48\n",
            "79  {'lattice_mat': [[3.4572806623707795, -0.00026...  ...   88.52\n",
            "80  {'lattice_mat': [[3.711812654584356, -2.043802...  ...  226.22\n",
            "\n",
            "[81 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 81/81 [00:00<00:00, 1223.01it/s]\n",
            "n_train: 650\n",
            "n_val: 81\n",
            "n_test: 81\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=1 batch_size=64 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False normalize_graph_level_loss=False distributed=False n_early_stopping=None output_dir='ExfoEnOut' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 64,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 1,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'ExfoEnOut',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "Val_MAE: 109.1313\n",
            "Train_MAE: 120.3741\n",
            "Test MAE: 114.45367982284522\n",
            "Time taken (s): 232.7245500087738\n",
            "Time in s 263.32866621017456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ExfoEnOut\t "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luExy9FkWJ81",
        "outputId": "d3bf3875-7e36-4cd7-a92e-25693b62d947"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_1.pt     ids_train_val_test.json\t      test_data_data_range\n",
            "config.json\t    mad\t\t\t\t      train_data_data_range\n",
            "history_train.json  prediction_results_test_set.csv   val_data_data_range\n",
            "history_val.json    prediction_results_train_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here checkpoints are the model parameter files that can be loaded in torch library to make predictions such as [this example](https://github.com/usnistgov/alignn/blob/main/alignn/scripts/predict.py)."
      ],
      "metadata": {
        "id": "zzrjEIMKpdFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/alignn/ExfoEnOut/prediction_results_test_set.csv')"
      ],
      "metadata": {
        "id": "EhzUYeD1oYpD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are predictions on 10 % held dataset that the model has never seen"
      ],
      "metadata": {
        "id": "Tz-AsQnNo9-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hGGnsXseo7Qz",
        "outputId": "dec2e492-11e8-4159-bd72-f6252a34c43b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         id      target  prediction\n",
              "0   POSCAR-JVASP-12918.vasp   27.170000   -6.190604\n",
              "1    POSCAR-JVASP-2035.vasp   82.290001   -7.343407\n",
              "2   POSCAR-JVASP-13942.vasp   87.809998   -7.393437\n",
              "3     POSCAR-JVASP-278.vasp  144.320007   -7.004790\n",
              "4   POSCAR-JVASP-10173.vasp   33.700001   -6.655459\n",
              "..                      ...         ...         ...\n",
              "76   POSCAR-JVASP-4364.vasp   54.290001   -8.039992\n",
              "77  POSCAR-JVASP-29480.vasp   78.639999   -8.734395\n",
              "78  POSCAR-JVASP-28375.vasp   55.480000   -7.635911\n",
              "79    POSCAR-JVASP-590.vasp   88.519997   -7.158084\n",
              "80   POSCAR-JVASP-4741.vasp  226.220001   -5.181231\n",
              "\n",
              "[81 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16c625e4-8eee-4e86-92ff-e9ae56e28f73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>POSCAR-JVASP-12918.vasp</td>\n",
              "      <td>27.170000</td>\n",
              "      <td>-6.190604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>POSCAR-JVASP-2035.vasp</td>\n",
              "      <td>82.290001</td>\n",
              "      <td>-7.343407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POSCAR-JVASP-13942.vasp</td>\n",
              "      <td>87.809998</td>\n",
              "      <td>-7.393437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>POSCAR-JVASP-278.vasp</td>\n",
              "      <td>144.320007</td>\n",
              "      <td>-7.004790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>POSCAR-JVASP-10173.vasp</td>\n",
              "      <td>33.700001</td>\n",
              "      <td>-6.655459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>POSCAR-JVASP-4364.vasp</td>\n",
              "      <td>54.290001</td>\n",
              "      <td>-8.039992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>POSCAR-JVASP-29480.vasp</td>\n",
              "      <td>78.639999</td>\n",
              "      <td>-8.734395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>POSCAR-JVASP-28375.vasp</td>\n",
              "      <td>55.480000</td>\n",
              "      <td>-7.635911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>POSCAR-JVASP-590.vasp</td>\n",
              "      <td>88.519997</td>\n",
              "      <td>-7.158084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>POSCAR-JVASP-4741.vasp</td>\n",
              "      <td>226.220001</td>\n",
              "      <td>-5.181231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16c625e4-8eee-4e86-92ff-e9ae56e28f73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16c625e4-8eee-4e86-92ff-e9ae56e28f73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16c625e4-8eee-4e86-92ff-e9ae56e28f73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "Sgg094jfO7Ol",
        "outputId": "91c46e77-59c3-478d-f42b-a4ff65c5808d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.22.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.3\n",
            "    Uninstalling matplotlib-3.5.3:\n",
            "      Successfully uninstalled matplotlib-3.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.10.1 requires matplotlib>=3.5.0, but you have matplotlib 3.1.3 which is incompatible.\n",
            "mizani 0.8.1 requires matplotlib>=3.5.0, but you have matplotlib 3.1.3 which is incompatible.\n",
            "alignn 2023.1.10 requires matplotlib>=3.4.1, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(df['target'],df['prediction'],'.')\n",
        "plt.plot(df['target'],df['target'],'-.')\n",
        "plt.xlabel('DFT data (meV)')\n",
        "plt.ylabel('ALIGNN predictions (meV)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "hf3vWrmQpDwg",
        "outputId": "cf6aaed6-26c8-44d7-8bd1-d9505fb01eba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'ALIGNN predictions (meV)')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis.db.figshare import data as jdata\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# import os\n",
        "\n",
        "# temp_dir_name = \"DataDir_QM9_U0\" \n",
        "# os.makedirs(temp_dir_name)\n",
        "# os.chdir(temp_dir_name)\n",
        "\n",
        "# dft_3d = jdata(\"qm9_std_jctc\") #jdata(\"dft_3d\")\n",
        "# prop = \"U0\" #\"exfoliation_energy\" #\"optb88vdw_bandgap\"\n",
        "# f = open(\"id_prop.csv\", \"w\")\n",
        "# # count = 0\n",
        "# for i in dft_3d:\n",
        "#     atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "#     jid = i[\"id\"]\n",
        "#     poscar_name = \"POSCAR-\" + jid + \".vasp\"\n",
        "#     target = i[prop]\n",
        "#     if target != \"na\":\n",
        "#         atoms.write_poscar(poscar_name)\n",
        "#         f.write(\"%s,%6f\\n\" % (poscar_name, target))\n",
        "#         # count += 1\n",
        "#         # if count == max_samples:\n",
        "#         #     break\n",
        "# f.close()\n",
        "\n",
        "# os.chdir(cwd)"
      ],
      "metadata": {
        "id": "cOSVNX6zUeXd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5SxYZoRkqM80",
        "outputId": "33270850-e21b-460a-8363-fd3de5d5d12a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/alignn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "wDQTE2p1ZMAh",
        "outputId": "8aafb30d-37be-4c9f-cfd6-1fa7588824b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alignn\t\t    eos.png\t opt.log\t README.md\n",
            "alignn_ff.log\t    ExfoEnOut\t opt.traj\t setup.py\n",
            "DataDir_ExfoEnergy  LICENSE.rst  pyproject.toml  temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the cut-off in config_example.json as 5,  n_train as 110000, n_val as 10000, n_test as 10829"
      ],
      "metadata": {
        "id": "y-NnYsVoZght"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# config = loadjson(\"alignn/examples/sample_data/config_example.json\")\n",
        "# config['cutoff'] = 5.0\n",
        "# config['n_train'] = 110000\n",
        "# config['n_val'] = 10000\n",
        "# config['n_test'] = 10829\n",
        "# dumpjson(data=config, filename=\"config_qm9.json\")"
      ],
      "metadata": {
        "id": "gqBCdqVCaBmy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run for 1000 epochs instead of 5 here to get reasonable performance/MAE"
      ],
      "metadata": {
        "id": "WasOday5a72c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# t1=time.time()\n",
        "# !train_folder.py --root_dir \"DataDir_QM9_U0\" --epochs 5 --batch_size 64 --config \"config_qm9.json\" --output_dir=\"DataDir_QM9U0out\"\n",
        "# t2=time.time()\n",
        "# print ('Time in s',t2-t1)"
      ],
      "metadata": {
        "id": "acaMqZP_XbBr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqaGpi_PYpjw",
        "outputId": "3329bc69-7e2b-4930-e972-8243734591e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aeppl==0.0.33\n",
            "aesara==2.7.9\n",
            "aiohttp==3.8.4\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.13\n",
            "albumentations==1.2.1\n",
            "alignn==2023.1.10\n",
            "altair==4.2.2\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "arviz==0.12.1\n",
            "ase==3.22.1\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.2\n",
            "atomicwrites==1.4.1\n",
            "attrs==22.2.0\n",
            "audioread==3.0.0\n",
            "autograd==1.5\n",
            "autopep8==2.0.2\n",
            "Babel==2.12.1\n",
            "backcall==0.2.0\n",
            "backports.zoneinfo==0.2.1\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==6.0.0\n",
            "blis==0.7.9\n",
            "bokeh==2.4.3\n",
            "branca==0.6.0\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.11\n",
            "cachetools==5.3.0\n",
            "catalogue==2.0.8\n",
            "certifi==2022.12.7\n",
            "cffi==1.15.1\n",
            "cftime==1.6.2\n",
            "chardet==4.0.0\n",
            "charset-normalizer==3.0.1\n",
            "click==8.1.3\n",
            "clikit==0.6.2\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.22.6\n",
            "cmdstanpy==1.1.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "confection==0.0.4\n",
            "cons==0.4.5\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.4.0\n",
            "crashtest==0.3.1\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.3.0\n",
            "cvxpy==1.2.3\n",
            "cycler==0.11.0\n",
            "cymem==2.0.7\n",
            "Cython==0.29.33\n",
            "dask==2022.2.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.0.5\n",
            "dbus-python==1.2.16\n",
            "debugpy==1.6.4\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "dgl==1.0.1+cu117\n",
            "dglgo==0.0.2\n",
            "distributed==2022.2.1\n",
            "dlib==19.24.0\n",
            "dm-tree==0.1.8\n",
            "dnspython==2.3.0\n",
            "docutils==0.19\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.342\n",
            "easydict==1.10\n",
            "ecos==2.0.12\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl\n",
            "entrypoints==0.4\n",
            "ephem==4.1.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.0.0\n",
            "etuples==0.3.8\n",
            "fa2==0.3.5\n",
            "fastai==2.7.11\n",
            "fastcore==1.5.28\n",
            "fastdownload==0.0.7\n",
            "fastdtw==0.3.4\n",
            "fastjsonschema==2.16.3\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.9.0\n",
            "firebase-admin==5.3.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "flake8==6.0.0\n",
            "Flask==2.2.3\n",
            "flatbuffers==23.1.21\n",
            "folium==0.12.1.post1\n",
            "fonttools==4.38.0\n",
            "frozenlist==1.3.3\n",
            "fsspec==2023.1.0\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==3.3.2\n",
            "gdown==4.4.0\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.11.0\n",
            "google-api-python-client==2.70.0\n",
            "google-auth==2.16.1\n",
            "google-auth-httplib2==0.1.0\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==3.4.2\n",
            "google-cloud-bigquery-storage==2.18.1\n",
            "google-cloud-core==2.3.2\n",
            "google-cloud-datastore==2.11.1\n",
            "google-cloud-firestore==2.7.3\n",
            "google-cloud-language==2.6.1\n",
            "google-cloud-storage==2.7.0\n",
            "google-cloud-translate==3.8.4\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.4.1\n",
            "googleapis-common-protos==1.58.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==2.0.2\n",
            "grpcio==1.51.3\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.4\n",
            "holidays==0.20\n",
            "holoviews==1.14.9\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httpstan==4.6.1\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "idna==2.10\n",
            "imageio==2.9.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.8.1\n",
            "imblearn==0.0\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==6.0.0\n",
            "importlib-resources==5.12.0\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "intel-openmp==2023.0.0\n",
            "ipykernel==5.3.4\n",
            "ipython==7.9.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.7.1\n",
            "isort==6.0.0b2\n",
            "itsdangerous==2.1.2\n",
            "jarvis-tools==2023.1.8\n",
            "jax==0.4.4\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.4+cuda11.cudnn82-cp38-cp38-manylinux2014_x86_64.whl\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.2.0\n",
            "jsonschema==4.3.3\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter_core==5.2.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==3.0.5\n",
            "kaggle==1.5.12\n",
            "keras==2.11.0\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.4.4\n",
            "korean-lunar-calendar==0.3.1\n",
            "langcodes==3.3.0\n",
            "libclang==15.0.6.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "littleutils==0.2.2\n",
            "llvmlite==0.39.1\n",
            "lmdb==0.99\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.5\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.9.2\n",
            "Markdown==3.4.1\n",
            "MarkupSafe==2.1.2\n",
            "marshmallow==3.19.0\n",
            "matplotlib==3.1.3\n",
            "matplotlib-venn==0.11.9\n",
            "mccabe==0.7.0\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.8.1\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==9.1.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.4\n",
            "multidict==6.0.4\n",
            "multipledispatch==0.6.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.9\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.7.2\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.7.3\n",
            "netCDF4==1.6.2\n",
            "networkx==3.0\n",
            "nibabel==3.0.2\n",
            "nltk==3.7\n",
            "notebook==6.3.0\n",
            "numba==0.56.4\n",
            "numexpr==2.8.4\n",
            "numpy==1.22.4\n",
            "numpydoc==1.5.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "ogb==1.3.5\n",
            "opencv-contrib-python==4.6.0.66\n",
            "opencv-python==4.6.0.66\n",
            "opencv-python-headless==4.7.0.72\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "outdated==0.2.2\n",
            "packaging==23.0\n",
            "palettable==3.3.0\n",
            "pandas==1.3.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.17.9\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.14.3\n",
            "param==1.12.3\n",
            "parso==0.8.3\n",
            "partd==1.3.0\n",
            "pastel==0.2.1\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.1\n",
            "patsy==0.5.3\n",
            "pep517==0.13.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==8.4.0\n",
            "pip-tools==6.6.2\n",
            "platformdirs==3.0.0\n",
            "plotly==5.5.0\n",
            "plotnine==0.10.1\n",
            "pluggy==0.7.1\n",
            "pooch==1.7.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.8\n",
            "prettytable==3.6.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.16.0\n",
            "promise==2.3\n",
            "prompt-toolkit==2.0.10\n",
            "prophet==1.1.2\n",
            "proto-plus==1.22.2\n",
            "protobuf==3.19.6\n",
            "psutil==5.9.4\n",
            "psycopg2==2.9.5\n",
            "ptyprocess==0.7.0\n",
            "py==1.11.0\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.6\n",
            "pycodestyle==2.10.0\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.5\n",
            "pydata-google-auth==1.7.0\n",
            "pydocstyle==6.3.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyerfa==2.0.0.1\n",
            "pyflakes==3.0.1\n",
            "Pygments==2.14.0\n",
            "PyGObject==3.36.0\n",
            "pylev==1.4.0\n",
            "pymc==4.1.4\n",
            "PyMeeus==0.5.12\n",
            "pymongo==4.3.3\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.19.3\n",
            "pysimdjson==3.2.0\n",
            "PySocks==1.7.1\n",
            "pystan==3.3.0\n",
            "pytest==3.6.4\n",
            "python-apt==2.0.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.5.2\n",
            "pytorch-ignite==0.5.0.dev20221024\n",
            "pytz==2022.7.1\n",
            "pyviz-comms==2.2.1\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.5.post3\n",
            "qudida==0.0.4\n",
            "rdkit-pypi==2022.9.5\n",
            "regex==2022.6.2\n",
            "requests==2.25.1\n",
            "requests-oauthlib==1.3.1\n",
            "requests-unixsocket==0.2.0\n",
            "resampy==0.4.2\n",
            "rpy2==3.5.5\n",
            "rsa==4.9\n",
            "ruamel.yaml==0.17.21\n",
            "ruamel.yaml.clib==0.2.7\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.1\n",
            "scipy==1.10.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==3.2.2\n",
            "seaborn==0.11.2\n",
            "Send2Trash==1.8.0\n",
            "shapely==2.0.1\n",
            "six==1.15.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "spacy==3.4.4\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.4\n",
            "spglib==2.0.2\n",
            "Sphinx==6.1.3\n",
            "sphinxcontrib-applehelp==1.0.4\n",
            "sphinxcontrib-devhelp==1.0.2\n",
            "sphinxcontrib-htmlhelp==2.0.1\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.3\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "SQLAlchemy==1.4.46\n",
            "sqlparse==0.4.3\n",
            "srsly==2.4.6\n",
            "statsmodels==0.13.5\n",
            "sympy==1.7.1\n",
            "tables==3.7.0\n",
            "tabulate==0.8.10\n",
            "tblib==1.7.0\n",
            "tenacity==8.2.2\n",
            "tensorboard==2.11.2\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow==2.11.0\n",
            "tensorflow-datasets==4.8.3\n",
            "tensorflow-estimator==2.11.0\n",
            "tensorflow-gcs-config==2.11.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.31.0\n",
            "tensorflow-metadata==1.12.0\n",
            "tensorflow-probability==0.19.0\n",
            "termcolor==2.2.0\n",
            "terminado==0.13.3\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "thinc==8.1.7\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2023.2.27\n",
            "tinycss2==1.2.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch==1.12.0\n",
            "torchaudio @ https://download.pytorch.org/whl/cu116/torchaudio-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.14.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
            "tornado==6.2\n",
            "tqdm==4.64.1\n",
            "traitlets==5.7.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typer==0.7.0\n",
            "typing_extensions==4.5.0\n",
            "tzlocal==1.5.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==1.26.14\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.10.1\n",
            "wcwidth==0.2.6\n",
            "webargs==8.2.0\n",
            "webencodings==0.5.1\n",
            "Werkzeug==2.2.3\n",
            "widgetsnbextension==3.6.2\n",
            "wordcloud==1.8.2.2\n",
            "wrapt==1.15.0\n",
            "xarray==2022.12.0\n",
            "xarray-einstats==0.5.1\n",
            "xgboost==1.7.4\n",
            "xkit==0.0.0\n",
            "xlrd==1.2.0\n",
            "xlwt==1.3.0\n",
            "xmltodict==0.13.0\n",
            "yarl==1.8.2\n",
            "yellowbrick==1.5\n",
            "zict==2.2.0\n",
            "zipp==3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arZZybt0Nw_Z"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}