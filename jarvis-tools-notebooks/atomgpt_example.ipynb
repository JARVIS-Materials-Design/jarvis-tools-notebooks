{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjv4e5i429ucBVBS6DHFjg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AtomGPT example: https://pubs.acs.org/doi/10.1021/acs.jpclett.4c01126\n"
      ],
      "metadata": {
        "id": "TkkuV4Hyib2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of contents\n",
        "\n",
        "1. Installing [AtomGPT](https://github.com/usnistgov/atomgpt)\n",
        "2. Example inverse model training for 5 materials\n",
        "3. Using the trained model for inference\n",
        "4. Relaxing structures with ALIGNN-FF\n",
        "5. Generating a database of atomic structures\n",
        "\n",
        "\n",
        "Author: Kamal Choudhary (kamal.choudhary@nist.gov)"
      ],
      "metadata": {
        "id": "bhdCyKO2tSeu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HURIAsbZgMF",
        "outputId": "e8fa2ecf-379e-4c4d-8078-d916e5c076e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:12\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "ZfBX7ilpiouF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf Software\n",
        "os.makedirs('/content/Software')\n",
        "os.chdir('/content/Software')\n",
        "if not os.path.exists('atomgpt'):\n",
        "  !rm -rf atomgpt\n",
        "  !git clone https://github.com/usnistgov/atomgpt.git\n",
        "  os.chdir('atomgpt')\n",
        "  !git checkout dev\n",
        "  !pip install -qqq -r dev-requirements.txt\n",
        "  # !pip install -q protobuf\n",
        "  !pip install -q -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0SQ7cmLgC8l",
        "outputId": "0f639d64-cf0b-48af-9c69-5d32e5cf77ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'atomgpt'...\n",
            "remote: Enumerating objects: 629, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 629 (delta 60), reused 52 (delta 24), pack-reused 500 (from 1)\u001b[K\n",
            "Receiving objects: 100% (629/629), 66.31 MiB | 17.29 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
            "Switched to a new branch 'dev'\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.2/809.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for multidict (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCPU times: user 1.79 s, sys: 227 ms, total: 2.02 s\n",
            "Wall time: 4min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jarvis_leaderboard"
      ],
      "metadata": {
        "id": "5s-xshg4Ksls",
        "outputId": "18feb852-d7bf-424a-ac98-5aa4de86b950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.0/259.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check import\n",
        "import atomgpt"
      ],
      "metadata": {
        "id": "A57B4HSIKsiJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jarvis_populate_data.py --benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae --output_path=Out"
      ],
      "metadata": {
        "id": "PJCSrGz9KwqU",
        "outputId": "956ef7a3-6a04-41c8-ae16-e7adb020e7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmark_file AI-SinglePropertyPrediction-exfoliation_energy-dft_3d-test-mae\n",
            "dataset dft_3d\n",
            "output_path Out\n",
            "property exfoliation_energy\n",
            "method AI\n",
            "task SinglePropertyPrediction\n",
            "id_tag jid\n",
            "out_format poscar\n",
            "dataset file to be used /usr/local/lib/python3.10/site-packages/jarvis_leaderboard/benchmarks/AI/SinglePropertyPrediction/dft_3d_exfoliation_energy.json.zip\n",
            "Currently for atomistic datasets only.\n",
            "https://jarvis-tools.readthedocs.io/en/master/databases.html\n",
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "100% 40.8M/40.8M [00:04<00:00, 9.31MiB/s]\n",
            "Loading the zipfile...\n",
            "Loading completed.\n",
            "number of training samples 650\n",
            "number of validation samples 81\n",
            "number of test samples 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "dataset_info = loadjson('Out/dataset_info.json')\n",
        "#print(dataset_info)\n",
        "n_train = dataset_info['n_train']\n",
        "n_val = dataset_info['n_val']\n",
        "n_test = dataset_info['n_test']"
      ],
      "metadata": {
        "id": "yzy3HXrrKwne"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_config={'id_prop_path': \"Out/id_prop.csv\",\n",
        " 'prefix': 'atomgpt_run',\n",
        " 'model_name': \"knc6/atomgpt_mistral_tc_supercon\",\n",
        " 'batch_size': 2,\n",
        " 'num_epochs': 5,\n",
        " 'seed_val': 42,\n",
        " 'num_train': 2,\n",
        " 'num_val': 2,\n",
        " 'num_test': 2,\n",
        " 'model_save_path': 'lora_model_m'}\n",
        "dumpjson(data=temp_config,filename='atomgpt_inverse_config.json')"
      ],
      "metadata": {
        "id": "iBA_lyw7LjEi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "qa7fheaiLYgp",
        "outputId": "1b442822-0643-48cc-c1b3-4a83836c76ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Software/atomgpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!atomgpt_inverse --config_name atomgpt_inverse_config.json"
      ],
      "metadata": {
        "id": "WOZMra5rKwig",
        "outputId": "3ac44d4a-e7d5-4242-d0df-eaa25f9f2b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "TrainingPropConfig(id_prop_path='Out/id_prop.csv', prefix='atomgpt_run', model_name='knc6/atomgpt_mistral_tc_supercon', batch_size=2, num_epochs=5, seed_val=42, num_train=2, num_val=2, num_test=2, model_save_path='lora_model_m')\n",
            "100% 812/812 [00:00<00:00, 4352.04it/s]\n",
            "adapter_config.json: 100% 732/732 [00:00<00:00, 3.75MB/s]\n",
            "config.json: 100% 1.19k/1.19k [00:00<00:00, 6.54MB/s]\n",
            "   GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "model.safetensors: 100% 4.13G/4.13G [00:20<00:00, 198MB/s]\n",
            "generation_config.json: 100% 155/155 [00:00<00:00, 988kB/s]\n",
            "tokenizer_config.json: 100% 1.02k/1.02k [00:00<00:00, 6.04MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 415MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.37MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 2.81MB/s]\n",
            "adapter_model.safetensors: 100% 168M/168M [00:08<00:00, 19.3MB/s]\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Generating train split: 2 examples [00:00, 11.42 examples/s]\n",
            "Map: 100% 2/2 [00:00<00:00, 188.80 examples/s]\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  7.08 examples/s]\n",
            "/usr/local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 5\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 5\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.2578, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 0.2578, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'loss': 0.2578, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'loss': 0.2578, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 4.0}\n",
            "{'loss': 0.2578, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'train_runtime': 17.3179, 'train_samples_per_second': 0.577, 'train_steps_per_second': 0.289, 'train_loss': 0.25784002542495726, 'epoch': 5.0}\n",
            "100% 5/5 [00:17<00:00,  3.46s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]prompt The chemical formula is TaSe2. The  prop is 88.52. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "target_mat System\n",
            "1.0\n",
            "3.33618 0.0 12.45078\n",
            "1.63918 2.90572 12.45078\n",
            "0.0 0.0 12.89\n",
            "Ta Se \n",
            "2 4 \n",
            "direct\n",
            "0.917 0.917 0.917 Ta\n",
            "0.083 0.083 0.083 Ta\n",
            "0.627 0.627 0.627 Se\n",
            "0.46 0.46 0.46 Se\n",
            "0.207 0.207 0.207 Se\n",
            "0.373 0.373 0.373 Se\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.68 0.0 0.0\n",
            "-2.26891 4.09322 0.0\n",
            "0.0 0.0 5.82\n",
            "Ta Se \n",
            "1 2 \n",
            "direct\n",
            "0.853 0.147 0.25 Ta\n",
            "0.438 0.562 0.75 Se\n",
            "0.556 0.444 0.25 Se\n",
            "\n",
            "\n",
            " 50% 1/2 [00:05<00:05,  5.91s/it]prompt The chemical formula is LuPb2. The  prop is 226.22. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "target_mat System\n",
            "1.0\n",
            "3.68177 0.0 -1.12563\n",
            "-0.34414 3.66565 -1.12563\n",
            "0.0 0.0 6.36\n",
            "Lu Pb \n",
            "1 2 \n",
            "direct\n",
            "0.0 0.0 0.0 Lu\n",
            "0.341 0.341 0.681 Pb\n",
            "0.659 0.659 0.319 Pb\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "4.03568 0.0 2.33\n",
            "1.34523 3.80487 2.33\n",
            "0.0 0.0 4.66\n",
            "Lu Pb \n",
            "1 2 \n",
            "direct\n",
            "0.5 0.5 0.5 Lu\n",
            "0.25 0.25 0.25 Pb\n",
            "0.75 0.75 0.75 Pb\n",
            "\n",
            "\n",
            "100% 2/2 [00:11<00:00,  5.82s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqgAPEOSKsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyKaHFL0Ksdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l39PFc7MKsbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLZEzWHhKsZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training forward/inverse models with AtomGPT requires:\n",
        "\n",
        "# 1) `config.json` file, 2) `id_prop.csv` file."
      ],
      "metadata": {
        "id": "syLLDPebB04Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Example inverse model training for 5 materials"
      ],
      "metadata": {
        "id": "HhAC-Tfetscz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverse Model Example"
      ],
      "metadata": {
        "id": "DVt6XyJjiUVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use default config:\n",
        "\n",
        "TrainingPropConfig(id_prop_path='id_prop.csv', prefix='atomgpt_run', model_name='unsloth/mistral-7b-bnb-4bit', batch_size=2, num_epochs=2, seed_val=42, num_train=2, num_val=2, num_test=2, model_save_path='lora_model_m')\n"
      ],
      "metadata": {
        "id": "t7t4PWmRA6zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use a small id_prop.csv dataset with 5 materials only for training as given [here](https://github.com/usnistgov/atomgpt/blob/main/atomgpt/examples/inverse_model/id_prop.csv) . For production results, use larger dataset.\n",
        "\n",
        "\n",
        "\n",
        "An example for creating a sample id_prop.csv for `\"optb88vdw_bandgap\"` bandgap is kept [here](https://github.com/usnistgov/alignn/blob/main/alignn/examples/sample_data/scripts/generate_sample_data_reg.py). For superconductor database use `\"Tc_supercon\"` key instead."
      ],
      "metadata": {
        "id": "b8hLHzxCBJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets' look at an example config file before running the training\n",
        "import os\n",
        "os.chdir('/content')\n",
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "import pprint\n",
        "config = loadjson('Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "# config['model_name'] = \"knc6/atomgpt_mistral_tc_supercon\"\n",
        "dumpjson(data=config,filename='Software/atomgpt/atomgpt/examples/inverse_model/config.json')\n",
        "pprint.pprint(config)"
      ],
      "metadata": {
        "id": "ZrHsPD2VoxtO",
        "outputId": "17ce1313-6b83-4e4e-ac71-9eb1ee5b3ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!atomgpt_inverse --config_name Software/atomgpt/atomgpt/examples/inverse_model/config.json"
      ],
      "metadata": {
        "id": "dPgJz-gxG5e5",
        "outputId": "65e66a34-0491-49b1-98e7-450b426f4fae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_save_path\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "TrainingPropConfig(id_prop_path='id_prop.csv', prefix='atomgpt_run', model_name='unsloth/mistral-7b-bnb-4bit', batch_size=2, num_epochs=5, seed_val=42, num_train=2, num_val=2, num_test=2, model_save_path='lora_model_m')\n",
            "100% 6/6 [00:00<00:00, 219.38it/s]\n",
            "config.json: 100% 1.19k/1.19k [00:00<00:00, 5.64MB/s]\n",
            "   GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "model.safetensors: 100% 4.13G/4.13G [00:22<00:00, 187MB/s]\n",
            "generation_config.json: 100% 155/155 [00:00<00:00, 632kB/s]\n",
            "tokenizer_config.json: 100% 1.02k/1.02k [00:00<00:00, 6.41MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 297MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.15MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 2.40MB/s]\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Generating train split: 2 examples [00:00, 15.06 examples/s]\n",
            "Map: 100% 2/2 [00:00<00:00, 194.21 examples/s]\n",
            "Map (num_proc=2): 100% 2/2 [00:00<00:00,  5.30 examples/s]\n",
            "Num GPUs = 1\n",
            "Num examples = 2 | Num Epochs = 5\n",
            "Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "Total batch size = 8 | Total steps = 5\n",
            "Number of trainable parameters = 41,943,040\n",
            "{'loss': 0.4395, 'grad_norm': 0.7865042686462402, 'learning_rate': 4e-05, 'epoch': 1.0}\n",
            "{'loss': 0.4395, 'grad_norm': 0.7864629626274109, 'learning_rate': 8e-05, 'epoch': 2.0}\n",
            "{'loss': 0.3939, 'grad_norm': 0.5291562080383301, 'learning_rate': 0.00012, 'epoch': 3.0}\n",
            "{'loss': 0.3236, 'grad_norm': 0.4633527994155884, 'learning_rate': 0.00016, 'epoch': 4.0}\n",
            "{'loss': 0.236, 'grad_norm': 0.4685467779636383, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "{'train_runtime': 13.7442, 'train_samples_per_second': 0.728, 'train_steps_per_second': 0.364, 'train_loss': 0.3665075272321701, 'epoch': 5.0}\n",
            "100% 5/5 [00:13<00:00,  2.75s/it]\n",
            "   GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]prompt The chemical formula is Pb. The  prop is 5.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response ['<s>Below is a description of a superconductor material..\\n\\n### Instruction:\\nBelow is a description of a superconductor material.\\n\\n### Input:\\nThe chemical formula is Pb. The  prop is 5.4. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\\n\\n### Output:\\n3.31 3.31 3.31\\n60 60 60\\nPb 0.000 0.000 0.000</s>']\n",
            "target_mat System\n",
            "1.0\n",
            "3.03437 0.0 1.82323\n",
            "0.96943 2.87535 1.82323\n",
            "0.0 0.0 3.54\n",
            "Pb \n",
            "1 \n",
            "direct\n",
            "-0.0 0.0 0.0 Pb\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "2.86654 0.0 1.655\n",
            "0.95551 2.7026 1.655\n",
            "0.0 0.0 3.31\n",
            "Pb \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 0.0 Pb\n",
            "\n",
            "\n",
            " 50% 1/2 [00:03<00:03,  3.74s/it]prompt The chemical formula is Ta. The  prop is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\n",
            "response ['<s>Below is a description of a superconductor material..\\n\\n### Instruction:\\nBelow is a description of a superconductor material.\\n\\n### Input:\\nThe chemical formula is Ta. The  prop is 7.6. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\\n\\n### Output:\\n3.3 3.3 3.3\\n60 60 60\\nTa 0.0 0.0 0.0</s>']\n",
            "target_mat System\n",
            "1.0\n",
            "2.71364 0.0 -0.93438\n",
            "-1.30995 2.37652 -0.93438\n",
            "0.0 0.0 2.87\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 -0.0 Ta\n",
            "\n",
            "genmat System\n",
            "1.0\n",
            "2.85788 0.0 1.65\n",
            "0.95263 2.69444 1.65\n",
            "0.0 0.0 3.3\n",
            "Ta \n",
            "1 \n",
            "direct\n",
            "0.0 0.0 0.0 Ta\n",
            "\n",
            "\n",
            "100% 2/2 [00:06<00:00,  3.10s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from atomgpt.inverse_models.inverse_models import gen_atoms\n",
        "from atomgpt.inverse_models import  FastLanguageModel\n",
        "# import torch\n",
        "# from datasets import load_dataset\n",
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.db.figshare import data\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# import numpy as np\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.core.lattice import Lattice\n",
        "# from tqdm import tqdm\n",
        "# from jarvis.io.vasp.inputs import Poscar\n",
        "# from jarvis.db.jsonutils import loadjson\n",
        "# import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "#torch.cuda.is_available = lambda : False\n",
        "alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Output:\n",
        "{}\"\"\"\n",
        "\n",
        "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None  #\n",
        "load_in_4bit = True\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    device_map=\"auto\"\n",
        "\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# Example prompt and generated structure\n",
        "if __name__==\"__main__\":\n",
        " prompt_example = \"The chemical formula is FeBN The  prop is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        " gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        " print(gen_mat)"
      ],
      "metadata": {
        "id": "5FDQhK6MX5Tt",
        "outputId": "ced1c9d9-1c28-47d8-8c08-fb67288180c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "   Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "  Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            "\n",
            "System\n",
            "1.0\n",
            "2.98 0.0 0.0\n",
            "-0.0 3.07 0.0\n",
            "0.0 0.0 4.72\n",
            "Fe B N \n",
            "2 2 2 \n",
            "direct\n",
            "0.75 0.146 0.292 Fe\n",
            "0.25 0.854 0.708 Fe\n",
            "0.75 0.436 0.874 B\n",
            "0.25 0.564 0.126 B\n",
            "0.75 0.915 0.586 N\n",
            "0.25 0.085 0.414 N\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DW_eXcZfX5Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IdyEJXzX5Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPO4Cf4EX5H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "Q_R0bYP6ZBFL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0rNEtR0X5Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "yzZyPb33AEll",
        "outputId": "267dccef-a70a-404b-aa69-67463a0c672b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-AtomGen-prop-dft_3d-test-rmse.csv  alpaca_prop_val.json\t    lora_model_m  Software\n",
            "alpaca_prop_test.json\t\t      condacolab_install.log\t    outputs\n",
            "alpaca_prop_train.json\t\t      huggingface_tokenizers_cache  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files such as `AI-AtomGen-prop-dft_3d-test-rmse.csv ` can be uploaded in the [JARVIS-Leaderboard](https://pages.nist.gov/jarvis_leaderboard/) benchmarking plotform.\n",
        "\n"
      ],
      "metadata": {
        "id": "UUkS9YNgrBM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models are saved in the folder `lora_model_m`"
      ],
      "metadata": {
        "id": "nvURZAxFrtVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls lora_model_m"
      ],
      "metadata": {
        "id": "Or-1ZO_arNHo",
        "outputId": "5e439d7e-6199-42e4-82b8-4d7fde6351d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  adapter_model.safetensors\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at `alpaca_prop_test.json` and `alpaca_prop_train.json`"
      ],
      "metadata": {
        "id": "f1UdRnNorUN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prop_test=loadjson('alpaca_prop_test.json')\n",
        "alpaca_prop_train=loadjson('alpaca_prop_train.json')\n",
        "print(len(alpaca_prop_test),len(alpaca_prop_train))\n",
        "print('\\n')\n",
        "pprint.pprint(alpaca_prop_train[0])\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "id": "ymYpnxvErTzW",
        "outputId": "82ab0f98-3903-4b41-996f-cfcbe0a3e3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "\n",
            "\n",
            "{'input': 'The chemical formula is MgB2. The  prop is 33.0. Generate atomic '\n",
            "          'structure description with lattice lengths, angles, coordinates and '\n",
            "          'atom types.',\n",
            " 'instruction': 'Below is a description of a superconductor material.',\n",
            " 'output': '3.07 3.07 3.51\\n'\n",
            "           '90 90 119\\n'\n",
            "           'Mg 0.000 0.000 0.000\\n'\n",
            "           'B 0.667 0.333 0.500\\n'\n",
            "           'B 0.333 0.667 0.500'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using the trained model for inference"
      ],
      "metadata": {
        "id": "IBz34xi_tztU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the trained model for inference/testing. Note again this model was trained on just a few samples, so accuracy wont be very high."
      ],
      "metadata": {
        "id": "-lt2RgZmr0ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from jarvis.db.jsonutils import loadjson\n",
        "# from atomgpt.inverse_models import  FastLanguageModel\n",
        "# import torch\n",
        "# from datasets import load_dataset\n",
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.db.figshare import data\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# import numpy as np\n",
        "# from jarvis.core.atoms import Atoms\n",
        "# from jarvis.core.lattice import Lattice\n",
        "# from tqdm import tqdm\n",
        "# from jarvis.io.vasp.inputs import Poscar\n",
        "\n",
        "# import os\n",
        "# #os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "# #torch.cuda.is_available = lambda : False\n",
        "# alpaca_prompt = \"\"\"Below is a description of a superconductor material..\n",
        "\n",
        "# ### Instruction:\n",
        "# {}\n",
        "\n",
        "# ### Input:\n",
        "# {}\n",
        "\n",
        "# ### Output:\n",
        "# {}\"\"\"\n",
        "\n",
        "# max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "# dtype = None  #\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"lora_model_m\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "#     device_map=\"auto\"\n",
        "\n",
        "# )\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "# def text2atoms(response):\n",
        "#     tmp_atoms_array = response.split(\"\\n\")\n",
        "#     lat_lengths = np.array(tmp_atoms_array[1].split(), dtype=\"float\")\n",
        "#     lat_angles = np.array(tmp_atoms_array[2].split(), dtype=\"float\")\n",
        "#     lat = Lattice.from_parameters(\n",
        "#         lat_lengths[0],\n",
        "#         lat_lengths[1],\n",
        "#         lat_lengths[2],\n",
        "#         lat_angles[0],\n",
        "#         lat_angles[1],\n",
        "#         lat_angles[2],\n",
        "#     )\n",
        "#     elements = []\n",
        "#     coords = []\n",
        "#     for ii, i in enumerate(tmp_atoms_array):\n",
        "#         if ii > 2 and ii < len(tmp_atoms_array):\n",
        "#             tmp = i.split()\n",
        "#             elements.append(tmp[0])\n",
        "#             coords.append([float(tmp[1]), float(tmp[2]), float(tmp[3])])\n",
        "#     atoms = Atoms(\n",
        "#         coords=coords,\n",
        "#         elements=elements,\n",
        "#         lattice_mat=lat.lattice(),\n",
        "#         cartesian=False,\n",
        "#     )\n",
        "#     return atoms\n",
        "\n",
        "# def gen_atoms(prompt=\"\", max_new_tokens=512, model=\"\", tokenizer=\"\"):\n",
        "#     inputs = tokenizer(\n",
        "#         [\n",
        "#             alpaca_prompt.format(\n",
        "#                 \"Below is a description of a superconductor material.\",  # instruction\n",
        "#                 prompt,  # input\n",
        "#                 \"\",  # output - leave this blank for generation!\n",
        "#             )\n",
        "#         ],\n",
        "#         return_tensors=\"pt\",\n",
        "#     ).to(\"cuda\")\n",
        "#     outputs = model.generate(\n",
        "#         **inputs, max_new_tokens=max_new_tokens, use_cache=True\n",
        "#     )\n",
        "#     response = tokenizer.batch_decode(outputs)[0].split(\"# Output:\")[1].strip('</s>')\n",
        "#     # print('response',response)\n",
        "#     atoms = text2atoms(response)\n",
        "#     return atoms\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#  prompt_example = \"The chemical formula is MgB2 The  Tc_supercon is 6.483. The spacegroup is 12. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#  prompt_example = \"The chemical formula is FeBN The  Tc_supercon is 36.483. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "\n",
        "#  gen_mat = gen_atoms(prompt=prompt_example,model=model,tokenizer=tokenizer)\n",
        "#  print(gen_mat)"
      ],
      "metadata": {
        "id": "Z0Gf0CKSr8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Relaxing structures with ALIGNN-FF"
      ],
      "metadata": {
        "id": "SOp5oZSpt68_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated atomic structures can be relaxed with ALIGNN-FF, see example [here](https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/ALIGNN_Structure_Relaxation_Phonons_Interface.ipynb)."
      ],
      "metadata": {
        "id": "wLEaeWSkstav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above example used 5 materials during train only. We used about 1000 materials database in JARVIS-DFT, and the fine-tuned model is kept on [huggingface](https://huggingface.co/knc6/atomgpt_mistral_tc_supercon)."
      ],
      "metadata": {
        "id": "BkzSijjds4o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generating a database"
      ],
      "metadata": {
        "id": "IDpOtWsLuABd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from jarvis.core.specie import atomic_numbers_to_symbols\n",
        "# import numpy as np\n",
        "# from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "# from jarvis.core.composition import Composition\n",
        "# from tqdm import tqdm\n",
        "# from inf import gen_atoms\n",
        "\n",
        "# Z = np.arange(100) + 1\n",
        "# els = atomic_numbers_to_symbols(Z)\n",
        "\n",
        "# m = 1\n",
        "# n = 2\n",
        "\n",
        "\n",
        "# def gen_binary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_binary_samples(\"S\")\n",
        "# gen_binary_samples(\"Se\")\n",
        "# gen_binary_samples(\"Te\")\n",
        "# def gen_ternary_samples(element=\"B\"):\n",
        "#     mem = []\n",
        "#     for m in np.arange(1, 4):\n",
        "#         for n in np.arange(1, 4):\n",
        "#           for j in tqdm(els):\n",
        "#             for i in tqdm(els):\n",
        "#                 try:\n",
        "#                     comp = Composition.from_dict({i: m, j:n, element: n})\n",
        "#                     prompt_example = (\n",
        "#                         \"The chemical formula is \"\n",
        "#                         + comp.reduced_formula\n",
        "#                         + \" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#                     )\n",
        "#                     gen_mat = gen_atoms(prompt_example)\n",
        "#                     print(i)\n",
        "#                     print(gen_mat, len(mem))\n",
        "#                     mem.append([int(m), int(n), i, gen_mat.to_dict()])\n",
        "#                     # dumpjson(data=mem,filename='superB.json')\n",
        "#                 except:\n",
        "#                     pass\n",
        "#     fname=\"binary_super\"+element+\".json\"\n",
        "#     dumpjson(data=mem, filename=fname)\n",
        "# gen_ternary_samples(\"B\")\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"C\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superC.json')\n",
        "\n",
        "\n",
        "\n",
        "# m=1\n",
        "# n=2\n",
        "# mem=[]\n",
        "# for m in np.arange(1,4):\n",
        "#   for n in np.arange(1,4):\n",
        "#     for i in tqdm(els):\n",
        "#       try:\n",
        "#         comp=Composition.from_dict({i:m,\"N\":n})\n",
        "#         prompt_example = \"The chemical formula is \"+comp.reduced_formula+\" The  Tc_supercon is 100. Generate atomic structure description with lattice lengths, angles, coordinates and atom types.\"\n",
        "#         gen_mat = gen_atoms(prompt_example)\n",
        "#         print(i)\n",
        "#         print(gen_mat,len(mem))\n",
        "#         mem.append([int(m),int(n),i,gen_mat.to_dict()])\n",
        "#         #mem.append([m,n,i,gen_mat.to_dict()])\n",
        "#       except:\n",
        "#         pass\n",
        "# dumpjson(data=mem,filename='superN.json')\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "k5qoILFysR-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For forward model training with AtomGPT, see https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/atomgpt_forward_example.ipynb"
      ],
      "metadata": {
        "id": "3S-GrT1LEAMv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_6ZFPJMsR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4Px2rjJz_AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4ulYeQizxii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ae04L4JgC05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "-IUbsYWmgCx_",
        "outputId": "66ba204b-dc5a-47f4-8221-6fe4949328cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.2.1\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.6.20\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - protobuf==5.27.3\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.2\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.13.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnGe03dra32v",
        "outputId": "2c98316b-d257-47de-e99b-a9aa1f771645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate==0.31.0\n",
            "aiohttp==3.9.5\n",
            "aiosignal==1.3.1\n",
            "alignn==2024.4.20\n",
            "annotated-types==0.7.0\n",
            "archspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\n",
            "ase==3.23.0\n",
            "async-timeout==4.0.3\n",
            "-e git+https://github.com/usnistgov/atomgpt.git@a516955aa3348e628175d024c6b16896ba34e31a#egg=atomgpt\n",
            "attrs==23.2.0\n",
            "autopep8==2.3.1\n",
            "bitsandbytes==0.43.1\n",
            "black==24.4.2\n",
            "boltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\n",
            "Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\n",
            "certifi==2024.6.2\n",
            "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\n",
            "chardet==3.0.4\n",
            "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\n",
            "click==8.1.7\n",
            "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
            "conda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\n",
            "conda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\n",
            "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\n",
            "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\n",
            "contourpy==1.2.1\n",
            "cycler==0.12.1\n",
            "datasets==2.20.0\n",
            "dgl==1.1.1\n",
            "dill==0.3.8\n",
            "distro @ file:///home/conda/feedstock_root/build_artifacts/distro_1675116244235/work\n",
            "docstring_parser==0.16\n",
            "eval_type_backport==0.2.0\n",
            "filelock==3.15.4\n",
            "flake8==7.1.0\n",
            "fonttools==4.53.0\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.5.0\n",
            "gmpy2==2.2.1\n",
            "huggingface-hub==0.23.4\n",
            "idna==3.7\n",
            "importlib_resources==6.4.0\n",
            "jarvis-tools==2024.4.30\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\n",
            "jsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\n",
            "kiwisolver==1.4.5\n",
            "libmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/libmambapy\n",
            "lmdb==1.4.1\n",
            "mamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/mamba\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.9.0\n",
            "mccabe==0.7.0\n",
            "mdurl==0.1.2\n",
            "menuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\n",
            "mpmath==1.3.0\n",
            "multidict==4.7.6\n",
            "multiprocess==0.70.16\n",
            "mypy-extensions==1.0.0\n",
            "networkx==3.3\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-nccl-cu12==2.19.3\n",
            "nvidia-nvjitlink-cu12==12.6.20\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "packaging==24.1\n",
            "pandas==2.2.2\n",
            "pathspec==0.12.1\n",
            "peft==0.11.1\n",
            "pillow==10.3.0\n",
            "platformdirs==4.2.2\n",
            "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\n",
            "protobuf==5.27.3\n",
            "psutil==6.0.0\n",
            "pyarrow==16.1.0\n",
            "pyarrow-hotfix==0.6\n",
            "pycodestyle==2.12.0\n",
            "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
            "pydantic==2.7.4\n",
            "pydantic-settings==2.3.3\n",
            "pydantic_core==2.18.4\n",
            "pydocstyle==6.3.0\n",
            "pyflakes==3.2.0\n",
            "Pygments==2.18.0\n",
            "pyparsing==2.4.7\n",
            "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.0.1\n",
            "pytz==2024.1\n",
            "PyYAML==6.0.2\n",
            "regex==2024.5.15\n",
            "requests==2.32.3\n",
            "rich==13.7.1\n",
            "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\n",
            "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\n",
            "safetensors==0.4.3\n",
            "scikit-learn==1.5.0\n",
            "scipy==1.13.1\n",
            "sentencepiece==0.2.0\n",
            "shtab==1.7.1\n",
            "six==1.16.0\n",
            "snowballstemmer==2.2.0\n",
            "spglib==2.4.0\n",
            "sympy==1.13.1\n",
            "threadpoolctl==3.5.0\n",
            "tokenizers==0.19.1\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch==2.2.2\n",
            "torchdata==0.7.1\n",
            "tqdm==4.66.4\n",
            "transformers==4.41.2\n",
            "triton==2.2.0\n",
            "trl==0.8.6\n",
            "truststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\n",
            "typing_extensions==4.12.2\n",
            "tyro==0.8.4\n",
            "tzdata==2024.1\n",
            "urllib3==2.2.2\n",
            "xformers==0.0.25.post1\n",
            "xmltodict==0.13.0\n",
            "xxhash==3.4.1\n",
            "yarl==1.9.4\n",
            "zipp==3.19.2\n",
            "zstandard==0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env export"
      ],
      "metadata": {
        "id": "zkNYlup4mNHL",
        "outputId": "3e6dd98c-2915-49e2-e674-6946fa172eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: base\n",
            "channels:\n",
            "  - conda-forge\n",
            "dependencies:\n",
            "  - _libgcc_mutex=0.1=conda_forge\n",
            "  - _openmp_mutex=4.5=2_gnu\n",
            "  - archspec=0.2.2=pyhd8ed1ab_0\n",
            "  - boltons=23.1.1=pyhd8ed1ab_0\n",
            "  - brotli-python=1.1.0=py310hc6cd4ac_1\n",
            "  - bzip2=1.0.8=hd590300_5\n",
            "  - c-ares=1.24.0=hd590300_0\n",
            "  - ca-certificates=2023.11.17=hbcca054_0\n",
            "  - cffi=1.16.0=py310h2fee648_0\n",
            "  - charset-normalizer=3.3.2=pyhd8ed1ab_0\n",
            "  - colorama=0.4.6=pyhd8ed1ab_0\n",
            "  - conda=23.11.0=py310hff52083_1\n",
            "  - conda-libmamba-solver=23.12.0=pyhd8ed1ab_0\n",
            "  - conda-package-handling=2.2.0=pyh38be061_0\n",
            "  - conda-package-streaming=0.9.0=pyhd8ed1ab_0\n",
            "  - distro=1.8.0=pyhd8ed1ab_0\n",
            "  - fmt=10.1.1=h00ab1b0_1\n",
            "  - icu=73.2=h59595ed_0\n",
            "  - jsonpatch=1.33=pyhd8ed1ab_0\n",
            "  - jsonpointer=2.4=py310hff52083_3\n",
            "  - keyutils=1.6.1=h166bdaf_0\n",
            "  - krb5=1.21.2=h659d440_0\n",
            "  - ld_impl_linux-64=2.40=h41732ed_0\n",
            "  - libarchive=3.7.2=h2aa1ff5_1\n",
            "  - libcurl=8.5.0=hca28451_0\n",
            "  - libedit=3.1.20191231=he28a2e2_2\n",
            "  - libev=4.33=hd590300_2\n",
            "  - libffi=3.4.2=h7f98852_5\n",
            "  - libgcc-ng=13.2.0=h807b86a_3\n",
            "  - libgomp=13.2.0=h807b86a_3\n",
            "  - libiconv=1.17=hd590300_2\n",
            "  - libmamba=1.5.5=had39da4_0\n",
            "  - libmambapy=1.5.5=py310h39ff949_0\n",
            "  - libnghttp2=1.58.0=h47da74e_1\n",
            "  - libnsl=2.0.1=hd590300_0\n",
            "  - libsolv=0.7.27=hfc55251_0\n",
            "  - libsqlite=3.44.2=h2797004_0\n",
            "  - libssh2=1.11.0=h0841786_0\n",
            "  - libstdcxx-ng=13.2.0=h7e041cc_3\n",
            "  - libuuid=2.38.1=h0b41bf4_0\n",
            "  - libxml2=2.12.3=h232c23b_0\n",
            "  - libzlib=1.2.13=hd590300_5\n",
            "  - lz4-c=1.9.4=hcb278e6_0\n",
            "  - lzo=2.10=h516909a_1000\n",
            "  - mamba=1.5.5=py310h51d5547_0\n",
            "  - menuinst=2.0.1=py310hff52083_0\n",
            "  - ncurses=6.4=h59595ed_2\n",
            "  - openssl=3.2.0=hd590300_1\n",
            "  - pip=23.3.2=pyhd8ed1ab_0\n",
            "  - pluggy=1.3.0=pyhd8ed1ab_0\n",
            "  - pybind11-abi=4=hd8ed1ab_3\n",
            "  - pycosat=0.6.6=py310h2372a71_0\n",
            "  - pycparser=2.21=pyhd8ed1ab_0\n",
            "  - pysocks=1.7.1=pyha2e5f31_6\n",
            "  - python=3.10.13=hd12c33a_0_cpython\n",
            "  - python_abi=3.10=4_cp310\n",
            "  - readline=8.2=h8228510_1\n",
            "  - reproc=14.2.4.post0=hd590300_1\n",
            "  - reproc-cpp=14.2.4.post0=h59595ed_1\n",
            "  - ruamel.yaml=0.18.5=py310h2372a71_0\n",
            "  - ruamel.yaml.clib=0.2.7=py310h2372a71_2\n",
            "  - setuptools=68.2.2=pyhd8ed1ab_0\n",
            "  - tk=8.6.13=noxft_h4845f30_101\n",
            "  - truststore=0.8.0=pyhd8ed1ab_0\n",
            "  - wheel=0.42.0=pyhd8ed1ab_0\n",
            "  - xz=5.2.6=h166bdaf_0\n",
            "  - yaml-cpp=0.8.0=h59595ed_0\n",
            "  - zstandard=0.22.0=py310h1275a96_0\n",
            "  - zstd=1.5.5=hfc55251_0\n",
            "  - pip:\n",
            "      - accelerate==0.31.0\n",
            "      - aiohttp==3.9.5\n",
            "      - aiosignal==1.3.1\n",
            "      - alignn==2024.4.20\n",
            "      - annotated-types==0.7.0\n",
            "      - ase==3.23.0\n",
            "      - async-timeout==4.0.3\n",
            "      - attrs==23.2.0\n",
            "      - autopep8==2.3.1\n",
            "      - bitsandbytes==0.43.1\n",
            "      - black==24.4.2\n",
            "      - certifi==2024.6.2\n",
            "      - chardet==3.0.4\n",
            "      - click==8.1.7\n",
            "      - contourpy==1.2.1\n",
            "      - cycler==0.12.1\n",
            "      - datasets==2.20.0\n",
            "      - dgl==1.1.1\n",
            "      - dill==0.3.8\n",
            "      - docstring-parser==0.16\n",
            "      - eval-type-backport==0.2.0\n",
            "      - filelock==3.15.4\n",
            "      - flake8==7.1.0\n",
            "      - fonttools==4.53.0\n",
            "      - frozenlist==1.4.1\n",
            "      - fsspec==2024.5.0\n",
            "      - gmpy2==2.1.5\n",
            "      - huggingface-hub==0.23.4\n",
            "      - idna==3.7\n",
            "      - importlib-resources==6.4.0\n",
            "      - jarvis-tools==2024.4.30\n",
            "      - jinja2==3.1.4\n",
            "      - joblib==1.4.2\n",
            "      - kiwisolver==1.4.5\n",
            "      - lmdb==1.4.1\n",
            "      - markdown-it-py==3.0.0\n",
            "      - markupsafe==2.1.5\n",
            "      - matplotlib==3.9.0\n",
            "      - mccabe==0.7.0\n",
            "      - mdurl==0.1.2\n",
            "      - mpmath==1.3.0\n",
            "      - multidict==4.7.6\n",
            "      - multiprocess==0.70.16\n",
            "      - mypy-extensions==1.0.0\n",
            "      - networkx==3.3\n",
            "      - numpy==1.26.4\n",
            "      - nvidia-cublas-cu12==12.1.3.1\n",
            "      - nvidia-cuda-cupti-cu12==12.1.105\n",
            "      - nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "      - nvidia-cuda-runtime-cu12==12.1.105\n",
            "      - nvidia-cudnn-cu12==8.9.2.26\n",
            "      - nvidia-cufft-cu12==11.0.2.54\n",
            "      - nvidia-curand-cu12==10.3.2.106\n",
            "      - nvidia-cusolver-cu12==11.4.5.107\n",
            "      - nvidia-cusparse-cu12==12.1.0.106\n",
            "      - nvidia-nccl-cu12==2.19.3\n",
            "      - nvidia-nvjitlink-cu12==12.5.40\n",
            "      - nvidia-nvtx-cu12==12.1.105\n",
            "      - packaging==24.1\n",
            "      - pandas==2.2.2\n",
            "      - pathspec==0.12.1\n",
            "      - peft==0.11.1\n",
            "      - pillow==10.3.0\n",
            "      - platformdirs==4.2.2\n",
            "      - psutil==6.0.0\n",
            "      - pyarrow==16.1.0\n",
            "      - pyarrow-hotfix==0.6\n",
            "      - pycodestyle==2.12.0\n",
            "      - pydantic==2.7.4\n",
            "      - pydantic-core==2.18.4\n",
            "      - pydantic-settings==2.3.3\n",
            "      - pydocstyle==6.3.0\n",
            "      - pyflakes==3.2.0\n",
            "      - pygments==2.18.0\n",
            "      - pyparsing==2.4.7\n",
            "      - python-dateutil==2.9.0.post0\n",
            "      - python-dotenv==1.0.1\n",
            "      - pytz==2024.1\n",
            "      - pyyaml==6.0.1\n",
            "      - regex==2024.5.15\n",
            "      - requests==2.32.3\n",
            "      - rich==13.7.1\n",
            "      - safetensors==0.4.3\n",
            "      - scikit-learn==1.5.0\n",
            "      - scipy==1.13.1\n",
            "      - sentencepiece==0.2.0\n",
            "      - shtab==1.7.1\n",
            "      - six==1.16.0\n",
            "      - snowballstemmer==2.2.0\n",
            "      - spglib==2.4.0\n",
            "      - sympy==1.12.1\n",
            "      - threadpoolctl==3.5.0\n",
            "      - tokenizers==0.19.1\n",
            "      - tomli==2.0.1\n",
            "      - toolz==0.12.1\n",
            "      - torch==2.2.2\n",
            "      - torchdata==0.7.1\n",
            "      - tqdm==4.66.4\n",
            "      - transformers==4.41.2\n",
            "      - triton==2.2.0\n",
            "      - trl==0.8.6\n",
            "      - typing-extensions==4.12.2\n",
            "      - tyro==0.8.4\n",
            "      - tzdata==2024.1\n",
            "      - urllib3==2.2.2\n",
            "      - xformers==0.0.25.post1\n",
            "      - xmltodict==0.13.0\n",
            "      - xxhash==3.4.1\n",
            "      - yarl==1.9.4\n",
            "      - zipp==3.19.2\n",
            "prefix: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opxC-PlXmQtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cW8QpTombNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# env=\"\"\"name:base\n",
        "# channels:\n",
        "#   - xformers\n",
        "#   - pytorch\n",
        "#   - nvidia\n",
        "#   - conda-forge\n",
        "#   - defaults\n",
        "# dependencies:\n",
        "#   - _libgcc_mutex=0.1=conda_forge\n",
        "#   - _openmp_mutex=4.5=2_gnu\n",
        "#   - blas=1.0=mkl\n",
        "#   - bzip2=1.0.8=h7f98852_4\n",
        "#   - ca-certificates=2024.2.2=hbcca054_0\n",
        "#   - cairo=1.18.0=h3faef2a_0\n",
        "#   - cffi=1.16.0=py39h7a31438_0\n",
        "#   - cuda-cudart=12.1.105=0\n",
        "#   - cuda-cupti=12.1.105=0\n",
        "#   - cuda-libraries=12.1.0=0\n",
        "#   - cuda-nvrtc=12.1.105=0\n",
        "#   - cuda-nvtx=12.1.105=0\n",
        "#   - cuda-opencl=12.4.99=0\n",
        "#   - cuda-runtime=12.1.0=0\n",
        "#   - cudatoolkit=11.7.0=hd8887f6_10\n",
        "#   - expat=2.5.0=hcb278e6_1\n",
        "#   - filelock=3.15.4=pyhd8ed1ab_0\n",
        "#   - font-ttf-dejavu-sans-mono=2.37=hab24e00_0\n",
        "#   - font-ttf-inconsolata=3.000=h77eed37_0\n",
        "#   - font-ttf-source-code-pro=2.038=h77eed37_0\n",
        "#   - font-ttf-ubuntu=0.83=hab24e00_0\n",
        "#   - fontconfig=2.14.2=h14ed4e7_0\n",
        "#   - fonts-conda-ecosystem=1=0\n",
        "#   - fonts-conda-forge=1=0\n",
        "#   - freetype=2.12.1=h267a509_2\n",
        "#   - gettext=0.21.1=h27087fc_0\n",
        "#   - gmp=6.3.0=h59595ed_1\n",
        "#   - gmpy2=2.1.2=py39h376b7d2_1\n",
        "#   - icu=73.2=h59595ed_0\n",
        "#   - intel-openmp=2022.1.0=h9e868ea_3769\n",
        "#   - jinja2=3.1.4=pyhd8ed1ab_0\n",
        "#   - ld_impl_linux-64=2.40=h41732ed_0\n",
        "#   - libblas=3.9.0=16_linux64_mkl\n",
        "#   - libcblas=3.9.0=16_linux64_mkl\n",
        "#   - libcublas=12.1.0.26=0\n",
        "#   - libcufft=11.0.2.4=0\n",
        "#   - libcufile=1.9.0.20=0\n",
        "#   - libcurand=10.3.5.119=0\n",
        "#   - libcusolver=11.4.4.55=0\n",
        "#   - libcusparse=12.0.2.55=0\n",
        "#   - libexpat=2.5.0=hcb278e6_1\n",
        "#   - libffi=3.4.2=h7f98852_5\n",
        "#   - libgcc-ng=13.2.0=h807b86a_2\n",
        "#   - libgfortran-ng=13.2.0=h69a702a_5\n",
        "#   - libgfortran5=13.2.0=ha4646dd_5\n",
        "#   - libglib=2.78.0=hebfc3b9_0\n",
        "#   - libgomp=13.2.0=h807b86a_2\n",
        "#   - libiconv=1.17=h166bdaf_0\n",
        "#   - liblapack=3.9.0=16_linux64_mkl\n",
        "#   - libnpp=12.0.2.50=0\n",
        "#   - libnsl=2.0.0=h7f98852_0\n",
        "#   - libnvjitlink=12.1.105=0\n",
        "#   - libnvjpeg=12.1.1.14=0\n",
        "#   - libopenblas=0.3.26=pthreads_h413a1c8_0\n",
        "#   - libpng=1.6.39=h753d276_0\n",
        "#   - libprotobuf=3.21.12=hfc55251_2\n",
        "#   - libsqlite=3.43.0=h2797004_0\n",
        "#   - libstdcxx-ng=13.2.0=h7e041cc_2\n",
        "#   - libuuid=2.38.1=h0b41bf4_0\n",
        "#   - libxcb=1.15=h0b41bf4_0\n",
        "#   - libxml2=2.11.5=h232c23b_1\n",
        "#   - libzlib=1.2.13=hd590300_5\n",
        "#   - llvm-openmp=15.0.7=h0cdce71_0\n",
        "#   - markupsafe=2.1.5=py39hd1e30aa_0\n",
        "#   - mkl=2022.1.0=hc2b9512_224\n",
        "#   - mpc=1.3.1=hfe3b2da_0\n",
        "#   - mpfr=4.2.1=h9458935_0\n",
        "#   - mpmath=1.3.0=pyhd8ed1ab_0\n",
        "#   - ncurses=6.4=hcb278e6_0\n",
        "#   - networkx=3.2.1=pyhd8ed1ab_0\n",
        "#   - ninja=1.11.1=h924138e_0\n",
        "#   - openbabel=3.1.1=py39h421517d_8\n",
        "#   - openssl=3.2.1=hd590300_1\n",
        "#   - pcre2=10.40=hc3806b6_0\n",
        "#   - pip=23.2.1=pyhd8ed1ab_0\n",
        "#   - pixman=0.42.2=h59595ed_0\n",
        "#   - pthread-stubs=0.4=h36c2ea0_1001\n",
        "#   - pycparser=2.22=pyhd8ed1ab_0\n",
        "#   - python=3.9.18=h0755675_0_cpython\n",
        "#   - python_abi=3.9=4_cp39\n",
        "#   - pytorch=2.2.2=py3.9_cuda12.1_cudnn8.9.2_0\n",
        "#   - pytorch-cuda=12.1=ha16c6d3_5\n",
        "#   - pytorch-mutex=1.0=cuda\n",
        "#   - pyyaml=6.0.1=py39hd1e30aa_1\n",
        "#   - readline=8.2=h8228510_1\n",
        "#   - setuptools=68.2.2=pyhd8ed1ab_0\n",
        "#   - sleef=3.5.1=h9b69904_2\n",
        "#   - sympy=1.12=pypyh9d50eac_103\n",
        "#   - tk=8.6.13=h2797004_0\n",
        "#   - torchtriton=2.2.0=py39\n",
        "#   - typing_extensions=4.10.0=pyha770c72_0\n",
        "#   - wheel=0.43.0=pyhd8ed1ab_1\n",
        "#   - xformers=0.0.25.post1=py39_cu12.1.0_pyt2.2.2\n",
        "#   - xorg-kbproto=1.0.7=h7f98852_1002\n",
        "#   - xorg-libice=1.1.1=hd590300_0\n",
        "#   - xorg-libsm=1.2.4=h7391055_0\n",
        "#   - xorg-libx11=1.8.7=h8ee46fc_0\n",
        "#   - xorg-libxau=1.0.11=hd590300_0\n",
        "#   - xorg-libxdmcp=1.1.3=h7f98852_0\n",
        "#   - xorg-libxext=1.3.4=h0b41bf4_2\n",
        "#   - xorg-libxrender=0.9.11=hd590300_0\n",
        "#   - xorg-renderproto=0.11.1=h7f98852_1002\n",
        "#   - xorg-xextproto=7.3.0=h0b41bf4_1003\n",
        "#   - xorg-xproto=7.0.31=h7f98852_1007\n",
        "#   - xz=5.2.6=h166bdaf_0\n",
        "#   - yaml=0.2.5=h7f98852_2\n",
        "#   - zlib=1.2.13=hd590300_5\n",
        "#   - pip:\n",
        "#       - accelerate==0.31.0\n",
        "#       - aiohttp==3.9.5\n",
        "#       - aiosignal==1.3.1\n",
        "#       - alignn==2024.4.20\n",
        "#       - annotated-types==0.7.0\n",
        "#       - ase==3.23.0\n",
        "#       - async-timeout==4.0.3\n",
        "#       - attrs==23.2.0\n",
        "#       - autopep8==2.3.1\n",
        "#       - bitsandbytes==0.43.1\n",
        "#       - black==24.4.2\n",
        "#       - certifi==2024.6.2\n",
        "#       - chardet==3.0.4\n",
        "#       - charset-normalizer==3.3.2\n",
        "#       - click==8.1.7\n",
        "#       - contourpy==1.2.1\n",
        "#       - cycler==0.12.1\n",
        "#       - datasets==2.20.0\n",
        "#       - dgl==1.1.1\n",
        "#       - dill==0.3.8\n",
        "#       - docstring-parser==0.16\n",
        "#       - eval-type-backport==0.2.0\n",
        "#       - flake8==7.1.0\n",
        "#       - fonttools==4.53.0\n",
        "#       - frozenlist==1.4.1\n",
        "#       - fsspec==2024.5.0\n",
        "#       - huggingface-hub==0.23.4\n",
        "#       - idna==3.7\n",
        "#       - importlib-resources==6.4.0\n",
        "#       - jarvis-tools==2024.4.30\n",
        "#       - joblib==1.4.2\n",
        "#       - kiwisolver==1.4.5\n",
        "#       - lmdb==1.4.1\n",
        "#       - markdown-it-py==3.0.0\n",
        "#       - matplotlib==3.9.0\n",
        "#       - mccabe==0.7.0\n",
        "#       - mdurl==0.1.2\n",
        "#       - multidict==4.7.6\n",
        "#       - multiprocess==0.70.16\n",
        "#       - mypy-extensions==1.0.0\n",
        "#       - numpy==1.26.4\n",
        "#       - packaging==24.1\n",
        "#       - pandas==2.2.2\n",
        "#       - pathspec==0.12.1\n",
        "#       - peft==0.11.1\n",
        "#       - pillow==10.3.0\n",
        "#       - platformdirs==4.2.2\n",
        "#       - psutil==6.0.0\n",
        "#       - pyarrow==16.1.0\n",
        "#       - pyarrow-hotfix==0.6\n",
        "#       - pycodestyle==2.12.0\n",
        "#       - pydantic==2.7.4\n",
        "#       - pydantic-core==2.18.4\n",
        "#       - pydantic-settings==2.3.3\n",
        "#       - pydocstyle==6.3.0\n",
        "#       - pyflakes==3.2.0\n",
        "#       - pygments==2.18.0\n",
        "#       - pyparsing==2.4.7\n",
        "#       - python-dateutil==2.9.0.post0\n",
        "#       - python-dotenv==1.0.1\n",
        "#       - pytz==2024.1\n",
        "#       - regex==2024.5.15\n",
        "#       - requests==2.32.3\n",
        "#       - rich==13.7.1\n",
        "#       - safetensors==0.4.3\n",
        "#       - scikit-learn==1.5.0\n",
        "#       - scipy==1.13.1\n",
        "#       - sentencepiece==0.2.0\n",
        "#       - shtab==1.7.1\n",
        "#       - six==1.16.0\n",
        "#       - snowballstemmer==2.2.0\n",
        "#       - spglib==2.4.0\n",
        "#       - threadpoolctl==3.5.0\n",
        "#       - tokenizers==0.19.1\n",
        "#       - tomli==2.0.1\n",
        "#       - toolz==0.12.1\n",
        "#       - torchdata==0.7.1\n",
        "#       - tqdm==4.66.4\n",
        "#       - transformers==4.41.2\n",
        "#       - trl==0.8.6\n",
        "#       - tyro==0.8.4\n",
        "#       - tzdata==2024.1\n",
        "#       - urllib3==2.2.2\n",
        "#       - xmltodict==0.13.0\n",
        "#       - xxhash==3.4.1\n",
        "#       - yarl==1.9.4\n",
        "#       - zipp==3.19.2\n",
        "# \"\"\"\n",
        "# with open(f'/content/conda.yaml', 'w') as f:\n",
        "#     f.write(env)\n",
        "# # !conda env update --name base -f conda.yaml"
      ],
      "metadata": {
        "id": "jvEq4Wu0mbPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}