{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8zvb2epJzoY8QalfgXcGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/Train_MLFF_NEQUIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouXtsEjaW3pU",
        "outputId": "5eedb835-50c5-4060-bc0c-ce3f41d0eeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.7/975.7 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "# install wandb\n",
        "!pip install -q wandb\n",
        "\n",
        "# install nequip\n",
        "!pip install -q nequip==0.5.5 torch==1.11  jarvis-tools\n",
        "\n",
        "# fix colab imports\n",
        "import site\n",
        "site.main()\n",
        "\n",
        "# set to allow anonymous WandB\n",
        "import os\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4N0mR-3W9dZ",
        "outputId": "d8875278-b6a4-41cc-bf64-900adca6b890"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-27 14:53:53--  https://figshare.com/ndownloader/files/40357663\n",
            "Resolving figshare.com (figshare.com)... 34.241.111.122, 54.171.25.118, 2a05:d018:1f4:d000:110e:8d24:f208:180e, ...\n",
            "Connecting to figshare.com (figshare.com)|34.241.111.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240127/eu-west-1/s3/aws4_request&X-Amz-Date=20240127T145353Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=83a5d710317b2e7d51bb8b25be4ddb3721eaa8b40b1d5a5b257adf43b139a1af [following]\n",
            "--2024-01-27 14:53:53--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240127/eu-west-1/s3/aws4_request&X-Amz-Date=20240127T145353Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=83a5d710317b2e7d51bb8b25be4ddb3721eaa8b40b1d5a5b257adf43b139a1af\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.25.91, 52.92.19.184, 52.218.25.75, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.25.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2542319 (2.4M) [application/zip]\n",
            "Saving to: ‘mlearn.json.zip’\n",
            "\n",
            "mlearn.json.zip     100%[===================>]   2.42M  3.17MB/s    in 0.8s    \n",
            "\n",
            "2024-01-27 14:53:55 (3.17 MB/s) - ‘mlearn.json.zip’ saved [2542319/2542319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json,zipfile\n",
        "mlearn = json.loads(\n",
        "        zipfile.ZipFile(\"mlearn.json.zip\").read(\n",
        "            \"mlearn.json\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "hjtceRcdW9nt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install allegro\n",
        "!git clone --depth 1 https://github.com/mir-group/allegro.git\n",
        "!pip install allegro/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtm4GIRW9qf",
        "outputId": "cd1af75f-e1bd-4f13-c37b-e135369a0dd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'allegro'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 44 (delta 0), reused 30 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (44/44), 71.97 KiB | 1.84 MiB/s, done.\n",
            "Processing ./allegro\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nequip>=0.5.3 (from mir-allegro==0.2.0)\n",
            "  Downloading nequip-0.5.6-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.6/145.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nequip>=0.5.3->mir-allegro==0.2.0) (1.23.5)\n",
            "Collecting ase (from nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Using cached ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nequip>=0.5.3->mir-allegro==0.2.0) (4.66.1)\n",
            "Collecting torch!=1.9.0,<1.13,>=1.10.0 (from nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting e3nn<0.6.0,>=0.4.4 (from nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Using cached e3nn-0.5.1-py3-none-any.whl (118 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from nequip>=0.5.3->mir-allegro==0.2.0) (6.0.1)\n",
            "Collecting torch-runstats>=0.2.0 (from nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Using cached torch_runstats-0.2.0-py3-none-any.whl (8.1 kB)\n",
            "Collecting torch-ema>=0.3.0 (from nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Using cached torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e3nn<0.6.0,>=0.4.4->nequip>=0.5.3->mir-allegro==0.2.0) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e3nn<0.6.0,>=0.4.4->nequip>=0.5.3->mir-allegro==0.2.0) (1.11.4)\n",
            "Collecting opt-einsum-fx>=0.1.4 (from e3nn<0.6.0,>=0.4.4->nequip>=0.5.3->mir-allegro==0.2.0)\n",
            "  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.9.0,<1.13,>=1.10.0->nequip>=0.5.3->mir-allegro==0.2.0) (4.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase->nequip>=0.5.3->mir-allegro==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn<0.6.0,>=0.4.4->nequip>=0.5.3->mir-allegro==0.2.0) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->e3nn<0.6.0,>=0.4.4->nequip>=0.5.3->mir-allegro==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase->nequip>=0.5.3->mir-allegro==0.2.0) (1.16.0)\n",
            "Building wheels for collected packages: mir-allegro\n",
            "  Building wheel for mir-allegro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-allegro: filename=mir_allegro-0.2.0-py3-none-any.whl size=27432 sha256=43f71e37d3efd415274ea2cbc192c2c3a2931528f69a93f206678e68c1ba2dd7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kcco2k3t/wheels/b4/da/7a/12e336aa57ba27cca94b3d21b0f02fa0c6c86f7e1f2b7a4195\n",
            "Successfully built mir-allegro\n",
            "Installing collected packages: torch-runstats, torch, torch-ema, opt-einsum-fx, e3nn, ase, nequip, mir-allegro\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ase-3.22.1 e3nn-0.5.1 mir-allegro-0.2.0 nequip-0.5.6 opt-einsum-fx-0.1.4 torch-1.12.1 torch-ema-0.3 torch-runstats-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('jarvis_leaderboard'):\n",
        "  !git clone https://github.com/usnistgov/jarvis_leaderboard.git\n",
        "os.chdir('jarvis_leaderboard')\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-KYE1PuW9tO",
        "outputId": "4c6879ee-71ed-4362-a084-7183255985d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jarvis_leaderboard'...\n",
            "remote: Enumerating objects: 60667, done.\u001b[K\n",
            "remote: Counting objects: 100% (679/679), done.\u001b[K\n",
            "remote: Compressing objects: 100% (268/268), done.\u001b[K\n",
            "remote: Total 60667 (delta 313), reused 472 (delta 115), pack-reused 59988\u001b[K\n",
            "Receiving objects: 100% (60667/60667), 390.06 MiB | 24.98 MiB/s, done.\n",
            "Resolving deltas: 100% (31730/31730), done.\n",
            "Updating files: 100% (3643/3643), done.\n",
            "Obtaining file:///content/jarvis_leaderboard\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (1.11.4)\n",
            "Collecting jarvis-tools>=2021.07.19 (from jarvis-leaderboard==2024.1.16)\n",
            "  Using cached jarvis_tools-2023.12.12-py2.py3-none-any.whl (975 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (1.5.3)\n",
            "Collecting rouge>=1.0.1 (from jarvis-leaderboard==2024.1.16)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting mkdocs>=1.5.2 (from jarvis-leaderboard==2024.1.16)\n",
            "  Downloading mkdocs-1.5.3-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mkdocs-material>=9.0.5 (from jarvis-leaderboard==2024.1.16)\n",
            "  Downloading mkdocs_material-9.5.5-py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic>=2.3.0 (from jarvis-leaderboard==2024.1.16)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (3.5.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (5.15.0)\n",
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (1.4.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-leaderboard==2024.1.16) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.16) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.16) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.16) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->jarvis-leaderboard==2024.1.16) (4.66.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (3.7.1)\n",
            "Collecting spglib>=1.14.1 (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading spglib-2.3.0-cp310-cp310-manylinux_2_17_x86_64.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.7/807.7 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (2.31.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (0.12.0)\n",
            "Collecting xmltodict>=0.11.0 (from jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting ghp-import>=1.0 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16) (3.1.3)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16) (2.1.4)\n",
            "Collecting mergedeep>=1.3.4 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: packaging>=20.5 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16) (23.2)\n",
            "Collecting pathspec>=0.11.1 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16) (4.1.0)\n",
            "Collecting pyyaml-env-tag>=0.1 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading pyyaml_env_tag-0.1-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16) (6.0.1)\n",
            "Collecting watchdog>=2.0 (from mkdocs>=1.5.2->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel~=2.10 in /usr/local/lib/python3.10/dist-packages (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16) (2.14.0)\n",
            "Collecting colorama~=0.4 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting mkdocs-material-extensions~=1.3 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting paginate~=0.5 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading paginate-0.5.6.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygments~=2.16 in /usr/local/lib/python3.10/dist-packages (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16) (2.16.1)\n",
            "Collecting pymdown-extensions~=10.2 (from mkdocs-material>=9.0.5->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading pymdown_extensions-10.7-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->jarvis-leaderboard==2024.1.16) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->jarvis-leaderboard==2024.1.16) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.6.1 (from pydantic>=2.3.0->jarvis-leaderboard==2024.1.16)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge>=1.0.1->jarvis-leaderboard==2024.1.16) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->jarvis-leaderboard==2024.1.16) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->jarvis-leaderboard==2024.1.16) (8.2.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->jarvis-tools>=2021.07.19->jarvis-leaderboard==2024.1.16) (2023.11.17)\n",
            "Building wheels for collected packages: paginate\n",
            "  Building wheel for paginate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paginate: filename=paginate-0.5.6-py3-none-any.whl size=12666 sha256=2ae8a2eb7ec5e6b317df84097a2ab814ad6471a873ee6e4b8b903e3938b37359\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/d3/18/0b5bebc873f29bea61fedece1e92cbcbef416839dfe5bd0eef\n",
            "Successfully built paginate\n",
            "Installing collected packages: paginate, xmltodict, watchdog, typing-extensions, spglib, rouge, pyyaml-env-tag, pymdown-extensions, pathspec, mkdocs-material-extensions, mergedeep, colorama, annotated-types, pydantic-core, ghp-import, pydantic, mkdocs, mkdocs-material, jarvis-tools, jarvis-leaderboard\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "  Running setup.py develop for jarvis-leaderboard\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.6.0 colorama-0.4.6 ghp-import-2.1.0 jarvis-leaderboard-2024.1.16 jarvis-tools-2023.12.12 mergedeep-1.3.4 mkdocs-1.5.3 mkdocs-material-9.5.5 mkdocs-material-extensions-1.3.1 paginate-0.5.6 pathspec-0.12.1 pydantic-2.5.3 pydantic-core-2.14.6 pymdown-extensions-10.7 pyyaml-env-tag-0.1 rouge-1.0.1 spglib-2.3.0 typing-extensions-4.9.0 watchdog-3.0.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os,glob,sys,yaml,pprint\n",
        "import zipfile\n",
        "import json\n",
        "import pandas as pd\n",
        "from jarvis.db.figshare import data\n",
        "from jarvis.core.atoms import Atoms\n",
        "import numpy as np\n",
        "from nequip.data import AtomicData, Collater, dataset_from_config, register_fields, AtomicDataDict\n",
        "from nequip.data.transforms import TypeMapper\n",
        "import fileinput\n",
        "import torch\n",
        "os.chdir('/content')\n",
        "#torch.cuda.is_available = lambda : False\n",
        "elements = [\"Si\"] #[\"Ni\", \"Si\", \"Ge\", \"Mo\", \"Cu\", \"Li\"]\n",
        "\n",
        "# with open('allegro/configs/tutorial.yaml','r') as f:\n",
        "#     txt=f.read()\n",
        "\n",
        "# tut = yaml.load(txt, Loader=yaml.Loader)\n",
        "tut = {'BesselBasis_trainable': True,\n",
        " 'PolynomialCutoff_p': 6,\n",
        " 'append': True,\n",
        " 'ase_args': {'format': 'extxyz'},\n",
        " 'avg_num_neighbors': 'auto',\n",
        " 'batch_size': 2,\n",
        " 'chemical_symbol_to_type': {'Si': 0},\n",
        " 'dataset': 'ase',\n",
        " 'dataset_file_name': './Si_data/sitraj.xyz',\n",
        " 'dataset_seed': 123456,\n",
        " 'default_dtype': 'float32',\n",
        " 'early_stopping_lower_bounds': {'LR': 1e-05},\n",
        " 'early_stopping_patiences': {'validation_loss': 100},\n",
        " 'invariant_layers':2,\n",
        " 'invariant_neurons':64,\n",
        " 'avg_num_neighbors':'auto',\n",
        " 'use_sc':True,\n",
        " 'l_max': 2,\n",
        "\n",
        " 'learning_rate': 0.001,\n",
        " 'log_batch_freq': 10,\n",
        " 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']},\n",
        " 'lr_scheduler_factor': 0.5,\n",
        " 'lr_scheduler_name': 'ReduceLROnPlateau',\n",
        " 'lr_scheduler_patience': 50,\n",
        " 'max_epochs': 100,\n",
        " 'metrics_components': [['forces', 'mae'],\n",
        "                        ['forces', 'rmse'],\n",
        "                        ['total_energy', 'mae'],\n",
        "                        ['total_energy', 'mae', {'PerAtom': True}]],\n",
        " 'metrics_key': 'validation_loss',\n",
        "#  'model_builders': ['allegro.model.Allegro',\n",
        "#                     'PerSpeciesRescale',\n",
        "#                     'ForceOutput',\n",
        "#                     'RescaleEnergyEtc'],\n",
        " 'n_test': 25,\n",
        " 'n_train': 214,\n",
        " 'n_val': 25,\n",
        " 'nonlinearity_type':'gate',\n",
        " 'num_features':32,\n",
        " 'num_layers': 1,\n",
        " 'num_basis':8,\n",
        " 'optimizer_name': 'Adam',\n",
        " 'optimizer_params': {'amsgrad': False,\n",
        "                      'betas': (0.9, 0.999),\n",
        "                      'eps': 1e-08,\n",
        "                      'weight_decay': 0.0},\n",
        " 'parity': True,\n",
        " 'r_max': 4.0,\n",
        " 'root': 'results/silicon-tutorial',\n",
        " 'run_name': 'si',\n",
        " 'seed': 123456,\n",
        " 'shuffle': False,\n",
        " 'train_val_split ': 'sequential',\n",
        " 'use_ema': True,\n",
        " 'verbose': 'info',\n",
        " 'wandb': True,\n",
        " 'wandb_project': 'allegro-tutorial'}\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n",
        "cmd = \"wandb offline\"\n",
        "os.system(cmd)\n",
        "#mlearn = data(\"mlearn\")\n",
        "\n",
        "\n",
        "# def replaceAll(filename,searchExp,replaceExp):\n",
        "#     with open(filename, \"r\") as file:\n",
        "#          filedata = file.read().splitlines()\n",
        "#     content = []\n",
        "#     for j in filedata:\n",
        "#         if searchExp in j:\n",
        "#            content.append(replaceExp)\n",
        "#         else:\n",
        "#             content.append(j)\n",
        "#     with open(filename, \"w\") as file:\n",
        "#          file.write(\"\\n\".join(content))\n",
        "for element in elements:\n",
        "    os.chdir('/content')\n",
        "    cmd = \"rm -r Si_data\"\n",
        "    os.system(cmd)\n",
        "    folder = \"Si_data\"\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    benchmark_energies = (\n",
        "        \"jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/mlearn_\"\n",
        "        + element\n",
        "        + \"_energy.json.zip\"\n",
        "    )\n",
        "    temp_energies = benchmark_energies.split(\"/\")[-1].split(\".zip\")[0]\n",
        "    energies = json.loads(\n",
        "        zipfile.ZipFile(benchmark_energies).read(temp_energies)\n",
        "    )\n",
        "    train_ids = list(energies[\"train\"].keys())\n",
        "    test_ids = list(energies[\"test\"].keys())\n",
        "\n",
        "    f = open(\"Si_data/sitraj.xyz\", \"w\")\n",
        "    line = \"\"\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in train_ids:\n",
        "            # print(i)\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            line += str(atoms.num_atoms) + \"\\n\"\n",
        "            line += (\n",
        "                \"Lattice=\"\n",
        "                + '\"'\n",
        "                + \" \".join(map(str, (atoms.lattice_mat).flatten()))\n",
        "                + '\"'\n",
        "                + \" Properties=species:S:1:pos:R:3:forces:R:3 energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                # + ' stress=\"'\n",
        "                # + \" \".join(map(str, np.array(i[\"stresses\"]).flatten()))\n",
        "                # + '\"'\n",
        "                + \" free_energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                + ' pbc=\"T T T\"'\n",
        "                + \"\\n\"\n",
        "            )\n",
        "            for m, n, p in zip(\n",
        "                atoms.elements, atoms.cart_coords, i[\"forces\"]\n",
        "            ):\n",
        "                line += (\n",
        "                    str(m)\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, n))\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, p))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "            # print(line)\n",
        "            f.write(line)\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            # print(i)\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            line += str(atoms.num_atoms) + \"\\n\"\n",
        "            line += (\n",
        "                \"Lattice=\"\n",
        "                + '\"'\n",
        "                + \" \".join(map(str, (atoms.lattice_mat).flatten()))\n",
        "                + '\"'\n",
        "                + \" Properties=species:S:1:pos:R:3:forces:R:3 energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                # + ' stress=\"'\n",
        "                # + \" \".join(map(str, np.array(i[\"stresses\"]).flatten()))\n",
        "                # + '\"'\n",
        "                + \" free_energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                + ' pbc=\"T T T\"'\n",
        "                + \"\\n\"\n",
        "            )\n",
        "            for m, n, p in zip(\n",
        "                atoms.elements, atoms.cart_coords, i[\"forces\"]\n",
        "            ):\n",
        "                line += (\n",
        "                    str(m)\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, n))\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, p))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "            f.write(line)\n",
        "            # print(line)\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            # print(i)\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            line += str(atoms.num_atoms) + \"\\n\"\n",
        "            line += (\n",
        "                \"Lattice=\"\n",
        "                + '\"'\n",
        "                + \" \".join(map(str, (atoms.lattice_mat).flatten()))\n",
        "                + '\"'\n",
        "                + \" Properties=species:S:1:pos:R:3:forces:R:3 energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                # + ' stress=\"'\n",
        "                # + \" \".join(map(str, np.array(i[\"stresses\"]).flatten()))\n",
        "                # + '\"'\n",
        "                + \" free_energy=\"\n",
        "                + str(i[\"energy\"])\n",
        "                + ' pbc=\"T T T\"'\n",
        "                + \"\\n\"\n",
        "            )\n",
        "            for m, n, p in zip(\n",
        "                atoms.elements, atoms.cart_coords, i[\"forces\"]\n",
        "            ):\n",
        "                line += (\n",
        "                    str(m)\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, n))\n",
        "                    + \" \"\n",
        "                    + \" \".join(map(str, p))\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "            # print(line)\n",
        "            f.write(line)\n",
        "    f.close()\n",
        "    pprint.pprint(tut)\n",
        "    cmd = \"rm -rf ./results\"\n",
        "    os.system(cmd)\n",
        "\n",
        "    yaml_f = 'allegro/configs/tutorial_'+element+'.yaml'\n",
        "\n",
        "    cmd = 'cp allegro/configs/tutorial.yaml allegro/configs/tutorial_'+element+'.yaml'\n",
        "    os.system(cmd)\n",
        "    tmp=\"  \"+element+\": 0\"\n",
        "    #replaceAll(yaml_f,\"Si: 0\",tmp)\n",
        "    tut['chemical_symbol_to_type'] ={element: 0}\n",
        "    tut['n_train'] = len(train_ids)\n",
        "    tut['shuffle'] = False\n",
        "    tut['n_test'] = len(test_ids)\n",
        "    tut['n_val'] = len(test_ids)\n",
        "    tut['batch_size'] = 2\n",
        "    # tut['r_max'] = 6\n",
        "    # tut['lmax'] = 2\n",
        "    # tut['num_layers'] = 2\n",
        "    # tut['env_embed_multiplicity'] = 64\n",
        "    # tut['two_body_latent_mlp_latent_dimensions']=[128, 256, 512, 1024]\n",
        "    # tut['latent_mlp_latent_dimension'] = [128] #[1024, 1024, 1024]\n",
        "    # tut['edge_eng_mlp_latent_dimension'] = 128\n",
        "    tut['learning_rate'] = 0.001\n",
        "    tut['train_val_split '] = 'sequential'\n",
        "    tut['shuffle']=False\n",
        "    #pprint.pprint('config',tut)\n",
        "    with open(yaml_f, \"w+\") as fp:\n",
        "        yaml.dump(tut,fp)\n",
        "    cmd = \"nequip-train allegro/configs/tutorial_\"+element+\".yaml  --equivariance-test\"\n",
        "    os.system(cmd)\n",
        "    print('FINISHED')\n",
        "    import torch\n",
        "    from nequip.utils import Config\n",
        "    from nequip.model import model_from_config\n",
        "    from nequip.data import AtomicData, ASEDataset\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    config = Config.from_file(\n",
        "        \"results/silicon-tutorial/si/config.yaml\"\n",
        "    )\n",
        "\n",
        "    # config[\"train_on_keys\"]=[\"forces\", \"total_energy\"]\n",
        "    # config[\"model_builders\"] = [\"EnergyModel\", \"PerSpeciesRescale\", \"ForceOutput\", \"RescaleEnergyEtc\"]\n",
        "    model = model_from_config(config, initialize=False)\n",
        "    d = torch.load(\n",
        "        \"results/silicon-tutorial/si/best_model.pth\",\n",
        "        map_location=device,\n",
        "    )\n",
        "    model.load_state_dict(d)\n",
        "\n",
        "    df = pd.DataFrame(mlearn)\n",
        "\n",
        "    def get_allegro_forces(model=[], atoms=[], cutoff=5):\n",
        "        ase_atoms = atoms.ase_converter()\n",
        "        a = AtomicData.from_ase(ase_atoms, cutoff)\n",
        "        data = AtomicData.to_AtomicDataDict(a)\n",
        "        tm = TypeMapper(\n",
        "            chemical_symbol_to_type=config[\"chemical_symbol_to_type\"]\n",
        "        )\n",
        "        data = tm(data)\n",
        "        out = model(data)\n",
        "        pen = (\n",
        "            out[\"total_energy\"]\n",
        "            .squeeze()\n",
        "            .cpu()\n",
        "            .detach()\n",
        "            .numpy()\n",
        "            .tolist()\n",
        "        )\n",
        "        num_atoms = atoms.num_atoms\n",
        "        pf = out[\"forces\"].squeeze().cpu().detach().numpy()\n",
        "        return pen, pf, 0\n",
        "\n",
        "\n",
        "    for i in glob.glob(\"jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "\n",
        "        if \"mlearn\" in i and element in i:\n",
        "            fname_e = (\n",
        "                \"AI-MLFF-energy-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-mae.csv\"\n",
        "            )\n",
        "            fname_f = (\n",
        "                \"AI-MLFF-forces-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-multimae.csv\"\n",
        "            )\n",
        "            fname_s = (\n",
        "                \"AI-MLFF-stresses-\"\n",
        "                + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "                + \"-test-multimae.csv\"\n",
        "            )\n",
        "            f_e = open(fname_e, \"w\")\n",
        "            f_f = open(fname_f, \"w\")\n",
        "            # f_s = open(fname_s, \"w\")\n",
        "\n",
        "            f_e.write(\"id,target,prediction\\n\")\n",
        "            f_f.write(\"id,target,prediction\\n\")\n",
        "            # f_s.write(\"id,prediction\\n\")\n",
        "            #\n",
        "            print(i)\n",
        "            dat = json.loads(\n",
        "                zipfile.ZipFile(i).read(\n",
        "                    i.split(\"/\")[-1].split(\".zip\")[0]\n",
        "                )\n",
        "            )\n",
        "            print(dat[\"test\"])\n",
        "            for key, val in dat[\"test\"].items():\n",
        "                entry = df[df[\"jid\"] == key]\n",
        "                atoms = Atoms.from_dict(entry.atoms.values[0])\n",
        "                # print(key,val,df[df['jid']==key],atoms)\n",
        "                # energy,forces=get_alignn_forces(atoms)\n",
        "                energy, forces, stress = get_allegro_forces(\n",
        "                    model=model, atoms=atoms\n",
        "                )\n",
        "                print(key, val, energy, atoms.num_atoms)\n",
        "                line = (\n",
        "                    key\n",
        "                    + \",\"\n",
        "                    + str(entry.energy.values[0])\n",
        "                    + \",\"\n",
        "                    + str(energy)\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "                f_e.write(line)\n",
        "                line = (\n",
        "                    key\n",
        "                    + \",\"\n",
        "                    + str(\n",
        "                        \";\".join(\n",
        "                            map(\n",
        "                                str,\n",
        "                                np.array(\n",
        "                                    entry.forces.values[0]\n",
        "                                ).flatten(),\n",
        "                            )\n",
        "                        )\n",
        "                    )\n",
        "                    + \",\"\n",
        "                    + str(\n",
        "                        \";\".join(map(str, np.array(forces).flatten()))\n",
        "                    )\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "                f_f.write(line)\n",
        "                # line = (\n",
        "                #     key\n",
        "                #     + \",\"\n",
        "                #     + str(\";\".join(map(str, np.array(stress).flatten())))\n",
        "                #     + \"\\n\"\n",
        "                # )\n",
        "                # f_s.write(line)\n",
        "            f_e.close()\n",
        "            f_f.close()\n",
        "            # f_s.close()\n",
        "            zname = fname_e + \".zip\"\n",
        "            with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "                myzip.write(fname_e)\n",
        "\n",
        "            zname = fname_f + \".zip\"\n",
        "            with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "                myzip.write(fname_f)\n",
        "\n",
        "            # zname = fname_s + \".zip\"\n",
        "            # with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            #     myzip.write(fname_s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iim8y2gQXGI4",
        "outputId": "7aab97ea-18f2-4fba-a0c9-ffb284dc7240"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BesselBasis_trainable': True,\n",
            " 'PolynomialCutoff_p': 6,\n",
            " 'append': True,\n",
            " 'ase_args': {'format': 'extxyz'},\n",
            " 'avg_num_neighbors': 'auto',\n",
            " 'batch_size': 2,\n",
            " 'chemical_symbol_to_type': {'Si': 0},\n",
            " 'dataset': 'ase',\n",
            " 'dataset_file_name': './Si_data/sitraj.xyz',\n",
            " 'dataset_seed': 123456,\n",
            " 'default_dtype': 'float32',\n",
            " 'early_stopping_lower_bounds': {'LR': 1e-05},\n",
            " 'early_stopping_patiences': {'validation_loss': 100},\n",
            " 'invariant_layers': 2,\n",
            " 'invariant_neurons': 64,\n",
            " 'l_max': 2,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_batch_freq': 10,\n",
            " 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']},\n",
            " 'lr_scheduler_factor': 0.5,\n",
            " 'lr_scheduler_name': 'ReduceLROnPlateau',\n",
            " 'lr_scheduler_patience': 50,\n",
            " 'max_epochs': 100,\n",
            " 'metrics_components': [['forces', 'mae'],\n",
            "                        ['forces', 'rmse'],\n",
            "                        ['total_energy', 'mae'],\n",
            "                        ['total_energy', 'mae', {'PerAtom': True}]],\n",
            " 'metrics_key': 'validation_loss',\n",
            " 'n_test': 25,\n",
            " 'n_train': 214,\n",
            " 'n_val': 25,\n",
            " 'nonlinearity_type': 'gate',\n",
            " 'num_basis': 8,\n",
            " 'num_features': 32,\n",
            " 'num_layers': 1,\n",
            " 'optimizer_name': 'Adam',\n",
            " 'optimizer_params': {'amsgrad': False,\n",
            "                      'betas': (0.9, 0.999),\n",
            "                      'eps': 1e-08,\n",
            "                      'weight_decay': 0.0},\n",
            " 'parity': True,\n",
            " 'r_max': 4.0,\n",
            " 'root': 'results/silicon-tutorial',\n",
            " 'run_name': 'si',\n",
            " 'seed': 123456,\n",
            " 'shuffle': False,\n",
            " 'train_val_split ': 'sequential',\n",
            " 'use_ema': True,\n",
            " 'use_sc': True,\n",
            " 'verbose': 'info',\n",
            " 'wandb': True,\n",
            " 'wandb_project': 'allegro-tutorial'}\n",
            "FINISHED\n",
            "jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/mlearn_Si_energy.json.zip\n",
            "{'Si-215': -297.62773938, 'Si-216': -295.77170067, 'Si-217': -291.28958206, 'Si-218': -296.24088456, 'Si-219': -294.41361742, 'Si-220': -334.75283939, 'Si-221': -334.69215136, 'Si-222': -184.71808052, 'Si-223': -121.41180043, 'Si-224': -338.93899696, 'Si-225': -338.83557056, 'Si-226': -335.68901422, 'Si-227': -333.7064957, 'Si-228': -344.85564046, 'Si-229': -344.81108268, 'Si-230': -298.83222646, 'Si-231': -298.96501782, 'Si-232': -295.20943762, 'Si-233': -291.86293882, 'Si-234': -344.74080048, 'Si-235': -344.74080047, 'Si-236': -344.74080046, 'Si-237': -341.22165747, 'Si-238': -341.22165734, 'Si-239': -341.22165747}\n",
            "Si-215 -297.62773938 -339.39697265625 63\n",
            "Si-216 -295.77170067 -336.03173828125 63\n",
            "Si-217 -291.28958206 -339.5978698730469 63\n",
            "Si-218 -296.24088456 -333.0889587402344 63\n",
            "Si-219 -294.41361742 -336.8280334472656 63\n",
            "Si-220 -334.75283939 -374.6390686035156 63\n",
            "Si-221 -334.69215136 -374.8531799316406 63\n",
            "Si-222 -184.71808052 -212.85069274902344 36\n",
            "Si-223 -121.41180043 -140.150146484375 24\n",
            "Si-224 -338.93899696 -375.86260986328125 64\n",
            "Si-225 -338.83557056 -375.7399597167969 64\n",
            "Si-226 -335.68901422 -372.3408508300781 64\n",
            "Si-227 -333.7064957 -370.62640380859375 64\n",
            "Si-228 -344.85564046 -381.9166259765625 64\n",
            "Si-229 -344.81108268 -381.8222351074219 64\n",
            "Si-230 -298.83222646 -345.80731201171875 64\n",
            "Si-231 -298.96501782 -346.5733642578125 64\n",
            "Si-232 -295.20943762 -343.6650390625 64\n",
            "Si-233 -291.86293882 -339.8960876464844 64\n",
            "Si-234 -344.74080048 -379.2209167480469 64\n",
            "Si-235 -344.74080047 -379.22100830078125 64\n",
            "Si-236 -344.74080046 -379.2211608886719 64\n",
            "Si-237 -341.22165747 -376.71875 64\n",
            "Si-238 -341.22165734 -376.71875 64\n",
            "Si-239 -341.22165747 -376.71868896484375 64\n",
            "CPU times: user 15 s, sys: 3.59 s, total: 18.6 s\n",
            "Wall time: 16min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x71RPRVLXGLI",
        "outputId": "3afbfbfd-3973-4139-d867-be9d6ce34dc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'allegro/configs/tutorial_Si.yaml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml,pprint\n",
        "with open(yaml_f, 'r') as stream:\n",
        "    data_loaded = yaml.load(stream, Loader=yaml.Loader)\n",
        "\n",
        "pprint.pprint(data_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3na9m27XGNk",
        "outputId": "b439a579-9fdb-4927-9a4a-d8269020fedc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BesselBasis_trainable': True,\n",
            " 'PolynomialCutoff_p': 6,\n",
            " 'append': True,\n",
            " 'ase_args': {'format': 'extxyz'},\n",
            " 'avg_num_neighbors': 'auto',\n",
            " 'batch_size': 2,\n",
            " 'chemical_symbol_to_type': {'Si': 0},\n",
            " 'dataset': 'ase',\n",
            " 'dataset_file_name': './Si_data/sitraj.xyz',\n",
            " 'dataset_seed': 123456,\n",
            " 'default_dtype': 'float32',\n",
            " 'early_stopping_lower_bounds': {'LR': 1e-05},\n",
            " 'early_stopping_patiences': {'validation_loss': 100},\n",
            " 'invariant_layers': 2,\n",
            " 'invariant_neurons': 64,\n",
            " 'l_max': 2,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_batch_freq': 10,\n",
            " 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']},\n",
            " 'lr_scheduler_factor': 0.5,\n",
            " 'lr_scheduler_name': 'ReduceLROnPlateau',\n",
            " 'lr_scheduler_patience': 50,\n",
            " 'max_epochs': 100,\n",
            " 'metrics_components': [['forces', 'mae'],\n",
            "                        ['forces', 'rmse'],\n",
            "                        ['total_energy', 'mae'],\n",
            "                        ['total_energy', 'mae', {'PerAtom': True}]],\n",
            " 'metrics_key': 'validation_loss',\n",
            " 'n_test': 25,\n",
            " 'n_train': 214,\n",
            " 'n_val': 25,\n",
            " 'nonlinearity_type': 'gate',\n",
            " 'num_basis': 8,\n",
            " 'num_features': 32,\n",
            " 'num_layers': 1,\n",
            " 'optimizer_name': 'Adam',\n",
            " 'optimizer_params': {'amsgrad': False,\n",
            "                      'betas': (0.9, 0.999),\n",
            "                      'eps': 1e-08,\n",
            "                      'weight_decay': 0.0},\n",
            " 'parity': True,\n",
            " 'r_max': 4.0,\n",
            " 'root': 'results/silicon-tutorial',\n",
            " 'run_name': 'si',\n",
            " 'seed': 123456,\n",
            " 'shuffle': False,\n",
            " 'train_val_split ': 'sequential',\n",
            " 'use_ema': True,\n",
            " 'use_sc': True,\n",
            " 'verbose': 'info',\n",
            " 'wandb': True,\n",
            " 'wandb_project': 'allegro-tutorial'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_df = pd.read_csv('AI-MLFF-energy-mlearn_Si-test-mae.csv.zip')\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print(mean_absolute_error(en_df['target'],en_df['prediction']))\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(en_df['target'],en_df['prediction'],'.')\n",
        "plt.xlabel('DFT energy(eV)')\n",
        "plt.ylabel('FF energy(eV)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "Eo-XFDGeXGQK",
        "outputId": "553a9bcb-e502-4224-fc8a-d1803f594f8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.35976932680781\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'FF energy(eV)')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJXZcylIXGS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RicN681XGVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-qFPSKNXGX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcyMqPy4XGaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGC1OZy1XGcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vUhiXyqW9v6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}