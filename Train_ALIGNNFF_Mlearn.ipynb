{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqFkrt3WAqBQtNohKwfaAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knc6/jarvis-tools-notebooks/blob/master/Train_ALIGNNFF_Mlearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m-7Dw7PbnND4",
        "outputId": "95bfdfa4-e681-4df1-c1be-fedbd1f53561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu118/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu118/dgl-1.1.1%2Bcu118-cp310-cp310-manylinux1_x86_64.whl (86.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1+cu118\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=78d29c7401699ed381cad1ecfc666f4fb2e89bc498457b5124d266f0e4e55c9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n",
            "Collecting alignn\n",
            "  Downloading alignn-2023.6.20-py2.py3-none-any.whl (60.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from alignn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from alignn) (1.10.1)\n",
            "Collecting jarvis-tools>=2021.07.19 (from alignn)\n",
            "  Downloading jarvis_tools-2023.5.26-py2.py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from alignn) (2.0.1+cu118)\n",
            "Requirement already satisfied: dgl>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from alignn) (1.1.1+cu118)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from alignn) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.4.1 in /usr/local/lib/python3.10/dist-packages (from alignn) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.10/dist-packages (from alignn) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from alignn) (1.5.3)\n",
            "Collecting pytorch-ignite>=0.5.0.dev20221024 (from alignn)\n",
            "  Downloading pytorch_ignite-0.5.0.dev20230703-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.4/267.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.8.1 (from alignn)\n",
            "  Downloading pydantic-1.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8>=3.9.1 (from alignn)\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycodestyle>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from alignn) (2.10.0)\n",
            "Collecting pydocstyle>=6.0.0 (from alignn)\n",
            "  Downloading pydocstyle-6.3.0-py3-none-any.whl (38 kB)\n",
            "Collecting pyparsing<3,>=2.2.1 (from alignn)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ase (from alignn)\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.8.1->alignn) (4.6.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl>=0.6.0->alignn) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl>=0.6.0->alignn) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl>=0.6.0->alignn) (5.9.5)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8>=3.9.1->alignn)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.1.0,>=3.0.0 (from flake8>=3.9.1->alignn)\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spglib>=1.14.1 (from jarvis-tools>=2021.07.19->alignn)\n",
            "  Downloading spglib-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->alignn) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jarvis-tools>=2021.07.19->alignn) (0.12.0)\n",
            "Collecting xmltodict>=0.11.0 (from jarvis-tools>=2021.07.19->alignn)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.1->alignn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.3->alignn) (2022.7.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pydocstyle>=6.0.0->alignn) (2.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->alignn) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->alignn) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->alignn) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->alignn) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->alignn) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->alignn) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->alignn) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.1->alignn) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl>=0.6.0->alignn) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->alignn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->alignn) (1.3.0)\n",
            "Installing collected packages: xmltodict, spglib, pyparsing, pyflakes, pydocstyle, pydantic, mccabe, flake8, jarvis-tools, ase, pytorch-ignite, alignn\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.0\n",
            "    Uninstalling pyparsing-3.1.0:\n",
            "      Successfully uninstalled pyparsing-3.1.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.9\n",
            "    Uninstalling pydantic-1.10.9:\n",
            "      Successfully uninstalled pydantic-1.10.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\n",
            "dglgo 0.0.2 requires pydantic>=1.9.0, but you have pydantic 1.8.1 which is incompatible.\n",
            "inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.1 which is incompatible.\n",
            "spacy 3.5.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\n",
            "thinc 8.1.10 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alignn-2023.6.20 ase-3.22.1 flake8-6.0.0 jarvis-tools-2023.5.26 mccabe-0.7.0 pydantic-1.8.1 pydocstyle-6.3.0 pyflakes-3.0.1 pyparsing-2.4.7 pytorch-ignite-0.5.0.dev20230703 spglib-2.0.2 xmltodict-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 569 ms, sys: 75.2 ms, total: 644 ms\n",
            "Wall time: 1min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu118/repo.html\n",
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
        "!pip install alignn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pwd\n",
        "os.chdir('/content')\n",
        "# Clone ALIGNN repo to get example folder\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFZn-PrinTX0",
        "outputId": "62396fcd-c367-4c37-b57e-a1a53666e94c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'alignn'...\n",
            "remote: Enumerating objects: 3776, done.\u001b[K\n",
            "remote: Counting objects: 100% (1370/1370), done.\u001b[K\n",
            "remote: Compressing objects: 100% (440/440), done.\u001b[K\n",
            "remote: Total 3776 (delta 1009), reused 1116 (delta 885), pack-reused 2406\u001b[K\n",
            "Receiving objects: 100% (3776/3776), 75.52 MiB | 20.50 MiB/s, done.\n",
            "Resolving deltas: 100% (2185/2185), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Just to test basic installation on gpu went right\n",
        "import time\n",
        "t1=time.time()\n",
        "!train_folder.py --root_dir \"alignn/alignn/examples/sample_data\" --epochs 3 --batch_size 2 --config \"alignn/alignn/examples/sample_data/config_example.json\" --output_dir=temp\n",
        "t2=time.time()\n",
        "print ('Time in s',t2-t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvJIYDhOnh2v",
        "outputId": "18213557-b3b4-41e7-ebeb-7874b41d7117"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "MAX val: 6.149\n",
            "MIN val: 0.0\n",
            "MAD: 1.0520696\n",
            "Baseline MAE: 2.3805500000000004\n",
            "data range 4.907 0.0\n",
            "100% 40/40 [00:02<00:00, 16.94it/s]\n",
            "df                                                 atoms  ... target\n",
            "0   {'lattice_mat': [[3.566933224304235, 0.0, -0.0...  ...  0.000\n",
            "1   {'lattice_mat': [[4.089078911208881, 0.0, 0.0]...  ...  0.000\n",
            "2   {'lattice_mat': [[-1.833590720595598, 1.833590...  ...  0.000\n",
            "3   {'lattice_mat': [[7.2963518353359165, 0.0, 0.0...  ...  0.472\n",
            "4   {'lattice_mat': [[1.6777483798834445, -2.90594...  ...  0.000\n",
            "5   {'lattice_mat': [[4.157436115454804, -0.0, 0.0...  ...  0.000\n",
            "6   {'lattice_mat': [[0.0, 5.1858714074842, 5.1858...  ...  0.000\n",
            "7   {'lattice_mat': [[3.790914410660539, -0.0, 0.0...  ...  0.000\n",
            "8   {'lattice_mat': [[4.284492173131309, 1.636192e...  ...  0.000\n",
            "9   {'lattice_mat': [[3.2250494729190726, 2.216578...  ...  0.689\n",
            "10  {'lattice_mat': [[5.587070827330502, -0.006443...  ...  1.517\n",
            "11  {'lattice_mat': [[4.927781968323723, -0.0, 0.0...  ...  0.000\n",
            "12  {'lattice_mat': [[10.725911963093319, 1.159968...  ...  0.000\n",
            "13  {'lattice_mat': [[5.140164879556414, 0.3718366...  ...  0.000\n",
            "14  {'lattice_mat': [[5.194393535053021, 0.0345773...  ...  0.000\n",
            "15  {'lattice_mat': [[4.927229198330356, -0.0, -0....  ...  2.122\n",
            "16  {'lattice_mat': [[4.839493559425439, 9.7116505...  ...  0.000\n",
            "17  {'lattice_mat': [[-2.2512310528422197, 1.49649...  ...  0.000\n",
            "18  {'lattice_mat': [[7.709535704177289, 2.46207e-...  ...  0.000\n",
            "19  {'lattice_mat': [[3.292134155794691, 0.0, 0.0]...  ...  0.502\n",
            "20  {'lattice_mat': [[9.067075684180468, -0.0, 0.0...  ...  1.197\n",
            "21  {'lattice_mat': [[6.850665464204784, -0.0, 0.0...  ...  0.560\n",
            "22  {'lattice_mat': [[3.3542337275744103, 0.0, 0.0...  ...  0.051\n",
            "23  {'lattice_mat': [[4.509029640475962, 0.0564034...  ...  4.907\n",
            "24  {'lattice_mat': [[3.5058938597621094, -3.08124...  ...  1.681\n",
            "25  {'lattice_mat': [[4.191262576674699, 0.0, -0.0...  ...  0.016\n",
            "26  {'lattice_mat': [[0.0, -3.9587610833154616, 0....  ...  0.658\n",
            "27  {'lattice_mat': [[4.084155317570781, -1.066825...  ...  0.000\n",
            "28  {'lattice_mat': [[9.407270982425844, 0.0171637...  ...  2.472\n",
            "29  {'lattice_mat': [[3.93712543178282, 0.0, 2.273...  ...  3.851\n",
            "30  {'lattice_mat': [[-0.0127275386492899, 4.47534...  ...  0.482\n",
            "31  {'lattice_mat': [[3.5666343258756448, 0.0, 0.0...  ...  0.000\n",
            "32  {'lattice_mat': [[7.843871888963013, 0.0, 0.0]...  ...  0.924\n",
            "33  {'lattice_mat': [[5.157077730332642, 0.0020004...  ...  4.030\n",
            "34  {'lattice_mat': [[3.8114364321417686, 0.0, 0.0...  ...  0.000\n",
            "35  {'lattice_mat': [[5.464512229851642, 0.0, -2.0...  ...  0.239\n",
            "36  {'lattice_mat': [[0.0, 4.936437902689708, 4.93...  ...  0.000\n",
            "37  {'lattice_mat': [[0.0, 4.893247728183244, 4.89...  ...  0.000\n",
            "38  {'lattice_mat': [[0.0, 4.901572410735, 4.90157...  ...  0.000\n",
            "39  {'lattice_mat': [[0.0, 5.104615296684174, 5.10...  ...  0.000\n",
            "\n",
            "[40 rows x 3 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 40/40 [00:00<00:00, 636.33it/s]\n",
            "data range 1.569 0.0\n",
            "100% 5/5 [00:00<00:00, 41.33it/s]\n",
            "df                                                atoms  ... target\n",
            "0  {'lattice_mat': [[-0.0, 5.040771484524319, 5.0...  ...  0.000\n",
            "1  {'lattice_mat': [[4.376835486482439, 0.0086562...  ...  0.000\n",
            "2  {'lattice_mat': [[-0.0, 5.037541505850243, 5.0...  ...  0.000\n",
            "3  {'lattice_mat': [[10.37325585559557, -2.271858...  ...  1.569\n",
            "4  {'lattice_mat': [[0.0, 5.129874508851702, 5.12...  ...  0.000\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 979.70it/s]\n",
            "data range 6.149 0.0\n",
            "100% 5/5 [00:00<00:00, 34.36it/s]\n",
            "df                                                atoms  ... target\n",
            "0  {'lattice_mat': [[1.6712283e-08, -2.5080296697...  ...  6.149\n",
            "1  {'lattice_mat': [[6.603532697435508, 0.0, -0.0...  ...  4.072\n",
            "2  {'lattice_mat': [[-0.0, 4.517300851474054, 4.5...  ...  0.000\n",
            "3  {'lattice_mat': [[-0.0, 4.326757913323647, 4.3...  ...  0.000\n",
            "4  {'lattice_mat': [[6.9098665629767275, 0.128626...  ...  2.341\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 5/5 [00:00<00:00, 817.00it/s]\n",
            "n_train: 40\n",
            "n_val: 5\n",
            "n_test: 5\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=3 batch_size=2 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False n_early_stopping=None output_dir='temp' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=256, output_features=1, link='identity', zero_inflated=False, classification=False, num_classes=2)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 2,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 3,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 256,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Val_MAE: 1.0282\n",
            "Train_MAE: 0.8347\n",
            "Val_MAE: 0.4758\n",
            "Train_MAE: 1.8375\n",
            "Val_MAE: 0.9286\n",
            "Train_MAE: 1.6457\n",
            "Test MAE: 2.507803225517273\n",
            "Time taken (s): 14.817846298217773\n",
            "Time in s 28.74060034751892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylnu0xCjoWjR",
        "outputId": "fe9bd3ec-d2d3-4fab-88eb-5d978fc7a096"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-03 17:09:15--  https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2034 (2.0K) [text/plain]\n",
            "Saving to: ‘config_mlearn_cu.json’\n",
            "\n",
            "\rconfig_mlearn_cu.js   0%[                    ]       0  --.-KB/s               \rconfig_mlearn_cu.js 100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-03 17:09:16 (36.1 MB/s) - ‘config_mlearn_cu.json’ saved [2034/2034]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls alignn/alignn/examples/sample_data_ff/mlearn_data/all/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWcGU66vn4J2",
        "outputId": "b9884322-6fe2-4413-bfd2-96bc102529a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config_example.json  id_prop.json  prepare_mlearn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jarvis.db.jsonutils import loadjson,dumpjson\n",
        "#lower batch size, samples, alignn and gcn layers etc. to fit in colab\n",
        "d=loadjson('config_mlearn_cu.json')\n",
        "d['batch_size']=2\n",
        "# d['n_train']=100\n",
        "# d['n_val']=5\n",
        "# d['n_test']=5\n",
        "dumpjson(data=d,filename='config_mlearn_cu_less.json')"
      ],
      "metadata": {
        "id": "1yQ5rv5rsvdC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !train_folder_ff.py --root_dir \"alignn/alignn/examples/sample_data_ff/mlearn_data/Cu/\"  --config \"config_mlearn_cu_less.json\" --output_dir=\"OutCu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8tG1cAusthS",
        "outputId": "3600074c-fb41-4664-d241-187ea60f70f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "len dataset 324\n",
            "MAX val: -3.5154572437962965\n",
            "MIN val: -4.101246713888889\n",
            "MAD: 0.11948171020654628\n",
            "Baseline MAE: 0.13718126977887754\n",
            "data range -3.5154572437962965 -4.101246713888889\n",
            "100% 262/262 [00:43<00:00,  6.06it/s]\n",
            "df        target  ...  jid\n",
            "0   -3.981879  ...   14\n",
            "1   -3.982149  ...   10\n",
            "2   -4.088199  ...  257\n",
            "3   -3.977330  ...   13\n",
            "4   -4.080317  ...  317\n",
            "..        ...  ...  ...\n",
            "257 -4.072867  ...  234\n",
            "258 -3.896843  ...   38\n",
            "259 -4.000258  ...  201\n",
            "260 -3.555814  ...  309\n",
            "261 -4.073291  ...  172\n",
            "\n",
            "[262 rows x 4 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 262/262 [00:02<00:00, 112.28it/s]\n",
            "data range -3.5660914372222225 -4.100467069907408\n",
            "100% 31/31 [00:04<00:00,  7.20it/s]\n",
            "df       target  ...  jid\n",
            "0  -4.036756  ...   88\n",
            "1  -4.070120  ...  135\n",
            "2  -4.034540  ...  250\n",
            "3  -3.895673  ...   43\n",
            "4  -4.063742  ...   93\n",
            "5  -3.986996  ...   17\n",
            "6  -4.100467  ...  262\n",
            "7  -4.072812  ...  192\n",
            "8  -4.094845  ...  215\n",
            "9  -3.950117  ...  267\n",
            "10 -4.018524  ...  249\n",
            "11 -4.100040  ...  223\n",
            "12 -3.984551  ...  263\n",
            "13 -4.067251  ...  204\n",
            "14 -3.979483  ...    7\n",
            "15 -3.950117  ...  298\n",
            "16 -3.566091  ...  270\n",
            "17 -3.961314  ...  106\n",
            "18 -4.099057  ...  248\n",
            "19 -3.938866  ...  268\n",
            "20 -4.018524  ...  176\n",
            "21 -4.083955  ...  157\n",
            "22 -3.979699  ...   19\n",
            "23 -4.080512  ...  241\n",
            "24 -3.956893  ...  136\n",
            "25 -4.092080  ...  245\n",
            "26 -4.099172  ...  221\n",
            "27 -3.953565  ...  150\n",
            "28 -3.980227  ...   11\n",
            "29 -3.964034  ...   65\n",
            "30 -3.962107  ...   73\n",
            "\n",
            "[31 rows x 4 columns]\n",
            "building line graphs\n",
            "100% 31/31 [00:00<00:00, 71.82it/s]\n",
            "data range -3.565395898333333 -4.100757043611111\n",
            "100% 31/31 [00:05<00:00,  5.68it/s]\n",
            "df       target  ...  jid\n",
            "0  -3.952025  ...   48\n",
            "1  -3.979364  ...   23\n",
            "2  -4.054687  ...   53\n",
            "3  -4.073379  ...  230\n",
            "4  -4.097994  ...  162\n",
            "5  -3.971151  ...    4\n",
            "6  -3.989234  ...   36\n",
            "7  -4.100757  ...  194\n",
            "8  -4.072867  ...  322\n",
            "9  -4.067251  ...  224\n",
            "10 -3.984111  ...    1\n",
            "11 -3.958536  ...   84\n",
            "12 -3.616537  ...  126\n",
            "13 -4.081772  ...  314\n",
            "14 -4.097994  ...  315\n",
            "15 -4.096307  ...  173\n",
            "16 -3.599006  ...   70\n",
            "17 -3.571802  ...   82\n",
            "18 -4.067251  ...  324\n",
            "19 -4.099057  ...  175\n",
            "20 -4.065376  ...  171\n",
            "21 -4.056356  ...  288\n",
            "22 -4.056721  ...  275\n",
            "23 -4.099171  ...  195\n",
            "24 -3.976079  ...   20\n",
            "25 -3.570559  ...   56\n",
            "26 -3.574628  ...  137\n",
            "27 -4.073380  ...  209\n",
            "28 -3.923674  ...   45\n",
            "29 -3.565396  ...  138\n",
            "30 -3.985642  ...   27\n",
            "\n",
            "[31 rows x 4 columns]\n",
            "building line graphs\n",
            "100% 31/31 [00:00<00:00, 115.73it/s]\n",
            "n_train: 262\n",
            "n_val: 31\n",
            "n_test: 31\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=31 n_test=31 n_train=262 train_ratio=0.9 val_ratio=0.05 test_ratio=0.05 target_multiplication_factor=None epochs=100 batch_size=2 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='l1' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=False progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=False num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False normalize_graph_level_loss=False distributed=False n_early_stopping=None output_dir='OutCu' model=ALIGNNAtomWiseConfig(name='alignn_atomwise', alignn_layers=2, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=300, output_features=1, grad_multiplier=-1, calculate_gradient=True, atomwise_output_features=0, graphwise_weight=0.8, gradwise_weight=0.2, stresswise_weight=0.0, atomwise_weight=0.0, link='identity', zero_inflated=False, classification=False, force_mult_natoms=True, energy_mult_natoms=False, include_pos_deriv=False, use_cutoff_function=False, inner_cutoff=6.0, stress_multiplier=1.0, add_reverse_forces=False)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 2,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'l1',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 100,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'add_reverse_forces': False,\n",
            "           'alignn_layers': 2,\n",
            "           'atom_input_features': 92,\n",
            "           'atomwise_output_features': 0,\n",
            "           'atomwise_weight': 0.0,\n",
            "           'calculate_gradient': True,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'energy_mult_natoms': False,\n",
            "           'force_mult_natoms': True,\n",
            "           'gcn_layers': 4,\n",
            "           'grad_multiplier': -1,\n",
            "           'gradwise_weight': 0.2,\n",
            "           'graphwise_weight': 0.8,\n",
            "           'hidden_features': 300,\n",
            "           'include_pos_deriv': False,\n",
            "           'inner_cutoff': 6.0,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn_atomwise',\n",
            "           'output_features': 1,\n",
            "           'stress_multiplier': 1.0,\n",
            "           'stresswise_weight': 0.0,\n",
            "           'triplet_input_features': 40,\n",
            "           'use_cutoff_function': False,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': 31,\n",
            " 'n_train': 262,\n",
            " 'n_val': 31,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'OutCu',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': False,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.05,\n",
            " 'train_ratio': 0.9,\n",
            " 'use_canonize': False,\n",
            " 'val_ratio': 0.05,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "TrainLoss Epoch 0 total 65.7026293380186 out 0.5222341728801946 atom nan grad 0.42393880712419096 stress nan\n",
            "Saving data for epoch: 0\n",
            "ValLoss Epoch 0 total 3.5256495475769043 out 0.22399423122406006 atom nan grad 0.2953340650623654 stress nan\n",
            "TrainLoss Epoch 1 total 23.655563490465283 out 0.15444544708455793 atom nan grad 0.2852870073799714 stress nan\n",
            "ValLoss Epoch 1 total 3.596076086163521 out 0.2506690740585327 atom nan grad 0.2044297159521289 stress nan\n",
            "TrainLoss Epoch 2 total 19.99852642789483 out 0.139688408101788 atom nan grad 0.20480433278511542 stress nan\n",
            "ValLoss Epoch 2 total 4.836315810680389 out 0.37697776953379314 atom nan grad 0.10681174003440622 stress nan\n",
            "TrainLoss Epoch 3 total 19.925315987318754 out 0.14120348992238518 atom nan grad 0.1902330254611111 stress nan\n",
            "Saving data for epoch: 3\n",
            "ValLoss Epoch 3 total 3.193852737545967 out 0.2483779509862264 atom nan grad 0.07050999214735121 stress nan\n",
            "TrainLoss Epoch 4 total 19.4559537852183 out 0.14641990006424999 atom nan grad 0.1517692724090012 stress nan\n",
            "Saving data for epoch: 4\n",
            "ValLoss Epoch 4 total 0.9328981172293425 out 0.051348876953125 atom nan grad 0.1070026844730713 stress nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  !train_folder_ff.py --root_dir \"alignn/alignn/examples/sample_data_ff/mlearn_data/all/\"  --config \"config.json\" --output_dir=\"OutAll\""
      ],
      "metadata": {
        "id": "Owq57SLTniQr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH2B3DFyn7w3",
        "outputId": "9211c522-31a2-4353-facc-eb2c02535493"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "7aPp-8e4pQ5E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnsmfvOepjVl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJS2zJK8p1Um"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}